import json
import os
import sys

# ===========================
# 0. ç’°å¢ƒè¨­å®š & å°å…¥ Config
# ===========================
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))

if project_root not in sys.path:
    sys.path.append(project_root)

try:
    from src.config import LABEL2ID, ID2LABEL, LABEL_LIST
except ImportError:
    print("âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° src.configã€‚è«‹ç¢ºä¿ä½ çš„å°ˆæ¡ˆçµæ§‹æ­£ç¢º (src/config.py å­˜åœ¨)ã€‚")
    exit()

print(f"âœ… æˆåŠŸè¼‰å…¥ Configã€‚æ¨™ç±¤ç¸½æ•¸: {len(LABEL_LIST)}")

# ===========================
# 1. å®šç¾©é—œéµå­— (Keywords)
# ===========================

# è·ä½é—œéµå­— (å¦‚æœé•· ORG åŒ…å«é€™äº›å­—ï¼Œé€šå¸¸ä¿‚æ¨™éŒ¯ï¼Œéœ€è¦åˆ‡æ–·)
TITLE_KEYWORDS = [
    "ç¸½è£", "ä¸»å¸­", "ç¶“ç†", "ç¸½ç›£", "ä¸»ä»»", "ç‰¹é¦–", "å¸é•·", "å±€é•·", "è™•é•·", 
    "æ›¾ä»»", "å‰ä»»", "å…¼ä»»", "ç¾ä»»", "å‰¯ç¸½", "CEO", "CFO", "COO", 
    "å‰µè¾¦äºº", "è² è²¬äºº", "ç™¼è¨€äºº", "é¡§å•", "å°ˆå®¶", "æ•™æˆ", "åšå£«",
    "å…ˆç”Ÿ", "å¥³å£«", "å°å§", "ç¸½è­¦å¸", "è­¦å¸", "æœƒé•·", "å°ˆå“¡", "ä»£è¡¨"
]

# æ³›å€åŸŸé—œéµå­— (å–®ç¨å‡ºç¾æ™‚è¦–ç‚º Oï¼Œé¿å…ä½œç‚º ADDRESS æˆ– ORG)
# é€™äº›è©åœ¨æ²’æœ‰å…·é«”è¡—é“/å¤§å»ˆæ™‚ï¼Œé€šå¸¸æ˜¯å™ªéŸ³
BROAD_REGIONS = {"é¦™æ¸¯", "ä¹é¾", "æ–°ç•Œ", "æ¾³é–€", "ä¸­åœ‹", "å¤§ç£å€", "ä¸­ç’°", "æ—ºè§’", "å°–æ²™å’€", "éŠ…é‘¼ç£"}

# ===========================
# 2. è¨­å®šï¼šè² é¢æ¨£æœ¬ (Negative Samples)
# ===========================
NEGATIVE_SAMPLES_RAW = [
    {
        "tokens": ["é¦™", "æ¸¯", "è­¦", "å‹™", "è™•", "å‰", "ç¶²", "çµ¡", "å®‰", "å…¨", "åŠ", "ç§‘", "æŠ€", "ç½ª", "æ¡ˆ", "èª¿", "æŸ¥", "ç§‘", "ç¸½", "è­¦", "å¸", "é™³", "å…ˆ", "ç”Ÿ"],
        "ner_tags": [
            "B-ORG", "I-ORG", "I-ORG", "I-ORG", "I-ORG", # é¦™æ¸¯è­¦å‹™è™•
            "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", # éƒ¨é–€æè¿° (O)
            "O", "O", "O", # ç¸½è­¦å¸ (O)
            "B-NAME", "I-NAME", "I-NAME" # é™³å…ˆç”Ÿ
        ]
    },
    {
        "tokens": ["è³‡", "æ·±", "ç¶²", "çµ¡", "å®‰", "å…¨", "é¡§", "å•", "åŠ", "å‰", "ä»»", "æŠ€", "è¡“", "ç¸½", "ç›£", "æ", "å¤§", "æ–‡", "è¡¨", "ç¤º"],
        "ner_tags": ["O"] * 20 
    },
    {
        "tokens": ["åœ‹", "ç«‹", "å°", "ç£", "å¤§", "å­¸", "ç”Ÿ", "ç‰©", "è³‡", "æº", "æš¨", "è¾²", "å­¸", "é™¢", "é™¢", "é•·", "ç™¼", "è¨€"],
        "ner_tags": [
            "B-ORG", "I-ORG", "I-ORG", "I-ORG", "I-ORG", "I-ORG", "I-ORG", "I-ORG", "I-ORG", "I-ORG", "I-ORG", "I-ORG", "I-ORG", "I-ORG", # æ©Ÿæ§‹å
            "O", "O", # é™¢é•· (O)
            "O", "O"
        ]
    },
    # æ–°å¢ï¼šé‡å°é …ç›® vs æ©Ÿæ§‹çš„è² æ¨£æœ¬
    {
        "tokens": ["å±¯", "é¦¬", "ç·š", "ä¿‚", "ä¸€", "æ¢", "å¥½", "æ–¹", "ä¾¿", "æ—¢", "éµ", "è·¯", "ã€‚"],
        "ner_tags": ["O"] * 13
    }
]

def convert_samples_to_ids(samples):
    converted = []
    for item in samples:
        try:
            tag_ids = [LABEL2ID[t] for t in item["ner_tags"]]
            converted.append({"tokens": item["tokens"], "ner_tags": tag_ids})
        except KeyError as e:
            print(f"âš ï¸ è­¦å‘Šï¼šè² é¢æ¨£æœ¬ä¸­æœ‰æœªçŸ¥çš„æ¨™ç±¤ {e}ï¼Œè«‹æª¢æŸ¥ config.pyã€‚è·³éæ­¤æ¨£æœ¬ã€‚")
    return converted

# ===========================
# 3. æ ¸å¿ƒåŠŸèƒ½ï¼šä¿®å¾©éŒ¯èª¤å¯¦é«”
# ===========================
def fix_bad_entities(data_list):
    """
    ğŸ”¥ ç¶œåˆä¿®å¾©å‡½æ•¸
    1. ç§»é™¤å–®ç¨å‡ºç¾çš„æ³›å€åŸŸ (Broad Regions -> O)
    2. åˆ‡æ–·åŒ…å«è·ä½çš„éé•·å¯¦é«” (Long Entity with Title -> O)
    """
    fixed_count = 0
    cleaned_data = []

    # é å…ˆç²å– IDï¼Œæå‡æ•ˆèƒ½
    O_ID = LABEL2ID.get("O", 0)

    for item in data_list:
        tokens = item["tokens"]
        tags = item["ner_tags"]
        
        # 1. æå–æ‰€æœ‰å¯¦é«”ç‰‡æ®µ (Start, End, TagID)
        # é‚è¼¯ï¼šæƒæ B-Tag é–‹é ­ï¼Œç›´åˆ°é I-Tag
        entities = []
        i = 0
        while i < len(tags):
            tag = tags[i]
            # å‡è¨­ ID çµæ§‹ï¼šå–®æ•¸æ˜¯ B (e.g., 1, 3, ...)ï¼Œå¶æ•¸æ˜¯ I (2, 4, ...)
            # æˆ–è€…ç›´æ¥åˆ¤æ–·æ˜¯å¦ä¸ç‚º O
            if tag != O_ID:
                # ç°¡å–®èµ·è¦‹ï¼Œæˆ‘å€‘å°‡é€£çºŒçš„é O è¦–ç‚ºä¸€å€‹å¯¦é«”å€™é¸
                # (æ›´åš´è¬¹çš„åšæ³•æ˜¯æª¢æŸ¥ BIO è½‰æ›ï¼Œä½†é€™è£¡ç‚ºäº†æ•æ‰æ‰€æœ‰æ½›åœ¨é•·å¯¦é«”ï¼Œå¯¬é¬†ä¸€é»ä¹Ÿç„¡å¦¨)
                start = i
                current_tag_base = tag # è¨˜ä½é–‹å§‹çš„ Tag
                i += 1
                while i < len(tags) and tags[i] != O_ID:
                    # å¦‚æœé‡åˆ°å¦ä¸€å€‹ B-Tag (ä¸” ID ä¸åŒ)ï¼Œè¦–ç‚ºæ–°å¯¦é«”ï¼Œæ–·é–‹
                    # é€™è£¡ç°¡åŒ–ï¼šåªè¦ä¸æ˜¯ O å°±ç¹¼çºŒé€£ï¼Œå› ç‚ºæˆ‘å€‘è¦æŠ“çš„æ˜¯é€£éŒ¯çš„æƒ…æ³
                    i += 1
                end = i
                entities.append((start, end))
            else:
                i += 1
        
        new_tags = list(tags)
        modified = False
        
        for start, end in entities:
            entity_tokens = tokens[start:end]
            entity_text = "".join(entity_tokens)
            
            # --- è¦å‰‡ A: éæ¿¾æ³›å€åŸŸ (Broad Regions) ---
            # æ¢ä»¶ï¼šæ–‡å­—åœ¨æ³›å€åŸŸæ¸…å–®ä¸­ ä¸” é•·åº¦å¾ˆçŸ­ (<=3)
            # ä¾‹å¦‚ "é¦™æ¸¯" (2å­—) -> æ®ºï¼Œ "é¦™æ¸¯å¤§å­¸" (4å­—) -> ç•™
            is_broad = entity_text in BROAD_REGIONS
            is_too_short = len(entity_text) <= 3 
            
            if is_broad and is_too_short:
                # print(f"  ğŸ”ª ç§»é™¤æ³›å€åŸŸå™ªéŸ³: {entity_text}")
                for k in range(start, end):
                    new_tags[k] = O_ID
                modified = True
                continue

            # --- è¦å‰‡ B: éæ¿¾å«è·ä½çš„é•·å¯¦é«” (Overly Long with Title) ---
            # æ¢ä»¶ï¼šé•·åº¦ > 12 ä¸” åŒ…å«è·ä½é—œéµå­—
            if len(entity_text) > 12:
                hit_title = any(t in entity_text for t in TITLE_KEYWORDS)
                
                if hit_title:
                    # print(f"  ğŸ”ª åˆ‡æ–·å«è·ä½é•·å¯¦é«”: {entity_text}")
                    # ç­–ç•¥ï¼šå› ç‚ºå¾ˆé›£ç²¾ç¢ºåˆ‡åˆ†ï¼Œç‚ºäº†å®‰å…¨ï¼Œå°‡æ•´æ®µæ¨™è¨˜ç‚º O (è¦–ç‚ºè² æ¨£æœ¬)
                    # æˆ–è€…ï¼šæ‚¨å¯ä»¥é¸æ“‡åªä¿ç•™å‰ 5-8 å€‹å­—ï¼Œå¾Œé¢è®Š O
                    # é€™è£¡æ¡ç”¨ã€Œå…¨æ®ºã€ç­–ç•¥ï¼Œé¿å…æ•™éŒ¯æ¨¡å‹
                    for k in range(start, end):
                        new_tags[k] = O_ID
                    modified = True
                    continue

        if modified:
            fixed_count += 1
            item["ner_tags"] = new_tags
        
        cleaned_data.append(item)

    print(f"ğŸ§¹ æ¸…æ´—å®Œæˆï¼šå…±ä¿®å¾©äº† {fixed_count} æ¢åŒ…å«ã€Œæ³›å€åŸŸã€æˆ–ã€Œè·ä½æ··åˆã€çš„éŒ¯èª¤æ•¸æ“šã€‚")
    return cleaned_data

# ===========================
# 4. ä¸»ç¨‹å¼
# ===========================
if __name__ == "__main__":
    input_file = "train_data_lora.json"
    output_file = "train_data_lora_cleaned.json"
    
    print(f"ğŸ“‚ è®€å– {input_file}...")
    try:
        with open(input_file, "r", encoding="utf-8") as f:
            raw = json.load(f)
            data = raw["data"] if isinstance(raw, dict) and "data" in raw else raw
    except FileNotFoundError:
        print("âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° train_data_lora.jsonã€‚è«‹å…ˆåŸ·è¡Œ prepare_data.pyï¼")
        exit()

    # 1. åŸ·è¡Œæ ¸å¿ƒæ¸…æ´— (ä¿®å¾©æ³›å€åŸŸ & é•·å¯¦é«”)
    data = fix_bad_entities(data)
    
    # 2. æ³¨å…¥è² é¢æ¨£æœ¬
    negative_data_ids = convert_samples_to_ids(NEGATIVE_SAMPLES_RAW)
    print(f"ğŸ’‰ æ³¨å…¥ {len(negative_data_ids)} æ¢è² é¢æ¨£æœ¬ (å·²è½‰ç‚º ID)...")
    data.extend(negative_data_ids)
    
    # 3. å„²å­˜
    final_output = {
        "data": data,
        "label2id": LABEL2ID,
        "id2label": ID2LABEL
    }
    
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(final_output, f, ensure_ascii=False, indent=2)
        
    print(f"âœ… ææ‚ï¼æ–°æ•¸æ“šå·²å„²å­˜è‡³ {output_file}")
    print(f"ğŸš€ ä¸‹ä¸€æ­¥ï¼šè«‹åŸ·è¡Œ train_lora.py (ç¢ºä¿å®ƒè®€å– {output_file})")