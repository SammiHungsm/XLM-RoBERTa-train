[
  {
    "step": 10,
    "epoch": 0.004443457009553432,
    "loss": 4.2685,
    "grad_norm": 17.92652702331543,
    "learning_rate": 1.4209591474245118e-07
  },
  {
    "step": 20,
    "epoch": 0.008886914019106865,
    "loss": 4.0308,
    "grad_norm": 13.764191627502441,
    "learning_rate": 3.1971580817051514e-07
  },
  {
    "step": 30,
    "epoch": 0.013330371028660297,
    "loss": 4.0431,
    "grad_norm": 14.391636848449707,
    "learning_rate": 4.97335701598579e-07
  },
  {
    "step": 40,
    "epoch": 0.01777382803821373,
    "loss": 4.0723,
    "grad_norm": 19.26730728149414,
    "learning_rate": 6.749555950266431e-07
  },
  {
    "step": 50,
    "epoch": 0.02221728504776716,
    "loss": 4.0865,
    "grad_norm": 17.06174659729004,
    "learning_rate": 8.52575488454707e-07
  },
  {
    "step": 60,
    "epoch": 0.026660742057320594,
    "loss": 4.0136,
    "grad_norm": 16.39106559753418,
    "learning_rate": 1.030195381882771e-06
  },
  {
    "step": 70,
    "epoch": 0.03110419906687403,
    "loss": 4.1535,
    "grad_norm": 23.35894203186035,
    "learning_rate": 1.207815275310835e-06
  },
  {
    "step": 80,
    "epoch": 0.03554765607642746,
    "loss": 3.9761,
    "grad_norm": 16.84635353088379,
    "learning_rate": 1.385435168738899e-06
  },
  {
    "step": 90,
    "epoch": 0.03999111308598089,
    "loss": 4.0154,
    "grad_norm": 18.683048248291016,
    "learning_rate": 1.563055062166963e-06
  },
  {
    "step": 100,
    "epoch": 0.04443457009553432,
    "loss": 4.0738,
    "grad_norm": 20.961410522460938,
    "learning_rate": 1.7406749555950267e-06
  },
  {
    "step": 100,
    "epoch": 0.04443457009553432,
    "eval_loss": 4.059502601623535,
    "eval_f1": 0.0022793550765930347,
    "eval_precision": 0.001396017244918908,
    "eval_recall": 0.006206644760861628,
    "eval_runtime": 36.9509,
    "eval_samples_per_second": 54.153,
    "eval_steps_per_second": 6.793
  },
  {
    "step": 110,
    "epoch": 0.048878027105087755,
    "loss": 4.0696,
    "grad_norm": 22.117223739624023,
    "learning_rate": 1.9182948490230907e-06
  },
  {
    "step": 120,
    "epoch": 0.05332148411464119,
    "loss": 3.998,
    "grad_norm": 14.886392593383789,
    "learning_rate": 2.0959147424511548e-06
  },
  {
    "step": 130,
    "epoch": 0.05776494112419462,
    "loss": 3.9135,
    "grad_norm": 17.58737564086914,
    "learning_rate": 2.273534635879219e-06
  },
  {
    "step": 140,
    "epoch": 0.06220839813374806,
    "loss": 3.932,
    "grad_norm": 19.906984329223633,
    "learning_rate": 2.4511545293072824e-06
  },
  {
    "step": 150,
    "epoch": 0.06665185514330149,
    "loss": 3.9488,
    "grad_norm": 14.691047668457031,
    "learning_rate": 2.628774422735347e-06
  },
  {
    "step": 160,
    "epoch": 0.07109531215285492,
    "loss": 3.8564,
    "grad_norm": 16.415878295898438,
    "learning_rate": 2.8063943161634105e-06
  },
  {
    "step": 170,
    "epoch": 0.07553876916240836,
    "loss": 3.9266,
    "grad_norm": 22.555261611938477,
    "learning_rate": 2.984014209591474e-06
  },
  {
    "step": 180,
    "epoch": 0.07998222617196178,
    "loss": 3.8053,
    "grad_norm": 16.746843338012695,
    "learning_rate": 3.1616341030195386e-06
  },
  {
    "step": 190,
    "epoch": 0.08442568318151522,
    "loss": 3.83,
    "grad_norm": 14.024469375610352,
    "learning_rate": 3.339253996447602e-06
  },
  {
    "step": 200,
    "epoch": 0.08886914019106865,
    "loss": 3.8221,
    "grad_norm": 20.166414260864258,
    "learning_rate": 3.5168738898756667e-06
  },
  {
    "step": 200,
    "epoch": 0.08886914019106865,
    "eval_loss": 3.8193795680999756,
    "eval_f1": 0.002065633849741796,
    "eval_precision": 0.0012633981334311448,
    "eval_recall": 0.005658999634903249,
    "eval_runtime": 37.3541,
    "eval_samples_per_second": 53.568,
    "eval_steps_per_second": 6.719
  },
  {
    "step": 210,
    "epoch": 0.09331259720062209,
    "loss": 3.6761,
    "grad_norm": 21.384632110595703,
    "learning_rate": 3.6944937833037303e-06
  },
  {
    "step": 220,
    "epoch": 0.09775605421017551,
    "loss": 3.7682,
    "grad_norm": 18.974628448486328,
    "learning_rate": 3.872113676731794e-06
  },
  {
    "step": 230,
    "epoch": 0.10219951121972895,
    "loss": 3.6155,
    "grad_norm": 14.362539291381836,
    "learning_rate": 4.049733570159858e-06
  },
  {
    "step": 240,
    "epoch": 0.10664296822928238,
    "loss": 3.7931,
    "grad_norm": 14.392654418945312,
    "learning_rate": 4.227353463587922e-06
  },
  {
    "step": 250,
    "epoch": 0.11108642523883581,
    "loss": 3.6505,
    "grad_norm": 16.902637481689453,
    "learning_rate": 4.404973357015986e-06
  },
  {
    "step": 260,
    "epoch": 0.11552988224838924,
    "loss": 3.6077,
    "grad_norm": 14.490577697753906,
    "learning_rate": 4.58259325044405e-06
  },
  {
    "step": 270,
    "epoch": 0.11997333925794268,
    "loss": 3.5603,
    "grad_norm": 12.995377540588379,
    "learning_rate": 4.760213143872114e-06
  },
  {
    "step": 280,
    "epoch": 0.12441679626749612,
    "loss": 3.5262,
    "grad_norm": 15.91612434387207,
    "learning_rate": 4.937833037300178e-06
  },
  {
    "step": 290,
    "epoch": 0.12886025327704956,
    "loss": 3.4542,
    "grad_norm": 15.331892013549805,
    "learning_rate": 5.115452930728242e-06
  },
  {
    "step": 300,
    "epoch": 0.13330371028660298,
    "loss": 3.4775,
    "grad_norm": 19.748512268066406,
    "learning_rate": 5.293072824156305e-06
  },
  {
    "step": 300,
    "epoch": 0.13330371028660298,
    "eval_loss": 3.4263739585876465,
    "eval_f1": 0.0025535918285061487,
    "eval_precision": 0.0015648163399769395,
    "eval_recall": 0.006936838262139467,
    "eval_runtime": 37.5108,
    "eval_samples_per_second": 53.345,
    "eval_steps_per_second": 6.691
  },
  {
    "step": 310,
    "epoch": 0.1377471672961564,
    "loss": 3.3129,
    "grad_norm": 14.740517616271973,
    "learning_rate": 5.4706927175843694e-06
  },
  {
    "step": 320,
    "epoch": 0.14219062430570983,
    "loss": 3.3078,
    "grad_norm": 13.63731575012207,
    "learning_rate": 5.648312611012434e-06
  },
  {
    "step": 330,
    "epoch": 0.1466340813152633,
    "loss": 3.3487,
    "grad_norm": 14.809940338134766,
    "learning_rate": 5.825932504440498e-06
  },
  {
    "step": 340,
    "epoch": 0.1510775383248167,
    "loss": 3.2575,
    "grad_norm": 17.69773292541504,
    "learning_rate": 6.0035523978685616e-06
  },
  {
    "step": 350,
    "epoch": 0.15552099533437014,
    "loss": 3.1964,
    "grad_norm": 14.798272132873535,
    "learning_rate": 6.181172291296626e-06
  },
  {
    "step": 360,
    "epoch": 0.15996445234392356,
    "loss": 3.1752,
    "grad_norm": 18.170822143554688,
    "learning_rate": 6.358792184724689e-06
  },
  {
    "step": 370,
    "epoch": 0.16440790935347702,
    "loss": 3.1114,
    "grad_norm": 13.987125396728516,
    "learning_rate": 6.536412078152754e-06
  },
  {
    "step": 380,
    "epoch": 0.16885136636303044,
    "loss": 3.0719,
    "grad_norm": 18.879789352416992,
    "learning_rate": 6.714031971580818e-06
  },
  {
    "step": 390,
    "epoch": 0.17329482337258387,
    "loss": 2.9631,
    "grad_norm": 15.215720176696777,
    "learning_rate": 6.891651865008882e-06
  },
  {
    "step": 400,
    "epoch": 0.1777382803821373,
    "loss": 2.8894,
    "grad_norm": 16.01283836364746,
    "learning_rate": 7.069271758436945e-06
  },
  {
    "step": 400,
    "epoch": 0.1777382803821373,
    "eval_loss": 2.8892650604248047,
    "eval_f1": 0.004054151885904583,
    "eval_precision": 0.0025284450063211127,
    "eval_recall": 0.01022270901788974,
    "eval_runtime": 38.5023,
    "eval_samples_per_second": 51.971,
    "eval_steps_per_second": 6.519
  },
  {
    "step": 410,
    "epoch": 0.18218173739169075,
    "loss": 2.8489,
    "grad_norm": 13.344032287597656,
    "learning_rate": 7.246891651865009e-06
  },
  {
    "step": 420,
    "epoch": 0.18662519440124417,
    "loss": 2.8386,
    "grad_norm": 17.936744689941406,
    "learning_rate": 7.424511545293074e-06
  },
  {
    "step": 430,
    "epoch": 0.1910686514107976,
    "loss": 2.7831,
    "grad_norm": 16.77459716796875,
    "learning_rate": 7.602131438721138e-06
  },
  {
    "step": 440,
    "epoch": 0.19551210842035102,
    "loss": 2.7147,
    "grad_norm": 14.707932472229004,
    "learning_rate": 7.779751332149202e-06
  },
  {
    "step": 450,
    "epoch": 0.19995556542990447,
    "loss": 2.6808,
    "grad_norm": 16.1146240234375,
    "learning_rate": 7.957371225577264e-06
  },
  {
    "step": 460,
    "epoch": 0.2043990224394579,
    "loss": 2.5851,
    "grad_norm": 13.185327529907227,
    "learning_rate": 8.117229129662523e-06
  },
  {
    "step": 470,
    "epoch": 0.20884247944901133,
    "loss": 2.4837,
    "grad_norm": 17.95867156982422,
    "learning_rate": 8.294849023090587e-06
  },
  {
    "step": 480,
    "epoch": 0.21328593645856475,
    "loss": 2.5025,
    "grad_norm": 18.672260284423828,
    "learning_rate": 8.472468916518651e-06
  },
  {
    "step": 490,
    "epoch": 0.2177293934681182,
    "loss": 2.3871,
    "grad_norm": 20.221050262451172,
    "learning_rate": 8.650088809946715e-06
  },
  {
    "step": 500,
    "epoch": 0.22217285047767163,
    "loss": 2.3782,
    "grad_norm": 16.381120681762695,
    "learning_rate": 8.82770870337478e-06
  },
  {
    "step": 500,
    "epoch": 0.22217285047767163,
    "eval_loss": 2.2533233165740967,
    "eval_f1": 0.007563694267515924,
    "eval_precision": 0.004836574686895428,
    "eval_recall": 0.017342095655348666,
    "eval_runtime": 41.306,
    "eval_samples_per_second": 48.443,
    "eval_steps_per_second": 6.077
  },
  {
    "step": 510,
    "epoch": 0.22661630748722505,
    "loss": 2.2811,
    "grad_norm": 14.13553237915039,
    "learning_rate": 9.005328596802843e-06
  },
  {
    "step": 520,
    "epoch": 0.23105976449677848,
    "loss": 2.2382,
    "grad_norm": 12.221708297729492,
    "learning_rate": 9.182948490230906e-06
  },
  {
    "step": 530,
    "epoch": 0.23550322150633193,
    "loss": 2.1363,
    "grad_norm": 12.798026084899902,
    "learning_rate": 9.36056838365897e-06
  },
  {
    "step": 540,
    "epoch": 0.23994667851588536,
    "loss": 2.0908,
    "grad_norm": 12.861186981201172,
    "learning_rate": 9.538188277087035e-06
  },
  {
    "step": 550,
    "epoch": 0.24439013552543878,
    "loss": 2.0067,
    "grad_norm": 14.023350715637207,
    "learning_rate": 9.7158081705151e-06
  },
  {
    "step": 560,
    "epoch": 0.24883359253499224,
    "loss": 1.9205,
    "grad_norm": 12.7344388961792,
    "learning_rate": 9.893428063943162e-06
  },
  {
    "step": 570,
    "epoch": 0.25327704954454566,
    "loss": 1.9472,
    "grad_norm": 11.074666023254395,
    "learning_rate": 1.0071047957371227e-05
  },
  {
    "step": 580,
    "epoch": 0.2577205065540991,
    "loss": 1.8417,
    "grad_norm": 16.01767921447754,
    "learning_rate": 1.024866785079929e-05
  },
  {
    "step": 590,
    "epoch": 0.2621639635636525,
    "loss": 1.7567,
    "grad_norm": 13.546709060668945,
    "learning_rate": 1.0426287744227354e-05
  },
  {
    "step": 600,
    "epoch": 0.26660742057320597,
    "loss": 1.7484,
    "grad_norm": 9.425036430358887,
    "learning_rate": 1.0603907637655418e-05
  },
  {
    "step": 600,
    "epoch": 0.26660742057320597,
    "eval_loss": 1.6040798425674438,
    "eval_f1": 0.08592287532759266,
    "eval_precision": 0.08816749903956973,
    "eval_recall": 0.08378970427163199,
    "eval_runtime": 40.338,
    "eval_samples_per_second": 49.606,
    "eval_steps_per_second": 6.222
  },
  {
    "step": 610,
    "epoch": 0.27105087758275936,
    "loss": 1.6639,
    "grad_norm": 13.53095531463623,
    "learning_rate": 1.0781527531083482e-05
  },
  {
    "step": 620,
    "epoch": 0.2754943345923128,
    "loss": 1.5869,
    "grad_norm": 10.272393226623535,
    "learning_rate": 1.0959147424511548e-05
  },
  {
    "step": 630,
    "epoch": 0.27993779160186627,
    "loss": 1.5145,
    "grad_norm": 11.546883583068848,
    "learning_rate": 1.113676731793961e-05
  },
  {
    "step": 640,
    "epoch": 0.28438124861141967,
    "loss": 1.4768,
    "grad_norm": 13.283930778503418,
    "learning_rate": 1.1314387211367674e-05
  },
  {
    "step": 650,
    "epoch": 0.2888247056209731,
    "loss": 1.4016,
    "grad_norm": 6.659216403961182,
    "learning_rate": 1.1492007104795736e-05
  },
  {
    "step": 660,
    "epoch": 0.2932681626305266,
    "loss": 1.3737,
    "grad_norm": 9.221288681030273,
    "learning_rate": 1.1669626998223802e-05
  },
  {
    "step": 670,
    "epoch": 0.29771161964007997,
    "loss": 1.3797,
    "grad_norm": 5.289982318878174,
    "learning_rate": 1.1847246891651866e-05
  },
  {
    "step": 680,
    "epoch": 0.3021550766496334,
    "loss": 1.3915,
    "grad_norm": 7.1313605308532715,
    "learning_rate": 1.202486678507993e-05
  },
  {
    "step": 690,
    "epoch": 0.3065985336591868,
    "loss": 1.3283,
    "grad_norm": 4.894072532653809,
    "learning_rate": 1.2202486678507994e-05
  },
  {
    "step": 700,
    "epoch": 0.3110419906687403,
    "loss": 1.2572,
    "grad_norm": 4.676938533782959,
    "learning_rate": 1.2380106571936057e-05
  },
  {
    "step": 700,
    "epoch": 0.3110419906687403,
    "eval_loss": 1.16245698928833,
    "eval_f1": 0.24886445135070526,
    "eval_precision": 0.36045706371191133,
    "eval_recall": 0.1900328587075575,
    "eval_runtime": 39.8243,
    "eval_samples_per_second": 50.246,
    "eval_steps_per_second": 6.303
  },
  {
    "step": 710,
    "epoch": 0.31548544767829373,
    "loss": 1.2827,
    "grad_norm": 3.6287918090820312,
    "learning_rate": 1.2557726465364122e-05
  },
  {
    "step": 720,
    "epoch": 0.3199289046878471,
    "loss": 1.1501,
    "grad_norm": 5.202157020568848,
    "learning_rate": 1.2735346358792186e-05
  },
  {
    "step": 730,
    "epoch": 0.3243723616974006,
    "loss": 1.203,
    "grad_norm": 3.013559341430664,
    "learning_rate": 1.2912966252220249e-05
  },
  {
    "step": 740,
    "epoch": 0.32881581870695403,
    "loss": 1.1594,
    "grad_norm": 2.6947576999664307,
    "learning_rate": 1.3090586145648314e-05
  },
  {
    "step": 750,
    "epoch": 0.33325927571650743,
    "loss": 1.1113,
    "grad_norm": 2.861250400543213,
    "learning_rate": 1.3268206039076377e-05
  },
  {
    "step": 760,
    "epoch": 0.3377027327260609,
    "loss": 1.0948,
    "grad_norm": 2.680562734603882,
    "learning_rate": 1.3445825932504441e-05
  },
  {
    "step": 770,
    "epoch": 0.3421461897356143,
    "loss": 1.0905,
    "grad_norm": 2.190729856491089,
    "learning_rate": 1.3623445825932507e-05
  },
  {
    "step": 780,
    "epoch": 0.34658964674516773,
    "loss": 1.1035,
    "grad_norm": 2.371596574783325,
    "learning_rate": 1.3801065719360569e-05
  },
  {
    "step": 790,
    "epoch": 0.3510331037547212,
    "loss": 1.04,
    "grad_norm": 2.5223729610443115,
    "learning_rate": 1.3978685612788635e-05
  },
  {
    "step": 800,
    "epoch": 0.3554765607642746,
    "loss": 1.033,
    "grad_norm": 2.2969810962677,
    "learning_rate": 1.4156305506216697e-05
  },
  {
    "step": 800,
    "epoch": 0.3554765607642746,
    "eval_loss": 0.9875798225402832,
    "eval_f1": 0.25640372116732507,
    "eval_precision": 0.4246517517940059,
    "eval_recall": 0.1836436655713764,
    "eval_runtime": 45.4757,
    "eval_samples_per_second": 44.002,
    "eval_steps_per_second": 5.519
  },
  {
    "step": 810,
    "epoch": 0.35992001777382804,
    "loss": 1.0737,
    "grad_norm": 2.3764686584472656,
    "learning_rate": 1.4333925399644761e-05
  },
  {
    "step": 820,
    "epoch": 0.3643634747833815,
    "loss": 1.0513,
    "grad_norm": 2.346223831176758,
    "learning_rate": 1.4511545293072827e-05
  },
  {
    "step": 830,
    "epoch": 0.3688069317929349,
    "loss": 0.927,
    "grad_norm": 1.3258850574493408,
    "learning_rate": 1.468916518650089e-05
  },
  {
    "step": 840,
    "epoch": 0.37325038880248834,
    "loss": 0.9737,
    "grad_norm": 1.8306185007095337,
    "learning_rate": 1.4866785079928953e-05
  },
  {
    "step": 850,
    "epoch": 0.3776938458120418,
    "loss": 1.0591,
    "grad_norm": 1.380838394165039,
    "learning_rate": 1.5044404973357016e-05
  },
  {
    "step": 860,
    "epoch": 0.3821373028215952,
    "loss": 0.9085,
    "grad_norm": 1.693124771118164,
    "learning_rate": 1.5222024866785081e-05
  },
  {
    "step": 870,
    "epoch": 0.38658075983114865,
    "loss": 0.9221,
    "grad_norm": 1.9480048418045044,
    "learning_rate": 1.5399644760213145e-05
  },
  {
    "step": 880,
    "epoch": 0.39102421684070204,
    "loss": 1.0926,
    "grad_norm": 3.6903233528137207,
    "learning_rate": 1.557726465364121e-05
  },
  {
    "step": 890,
    "epoch": 0.3954676738502555,
    "loss": 0.9822,
    "grad_norm": 1.562104344367981,
    "learning_rate": 1.5754884547069273e-05
  },
  {
    "step": 900,
    "epoch": 0.39991113085980895,
    "loss": 0.8942,
    "grad_norm": 1.4355745315551758,
    "learning_rate": 1.5932504440497337e-05
  },
  {
    "step": 900,
    "epoch": 0.39991113085980895,
    "eval_loss": 0.9326561689376831,
    "eval_f1": 0.2651032373183788,
    "eval_precision": 0.4391891891891892,
    "eval_recall": 0.18985031033223804,
    "eval_runtime": 40.2504,
    "eval_samples_per_second": 49.714,
    "eval_steps_per_second": 6.236
  },
  {
    "step": 910,
    "epoch": 0.40435458786936235,
    "loss": 0.9421,
    "grad_norm": 1.7337939739227295,
    "learning_rate": 1.61101243339254e-05
  },
  {
    "step": 920,
    "epoch": 0.4087980448789158,
    "loss": 1.0542,
    "grad_norm": 1.9292551279067993,
    "learning_rate": 1.6287744227353466e-05
  },
  {
    "step": 930,
    "epoch": 0.41324150188846925,
    "loss": 0.9613,
    "grad_norm": 2.468043804168701,
    "learning_rate": 1.646536412078153e-05
  },
  {
    "step": 940,
    "epoch": 0.41768495889802265,
    "loss": 0.939,
    "grad_norm": 1.2299673557281494,
    "learning_rate": 1.6642984014209594e-05
  },
  {
    "step": 950,
    "epoch": 0.4221284159075761,
    "loss": 0.9699,
    "grad_norm": 1.1555287837982178,
    "learning_rate": 1.6820603907637654e-05
  },
  {
    "step": 960,
    "epoch": 0.4265718729171295,
    "loss": 0.9211,
    "grad_norm": 2.5200304985046387,
    "learning_rate": 1.6998223801065722e-05
  },
  {
    "step": 970,
    "epoch": 0.43101532992668296,
    "loss": 0.9504,
    "grad_norm": 2.7301948070526123,
    "learning_rate": 1.7175843694493786e-05
  },
  {
    "step": 980,
    "epoch": 0.4354587869362364,
    "loss": 0.9277,
    "grad_norm": 1.640059232711792,
    "learning_rate": 1.735346358792185e-05
  },
  {
    "step": 990,
    "epoch": 0.4399022439457898,
    "loss": 0.9634,
    "grad_norm": 1.1359297037124634,
    "learning_rate": 1.7531083481349914e-05
  },
  {
    "step": 1000,
    "epoch": 0.44434570095534326,
    "loss": 0.9423,
    "grad_norm": 3.7918269634246826,
    "learning_rate": 1.7708703374777974e-05
  },
  {
    "step": 1000,
    "epoch": 0.44434570095534326,
    "eval_loss": 0.9120997190475464,
    "eval_f1": 0.26730793570434125,
    "eval_precision": 0.4358233594717293,
    "eval_recall": 0.1927710843373494,
    "eval_runtime": 41.2612,
    "eval_samples_per_second": 48.496,
    "eval_steps_per_second": 6.083
  },
  {
    "step": 1010,
    "epoch": 0.4487891579648967,
    "loss": 0.902,
    "grad_norm": 1.8428915739059448,
    "learning_rate": 1.7886323268206042e-05
  },
  {
    "step": 1020,
    "epoch": 0.4532326149744501,
    "loss": 0.9492,
    "grad_norm": 1.283030390739441,
    "learning_rate": 1.8063943161634106e-05
  },
  {
    "step": 1030,
    "epoch": 0.45767607198400356,
    "loss": 0.8483,
    "grad_norm": 1.9194828271865845,
    "learning_rate": 1.8241563055062167e-05
  },
  {
    "step": 1040,
    "epoch": 0.46211952899355696,
    "loss": 1.0261,
    "grad_norm": 1.6316347122192383,
    "learning_rate": 1.8419182948490234e-05
  },
  {
    "step": 1050,
    "epoch": 0.4665629860031104,
    "loss": 0.9201,
    "grad_norm": 1.516812801361084,
    "learning_rate": 1.8596802841918295e-05
  },
  {
    "step": 1060,
    "epoch": 0.47100644301266387,
    "loss": 0.9319,
    "grad_norm": 1.3253662586212158,
    "learning_rate": 1.877442273534636e-05
  },
  {
    "step": 1070,
    "epoch": 0.47544990002221726,
    "loss": 0.9584,
    "grad_norm": 1.2201621532440186,
    "learning_rate": 1.8952042628774426e-05
  },
  {
    "step": 1080,
    "epoch": 0.4798933570317707,
    "loss": 0.9203,
    "grad_norm": 1.1983426809310913,
    "learning_rate": 1.9129662522202487e-05
  },
  {
    "step": 1090,
    "epoch": 0.48433681404132417,
    "loss": 0.8986,
    "grad_norm": 2.869040012359619,
    "learning_rate": 1.9307282415630554e-05
  },
  {
    "step": 1100,
    "epoch": 0.48878027105087757,
    "loss": 0.9926,
    "grad_norm": 1.016208291053772,
    "learning_rate": 1.9484902309058615e-05
  },
  {
    "step": 1100,
    "epoch": 0.48878027105087757,
    "eval_loss": 0.8965524435043335,
    "eval_f1": 0.2848530519969857,
    "eval_precision": 0.45652173913043476,
    "eval_recall": 0.20700985761226726,
    "eval_runtime": 43.2062,
    "eval_samples_per_second": 46.313,
    "eval_steps_per_second": 5.809
  },
  {
    "step": 1110,
    "epoch": 0.493223728060431,
    "loss": 0.8682,
    "grad_norm": 2.835449457168579,
    "learning_rate": 1.966252220248668e-05
  },
  {
    "step": 1120,
    "epoch": 0.4976671850699845,
    "loss": 0.9059,
    "grad_norm": 0.9774041175842285,
    "learning_rate": 1.9840142095914746e-05
  },
  {
    "step": 1130,
    "epoch": 0.5021106420795379,
    "loss": 0.9094,
    "grad_norm": 1.62254798412323,
    "learning_rate": 1.9999999519009385e-05
  },
  {
    "step": 1140,
    "epoch": 0.5065540990890913,
    "loss": 0.875,
    "grad_norm": 1.4808374643325806,
    "learning_rate": 1.999994180019139e-05
  },
  {
    "step": 1150,
    "epoch": 0.5109975560986447,
    "loss": 0.9705,
    "grad_norm": 1.7231990098953247,
    "learning_rate": 1.9999787883886296e-05
  },
  {
    "step": 1160,
    "epoch": 0.5154410131081982,
    "loss": 0.9147,
    "grad_norm": 1.6545416116714478,
    "learning_rate": 1.9999537771574758e-05
  },
  {
    "step": 1170,
    "epoch": 0.5198844701177516,
    "loss": 1.0021,
    "grad_norm": 1.1846469640731812,
    "learning_rate": 1.999919146566281e-05
  },
  {
    "step": 1180,
    "epoch": 0.524327927127305,
    "loss": 0.9129,
    "grad_norm": 1.4975879192352295,
    "learning_rate": 1.9998748969481836e-05
  },
  {
    "step": 1190,
    "epoch": 0.5287713841368584,
    "loss": 0.9616,
    "grad_norm": 1.7521864175796509,
    "learning_rate": 1.999821028728857e-05
  },
  {
    "step": 1200,
    "epoch": 0.5332148411464119,
    "loss": 0.8788,
    "grad_norm": 1.3142449855804443,
    "learning_rate": 1.999757542426503e-05
  },
  {
    "step": 1200,
    "epoch": 0.5332148411464119,
    "eval_loss": 0.8843535780906677,
    "eval_f1": 0.2887968887216159,
    "eval_precision": 0.46169273967107904,
    "eval_recall": 0.21011317999269807,
    "eval_runtime": 42.7582,
    "eval_samples_per_second": 46.798,
    "eval_steps_per_second": 5.87
  },
  {
    "step": 1210,
    "epoch": 0.5376582981559653,
    "loss": 0.9438,
    "grad_norm": 0.9653723835945129,
    "learning_rate": 1.9996844386518473e-05
  },
  {
    "step": 1220,
    "epoch": 0.5421017551655187,
    "loss": 0.9,
    "grad_norm": 1.7098802328109741,
    "learning_rate": 1.999601718108134e-05
  },
  {
    "step": 1230,
    "epoch": 0.5465452121750722,
    "loss": 0.8675,
    "grad_norm": 1.089591145515442,
    "learning_rate": 1.9995093815911177e-05
  },
  {
    "step": 1240,
    "epoch": 0.5509886691846256,
    "loss": 0.9673,
    "grad_norm": 1.464019536972046,
    "learning_rate": 1.999407429989059e-05
  },
  {
    "step": 1250,
    "epoch": 0.555432126194179,
    "loss": 0.9646,
    "grad_norm": 2.1539254188537598,
    "learning_rate": 1.999295864282712e-05
  },
  {
    "step": 1260,
    "epoch": 0.5598755832037325,
    "loss": 0.9746,
    "grad_norm": 1.2565079927444458,
    "learning_rate": 1.9991746855453162e-05
  },
  {
    "step": 1270,
    "epoch": 0.5643190402132859,
    "loss": 0.8645,
    "grad_norm": 1.998928189277649,
    "learning_rate": 1.9990438949425886e-05
  },
  {
    "step": 1280,
    "epoch": 0.5687624972228393,
    "loss": 0.9486,
    "grad_norm": 1.3804048299789429,
    "learning_rate": 1.9989034937327084e-05
  },
  {
    "step": 1290,
    "epoch": 0.5732059542323928,
    "loss": 0.8548,
    "grad_norm": 0.6760088801383972,
    "learning_rate": 1.9987534832663082e-05
  },
  {
    "step": 1300,
    "epoch": 0.5776494112419462,
    "loss": 0.8885,
    "grad_norm": 2.5730268955230713,
    "learning_rate": 1.998593864986459e-05
  },
  {
    "step": 1300,
    "epoch": 0.5776494112419462,
    "eval_loss": 0.8741578459739685,
    "eval_f1": 0.30193871169480924,
    "eval_precision": 0.47953913388955105,
    "eval_recall": 0.22033588901058782,
    "eval_runtime": 42.362,
    "eval_samples_per_second": 47.236,
    "eval_steps_per_second": 5.925
  },
  {
    "step": 1310,
    "epoch": 0.5820928682514996,
    "loss": 0.9605,
    "grad_norm": 5.777554512023926,
    "learning_rate": 1.9984246404286583e-05
  },
  {
    "step": 1320,
    "epoch": 0.5865363252610531,
    "loss": 1.0368,
    "grad_norm": 1.1591788530349731,
    "learning_rate": 1.9982458112208124e-05
  },
  {
    "step": 1330,
    "epoch": 0.5909797822706065,
    "loss": 0.8936,
    "grad_norm": 1.9193118810653687,
    "learning_rate": 1.9980573790832236e-05
  },
  {
    "step": 1340,
    "epoch": 0.5954232392801599,
    "loss": 0.8424,
    "grad_norm": 1.4317731857299805,
    "learning_rate": 1.9978593458285726e-05
  },
  {
    "step": 1350,
    "epoch": 0.5998666962897135,
    "loss": 0.8607,
    "grad_norm": 1.121590256690979,
    "learning_rate": 1.9976517133619e-05
  },
  {
    "step": 1360,
    "epoch": 0.6043101532992669,
    "loss": 0.9248,
    "grad_norm": 1.7317180633544922,
    "learning_rate": 1.9974344836805905e-05
  },
  {
    "step": 1370,
    "epoch": 0.6087536103088202,
    "loss": 0.9006,
    "grad_norm": 0.7012624144554138,
    "learning_rate": 1.9972076588743507e-05
  },
  {
    "step": 1380,
    "epoch": 0.6131970673183736,
    "loss": 0.8695,
    "grad_norm": 1.0082893371582031,
    "learning_rate": 1.9969712411251903e-05
  },
  {
    "step": 1390,
    "epoch": 0.6176405243279272,
    "loss": 0.9316,
    "grad_norm": 1.3458688259124756,
    "learning_rate": 1.996725232707403e-05
  },
  {
    "step": 1400,
    "epoch": 0.6220839813374806,
    "loss": 0.8284,
    "grad_norm": 2.0414326190948486,
    "learning_rate": 1.9964696359875413e-05
  },
  {
    "step": 1400,
    "epoch": 0.6220839813374806,
    "eval_loss": 0.8632249236106873,
    "eval_f1": 0.31367659892781447,
    "eval_precision": 0.4946913094769957,
    "eval_recall": 0.22964585615188024,
    "eval_runtime": 42.6566,
    "eval_samples_per_second": 46.91,
    "eval_steps_per_second": 5.884
  },
  {
    "step": 1410,
    "epoch": 0.626527438347034,
    "loss": 0.9275,
    "grad_norm": 1.715699315071106,
    "learning_rate": 1.9962044534243954e-05
  },
  {
    "step": 1420,
    "epoch": 0.6309708953565875,
    "loss": 0.8539,
    "grad_norm": 1.361479640007019,
    "learning_rate": 1.99592968756897e-05
  },
  {
    "step": 1430,
    "epoch": 0.6354143523661409,
    "loss": 0.8608,
    "grad_norm": 1.5971277952194214,
    "learning_rate": 1.995645341064459e-05
  },
  {
    "step": 1440,
    "epoch": 0.6398578093756943,
    "loss": 0.9013,
    "grad_norm": 1.600419282913208,
    "learning_rate": 1.9953514166462208e-05
  },
  {
    "step": 1450,
    "epoch": 0.6443012663852478,
    "loss": 0.8364,
    "grad_norm": 2.6890451908111572,
    "learning_rate": 1.9950479171417497e-05
  },
  {
    "step": 1460,
    "epoch": 0.6487447233948012,
    "loss": 0.8662,
    "grad_norm": 1.3831461668014526,
    "learning_rate": 1.9947348454706523e-05
  },
  {
    "step": 1470,
    "epoch": 0.6531881804043546,
    "loss": 0.8762,
    "grad_norm": 0.8392562866210938,
    "learning_rate": 1.9944122046446172e-05
  },
  {
    "step": 1480,
    "epoch": 0.6576316374139081,
    "loss": 0.8632,
    "grad_norm": 0.9864808917045593,
    "learning_rate": 1.9940799977673855e-05
  },
  {
    "step": 1490,
    "epoch": 0.6620750944234615,
    "loss": 0.9485,
    "grad_norm": 2.554126262664795,
    "learning_rate": 1.9937382280347232e-05
  },
  {
    "step": 1500,
    "epoch": 0.6665185514330149,
    "loss": 0.9099,
    "grad_norm": 2.0144269466400146,
    "learning_rate": 1.9933868987343875e-05
  },
  {
    "step": 1500,
    "epoch": 0.6665185514330149,
    "eval_loss": 0.8552168607711792,
    "eval_f1": 0.3166417538614848,
    "eval_precision": 0.4984313725490196,
    "eval_recall": 0.23201898503103321,
    "eval_runtime": 43.3722,
    "eval_samples_per_second": 46.136,
    "eval_steps_per_second": 5.787
  },
  {
    "step": 1510,
    "epoch": 0.6709620084425684,
    "loss": 0.8324,
    "grad_norm": 1.467557668685913,
    "learning_rate": 1.9930260132460986e-05
  },
  {
    "step": 1520,
    "epoch": 0.6754054654521218,
    "loss": 0.8326,
    "grad_norm": 0.8168296813964844,
    "learning_rate": 1.992655575041504e-05
  },
  {
    "step": 1530,
    "epoch": 0.6798489224616752,
    "loss": 0.8163,
    "grad_norm": 0.8465065360069275,
    "learning_rate": 1.9922755876841465e-05
  },
  {
    "step": 1540,
    "epoch": 0.6842923794712286,
    "loss": 0.8905,
    "grad_norm": 1.1166465282440186,
    "learning_rate": 1.991886054829431e-05
  },
  {
    "step": 1550,
    "epoch": 0.6887358364807821,
    "loss": 0.8614,
    "grad_norm": 0.8107447028160095,
    "learning_rate": 1.991486980224587e-05
  },
  {
    "step": 1560,
    "epoch": 0.6931792934903355,
    "loss": 0.9248,
    "grad_norm": 2.1383492946624756,
    "learning_rate": 1.9910783677086343e-05
  },
  {
    "step": 1570,
    "epoch": 0.6976227504998889,
    "loss": 0.9149,
    "grad_norm": 1.1057641506195068,
    "learning_rate": 1.9906602212123456e-05
  },
  {
    "step": 1580,
    "epoch": 0.7020662075094424,
    "loss": 0.8543,
    "grad_norm": 2.738879680633545,
    "learning_rate": 1.990232544758209e-05
  },
  {
    "step": 1590,
    "epoch": 0.7065096645189958,
    "loss": 0.912,
    "grad_norm": 1.7632405757904053,
    "learning_rate": 1.9897953424603867e-05
  },
  {
    "step": 1600,
    "epoch": 0.7109531215285492,
    "loss": 0.8399,
    "grad_norm": 1.1847633123397827,
    "learning_rate": 1.9893486185246814e-05
  },
  {
    "step": 1600,
    "epoch": 0.7109531215285492,
    "eval_loss": 0.8457694053649902,
    "eval_f1": 0.32343070229956494,
    "eval_precision": 0.5068172964550058,
    "eval_recall": 0.237495436290617,
    "eval_runtime": 43.6085,
    "eval_samples_per_second": 45.886,
    "eval_steps_per_second": 5.756
  },
  {
    "step": 1610,
    "epoch": 0.7153965785381027,
    "loss": 0.9527,
    "grad_norm": 1.1055413484573364,
    "learning_rate": 1.9888923772484898e-05
  },
  {
    "step": 1620,
    "epoch": 0.7198400355476561,
    "loss": 0.8215,
    "grad_norm": 1.4474719762802124,
    "learning_rate": 1.988426623020763e-05
  },
  {
    "step": 1630,
    "epoch": 0.7242834925572095,
    "loss": 0.8666,
    "grad_norm": 1.281529426574707,
    "learning_rate": 1.987951360321966e-05
  },
  {
    "step": 1640,
    "epoch": 0.728726949566763,
    "loss": 0.9379,
    "grad_norm": 2.2741241455078125,
    "learning_rate": 1.9874665937240335e-05
  },
  {
    "step": 1650,
    "epoch": 0.7331704065763164,
    "loss": 0.8999,
    "grad_norm": 1.7203147411346436,
    "learning_rate": 1.9869723278903254e-05
  },
  {
    "step": 1660,
    "epoch": 0.7376138635858698,
    "loss": 0.8751,
    "grad_norm": 0.880556583404541,
    "learning_rate": 1.9864685675755827e-05
  },
  {
    "step": 1670,
    "epoch": 0.7420573205954233,
    "loss": 0.8159,
    "grad_norm": 1.1123948097229004,
    "learning_rate": 1.9859553176258805e-05
  },
  {
    "step": 1680,
    "epoch": 0.7465007776049767,
    "loss": 0.8768,
    "grad_norm": 1.5054360628128052,
    "learning_rate": 1.985432582978583e-05
  },
  {
    "step": 1690,
    "epoch": 0.7509442346145301,
    "loss": 0.8329,
    "grad_norm": 1.8122869729995728,
    "learning_rate": 1.984900368662297e-05
  },
  {
    "step": 1700,
    "epoch": 0.7553876916240836,
    "loss": 0.8558,
    "grad_norm": 1.148385763168335,
    "learning_rate": 1.9843586797968184e-05
  },
  {
    "step": 1700,
    "epoch": 0.7553876916240836,
    "eval_loss": 0.8406127095222473,
    "eval_f1": 0.32514271531397365,
    "eval_precision": 0.5077519379844961,
    "eval_recall": 0.23913837166849214,
    "eval_runtime": 41.8093,
    "eval_samples_per_second": 47.86,
    "eval_steps_per_second": 6.003
  },
  {
    "step": 1710,
    "epoch": 0.759831148633637,
    "loss": 0.8216,
    "grad_norm": 1.6286872625350952,
    "learning_rate": 1.9838075215930895e-05
  },
  {
    "step": 1720,
    "epoch": 0.7642746056431904,
    "loss": 0.8706,
    "grad_norm": 1.288699746131897,
    "learning_rate": 1.983246899353144e-05
  },
  {
    "step": 1730,
    "epoch": 0.7687180626527438,
    "loss": 0.882,
    "grad_norm": 1.110918402671814,
    "learning_rate": 1.9826768184700586e-05
  },
  {
    "step": 1740,
    "epoch": 0.7731615196622973,
    "loss": 0.8707,
    "grad_norm": 3.3112633228302,
    "learning_rate": 1.9820972844279e-05
  },
  {
    "step": 1750,
    "epoch": 0.7776049766718507,
    "loss": 0.938,
    "grad_norm": 2.091076612472534,
    "learning_rate": 1.9815083028016726e-05
  },
  {
    "step": 1760,
    "epoch": 0.7820484336814041,
    "loss": 0.8132,
    "grad_norm": 1.4424912929534912,
    "learning_rate": 1.9809098792572643e-05
  },
  {
    "step": 1770,
    "epoch": 0.7864918906909576,
    "loss": 0.8463,
    "grad_norm": 0.6581863164901733,
    "learning_rate": 1.980302019551393e-05
  },
  {
    "step": 1780,
    "epoch": 0.790935347700511,
    "loss": 0.8629,
    "grad_norm": 1.0456751585006714,
    "learning_rate": 1.97968472953155e-05
  },
  {
    "step": 1790,
    "epoch": 0.7953788047100644,
    "loss": 0.954,
    "grad_norm": 1.6663379669189453,
    "learning_rate": 1.9790580151359453e-05
  },
  {
    "step": 1800,
    "epoch": 0.7998222617196179,
    "loss": 0.8514,
    "grad_norm": 0.9567673802375793,
    "learning_rate": 1.9784218823934486e-05
  },
  {
    "step": 1800,
    "epoch": 0.7998222617196179,
    "eval_loss": 0.8329846858978271,
    "eval_f1": 0.325922245683766,
    "eval_precision": 0.5099106101826661,
    "eval_recall": 0.23950346841913106,
    "eval_runtime": 41.6692,
    "eval_samples_per_second": 48.021,
    "eval_steps_per_second": 6.024
  },
  {
    "step": 1810,
    "epoch": 0.8042657187291713,
    "loss": 0.8644,
    "grad_norm": 4.029717922210693,
    "learning_rate": 1.977776337423533e-05
  },
  {
    "step": 1820,
    "epoch": 0.8087091757387247,
    "loss": 0.8214,
    "grad_norm": 1.278374195098877,
    "learning_rate": 1.9771213864362147e-05
  },
  {
    "step": 1830,
    "epoch": 0.8131526327482782,
    "loss": 0.8765,
    "grad_norm": 1.8175824880599976,
    "learning_rate": 1.9764570357319943e-05
  },
  {
    "step": 1840,
    "epoch": 0.8175960897578316,
    "loss": 0.8695,
    "grad_norm": 1.983191728591919,
    "learning_rate": 1.9757832917017957e-05
  },
  {
    "step": 1850,
    "epoch": 0.822039546767385,
    "loss": 0.8194,
    "grad_norm": 0.8904186487197876,
    "learning_rate": 1.975100160826905e-05
  },
  {
    "step": 1860,
    "epoch": 0.8264830037769385,
    "loss": 0.8306,
    "grad_norm": 0.7025706171989441,
    "learning_rate": 1.974407649678908e-05
  },
  {
    "step": 1870,
    "epoch": 0.8309264607864919,
    "loss": 0.8939,
    "grad_norm": 0.9747990369796753,
    "learning_rate": 1.9737057649196266e-05
  },
  {
    "step": 1880,
    "epoch": 0.8353699177960453,
    "loss": 0.8769,
    "grad_norm": 0.9204227328300476,
    "learning_rate": 1.972994513301055e-05
  },
  {
    "step": 1890,
    "epoch": 0.8398133748055988,
    "loss": 0.8485,
    "grad_norm": 1.8281877040863037,
    "learning_rate": 1.972273901665295e-05
  },
  {
    "step": 1900,
    "epoch": 0.8442568318151522,
    "loss": 0.8518,
    "grad_norm": 1.4212775230407715,
    "learning_rate": 1.9715439369444897e-05
  },
  {
    "step": 1900,
    "epoch": 0.8442568318151522,
    "eval_loss": 0.8269155025482178,
    "eval_f1": 0.3378128467513254,
    "eval_precision": 0.5203190277250285,
    "eval_recall": 0.25009127418765975,
    "eval_runtime": 41.7431,
    "eval_samples_per_second": 47.936,
    "eval_steps_per_second": 6.013
  },
  {
    "step": 1910,
    "epoch": 0.8487002888247056,
    "loss": 0.9196,
    "grad_norm": 4.714939594268799,
    "learning_rate": 1.9708046261607573e-05
  },
  {
    "step": 1920,
    "epoch": 0.853143745834259,
    "loss": 0.8597,
    "grad_norm": 2.507072687149048,
    "learning_rate": 1.9700559764261227e-05
  },
  {
    "step": 1930,
    "epoch": 0.8575872028438125,
    "loss": 0.8549,
    "grad_norm": 2.958371639251709,
    "learning_rate": 1.9692979949424508e-05
  },
  {
    "step": 1940,
    "epoch": 0.8620306598533659,
    "loss": 0.8442,
    "grad_norm": 0.9038152694702148,
    "learning_rate": 1.9685306890013746e-05
  },
  {
    "step": 1950,
    "epoch": 0.8664741168629193,
    "loss": 0.8115,
    "grad_norm": 0.9810814261436462,
    "learning_rate": 1.9677540659842283e-05
  },
  {
    "step": 1960,
    "epoch": 0.8709175738724728,
    "loss": 0.8691,
    "grad_norm": 1.2981270551681519,
    "learning_rate": 1.9669681333619732e-05
  },
  {
    "step": 1970,
    "epoch": 0.8753610308820262,
    "loss": 0.8675,
    "grad_norm": 1.1735295057296753,
    "learning_rate": 1.9661728986951276e-05
  },
  {
    "step": 1980,
    "epoch": 0.8798044878915796,
    "loss": 0.8429,
    "grad_norm": 0.9117563962936401,
    "learning_rate": 1.9653683696336938e-05
  },
  {
    "step": 1990,
    "epoch": 0.8842479449011331,
    "loss": 0.8908,
    "grad_norm": 2.49662184715271,
    "learning_rate": 1.964554553917084e-05
  },
  {
    "step": 2000,
    "epoch": 0.8886914019106865,
    "loss": 0.8408,
    "grad_norm": 1.0294127464294434,
    "learning_rate": 1.9637314593740468e-05
  },
  {
    "step": 2000,
    "epoch": 0.8886914019106865,
    "eval_loss": 0.8216095566749573,
    "eval_f1": 0.34842350631824315,
    "eval_precision": 0.5312383090160868,
    "eval_recall": 0.2592186929536327,
    "eval_runtime": 41.6888,
    "eval_samples_per_second": 47.999,
    "eval_steps_per_second": 6.021
  },
  {
    "step": 2010,
    "epoch": 0.8931348589202399,
    "loss": 0.8758,
    "grad_norm": 0.7628923654556274,
    "learning_rate": 1.9628990939225904e-05
  },
  {
    "step": 2020,
    "epoch": 0.8975783159297934,
    "loss": 0.9956,
    "grad_norm": 1.0243734121322632,
    "learning_rate": 1.9620574655699086e-05
  },
  {
    "step": 2030,
    "epoch": 0.9020217729393468,
    "loss": 0.8175,
    "grad_norm": 0.8542401790618896,
    "learning_rate": 1.9612065824123016e-05
  },
  {
    "step": 2040,
    "epoch": 0.9064652299489002,
    "loss": 0.8152,
    "grad_norm": 1.2667144536972046,
    "learning_rate": 1.9603464526350987e-05
  },
  {
    "step": 2050,
    "epoch": 0.9109086869584537,
    "loss": 0.8581,
    "grad_norm": 1.5387989282608032,
    "learning_rate": 1.959477084512581e-05
  },
  {
    "step": 2060,
    "epoch": 0.9153521439680071,
    "loss": 0.8409,
    "grad_norm": 1.8036596775054932,
    "learning_rate": 1.9585984864079e-05
  },
  {
    "step": 2070,
    "epoch": 0.9197956009775605,
    "loss": 0.9194,
    "grad_norm": 1.1622824668884277,
    "learning_rate": 1.957710666772997e-05
  },
  {
    "step": 2080,
    "epoch": 0.9242390579871139,
    "loss": 0.8061,
    "grad_norm": 1.3882005214691162,
    "learning_rate": 1.9568136341485244e-05
  },
  {
    "step": 2090,
    "epoch": 0.9286825149966674,
    "loss": 0.8671,
    "grad_norm": 1.9210482835769653,
    "learning_rate": 1.955907397163761e-05
  },
  {
    "step": 2100,
    "epoch": 0.9331259720062208,
    "loss": 0.9018,
    "grad_norm": 1.1803981065750122,
    "learning_rate": 1.9549919645365284e-05
  },
  {
    "step": 2100,
    "epoch": 0.9331259720062208,
    "eval_loss": 0.8174182772636414,
    "eval_f1": 0.3582125897966638,
    "eval_precision": 0.5378427787934187,
    "eval_recall": 0.26852866009492515,
    "eval_runtime": 41.6088,
    "eval_samples_per_second": 48.091,
    "eval_steps_per_second": 6.032
  },
  {
    "step": 2110,
    "epoch": 0.9375694290157742,
    "loss": 0.8699,
    "grad_norm": 1.266372561454773,
    "learning_rate": 1.954067345073111e-05
  },
  {
    "step": 2120,
    "epoch": 0.9420128860253277,
    "loss": 0.8401,
    "grad_norm": 1.18470299243927,
    "learning_rate": 1.953133547668167e-05
  },
  {
    "step": 2130,
    "epoch": 0.9464563430348811,
    "loss": 0.8099,
    "grad_norm": 1.5201101303100586,
    "learning_rate": 1.9521905813046445e-05
  },
  {
    "step": 2140,
    "epoch": 0.9508998000444345,
    "loss": 0.8318,
    "grad_norm": 1.4367315769195557,
    "learning_rate": 1.9512384550536968e-05
  },
  {
    "step": 2150,
    "epoch": 0.955343257053988,
    "loss": 0.8314,
    "grad_norm": 1.8064182996749878,
    "learning_rate": 1.9502771780745914e-05
  },
  {
    "step": 2160,
    "epoch": 0.9597867140635414,
    "loss": 0.8983,
    "grad_norm": 1.6793376207351685,
    "learning_rate": 1.949306759614626e-05
  },
  {
    "step": 2170,
    "epoch": 0.9642301710730948,
    "loss": 0.8307,
    "grad_norm": 1.7416528463363647,
    "learning_rate": 1.948327209009036e-05
  },
  {
    "step": 2180,
    "epoch": 0.9686736280826483,
    "loss": 0.8719,
    "grad_norm": 1.3810735940933228,
    "learning_rate": 1.9473385356809073e-05
  },
  {
    "step": 2190,
    "epoch": 0.9731170850922017,
    "loss": 0.8583,
    "grad_norm": 1.6549229621887207,
    "learning_rate": 1.9463407491410843e-05
  },
  {
    "step": 2200,
    "epoch": 0.9775605421017551,
    "loss": 0.8422,
    "grad_norm": 1.0912113189697266,
    "learning_rate": 1.945333858988078e-05
  },
  {
    "step": 2200,
    "epoch": 0.9775605421017551,
    "eval_loss": 0.8132801055908203,
    "eval_f1": 0.36469588442394074,
    "eval_precision": 0.5444001449800653,
    "eval_recall": 0.2741876597298284,
    "eval_runtime": 41.5811,
    "eval_samples_per_second": 48.123,
    "eval_steps_per_second": 6.036
  },
  {
    "step": 2210,
    "epoch": 0.9820039991113086,
    "loss": 0.8719,
    "grad_norm": 1.5527349710464478,
    "learning_rate": 1.9443178749079757e-05
  },
  {
    "step": 2220,
    "epoch": 0.986447456120862,
    "loss": 0.7751,
    "grad_norm": 0.999566376209259,
    "learning_rate": 1.943292806674346e-05
  },
  {
    "step": 2230,
    "epoch": 0.9908909131304154,
    "loss": 0.769,
    "grad_norm": 0.8977484107017517,
    "learning_rate": 1.9422586641481444e-05
  },
  {
    "step": 2240,
    "epoch": 0.995334370139969,
    "loss": 0.7984,
    "grad_norm": 0.7983905673027039,
    "learning_rate": 1.9412154572776203e-05
  },
  {
    "step": 2250,
    "epoch": 0.9997778271495223,
    "loss": 0.7929,
    "grad_norm": 1.4690282344818115,
    "learning_rate": 1.94016319609822e-05
  },
  {
    "step": 2260,
    "epoch": 1.003999111308598,
    "loss": 0.845,
    "grad_norm": 2.680638313293457,
    "learning_rate": 1.939101890732491e-05
  },
  {
    "step": 2270,
    "epoch": 1.0084425683181515,
    "loss": 0.8281,
    "grad_norm": 1.832972764968872,
    "learning_rate": 1.9380315513899828e-05
  },
  {
    "step": 2280,
    "epoch": 1.012886025327705,
    "loss": 0.7894,
    "grad_norm": 0.97395920753479,
    "learning_rate": 1.9369521883671516e-05
  },
  {
    "step": 2290,
    "epoch": 1.0173294823372583,
    "loss": 0.8193,
    "grad_norm": 1.4635523557662964,
    "learning_rate": 1.9358638120472587e-05
  },
  {
    "step": 2300,
    "epoch": 1.0217729393468118,
    "loss": 0.8239,
    "grad_norm": 1.0766392946243286,
    "learning_rate": 1.9347664329002714e-05
  },
  {
    "step": 2300,
    "epoch": 1.0217729393468118,
    "eval_loss": 0.8097317218780518,
    "eval_f1": 0.37563207320009634,
    "eval_precision": 0.5516265912305516,
    "eval_recall": 0.2847754654983571,
    "eval_runtime": 41.5899,
    "eval_samples_per_second": 48.113,
    "eval_steps_per_second": 6.035
  },
  {
    "step": 2310,
    "epoch": 1.0262163963563653,
    "loss": 0.8766,
    "grad_norm": 1.119211196899414,
    "learning_rate": 1.933660061482763e-05
  },
  {
    "step": 2320,
    "epoch": 1.0306598533659186,
    "loss": 0.799,
    "grad_norm": 1.332537055015564,
    "learning_rate": 1.9325447084378107e-05
  },
  {
    "step": 2330,
    "epoch": 1.035103310375472,
    "loss": 0.8817,
    "grad_norm": 1.3087962865829468,
    "learning_rate": 1.931420384494892e-05
  },
  {
    "step": 2340,
    "epoch": 1.0395467673850256,
    "loss": 0.8272,
    "grad_norm": 1.4727789163589478,
    "learning_rate": 1.9302871004697853e-05
  },
  {
    "step": 2350,
    "epoch": 1.043990224394579,
    "loss": 0.8924,
    "grad_norm": 1.189950704574585,
    "learning_rate": 1.9291448672644602e-05
  },
  {
    "step": 2360,
    "epoch": 1.0484336814041324,
    "loss": 0.8315,
    "grad_norm": 1.4594320058822632,
    "learning_rate": 1.9279936958669772e-05
  },
  {
    "step": 2370,
    "epoch": 1.052877138413686,
    "loss": 0.8544,
    "grad_norm": 1.7496724128723145,
    "learning_rate": 1.9268335973513813e-05
  },
  {
    "step": 2380,
    "epoch": 1.0573205954232392,
    "loss": 0.8419,
    "grad_norm": 1.0216785669326782,
    "learning_rate": 1.9256645828775926e-05
  },
  {
    "step": 2390,
    "epoch": 1.0617640524327927,
    "loss": 0.8099,
    "grad_norm": 1.8915684223175049,
    "learning_rate": 1.924486663691302e-05
  },
  {
    "step": 2400,
    "epoch": 1.0662075094423462,
    "loss": 0.8664,
    "grad_norm": 0.8676711916923523,
    "learning_rate": 1.9232998511238626e-05
  },
  {
    "step": 2400,
    "epoch": 1.0662075094423462,
    "eval_loss": 0.8041903376579285,
    "eval_f1": 0.3781592751549833,
    "eval_precision": 0.5450171821305841,
    "eval_recall": 0.28952172325666303,
    "eval_runtime": 42.5978,
    "eval_samples_per_second": 46.974,
    "eval_steps_per_second": 5.892
  },
  {
    "step": 2410,
    "epoch": 1.0706509664518995,
    "loss": 0.8612,
    "grad_norm": 1.4040086269378662,
    "learning_rate": 1.9221041565921797e-05
  },
  {
    "step": 2420,
    "epoch": 1.075094423461453,
    "loss": 0.8824,
    "grad_norm": 1.4394651651382446,
    "learning_rate": 1.9208995915986005e-05
  },
  {
    "step": 2430,
    "epoch": 1.0795378804710065,
    "loss": 0.9303,
    "grad_norm": 1.9644941091537476,
    "learning_rate": 1.9196861677308052e-05
  },
  {
    "step": 2440,
    "epoch": 1.0839813374805598,
    "loss": 0.8452,
    "grad_norm": 2.0008230209350586,
    "learning_rate": 1.9184638966616947e-05
  },
  {
    "step": 2450,
    "epoch": 1.0884247944901133,
    "loss": 0.8765,
    "grad_norm": 1.0160025358200073,
    "learning_rate": 1.9172327901492775e-05
  },
  {
    "step": 2460,
    "epoch": 1.0928682514996668,
    "loss": 0.8919,
    "grad_norm": 1.6044421195983887,
    "learning_rate": 1.915992860036558e-05
  },
  {
    "step": 2470,
    "epoch": 1.09731170850922,
    "loss": 0.8034,
    "grad_norm": 0.7641818523406982,
    "learning_rate": 1.9147441182514222e-05
  },
  {
    "step": 2480,
    "epoch": 1.1017551655187736,
    "loss": 0.8206,
    "grad_norm": 0.4844268262386322,
    "learning_rate": 1.9134865768065217e-05
  },
  {
    "step": 2490,
    "epoch": 1.1061986225283271,
    "loss": 0.8086,
    "grad_norm": 1.3005468845367432,
    "learning_rate": 1.9122202477991595e-05
  },
  {
    "step": 2500,
    "epoch": 1.1106420795378804,
    "loss": 0.7981,
    "grad_norm": 1.3019744157791138,
    "learning_rate": 1.9109451434111738e-05
  },
  {
    "step": 2500,
    "epoch": 1.1106420795378804,
    "eval_loss": 0.8021496534347534,
    "eval_f1": 0.3823809523809524,
    "eval_precision": 0.5496235455167693,
    "eval_recall": 0.2931726907630522,
    "eval_runtime": 42.2599,
    "eval_samples_per_second": 47.35,
    "eval_steps_per_second": 5.939
  },
  {
    "step": 2510,
    "epoch": 1.115085536547434,
    "loss": 0.7621,
    "grad_norm": 0.9291768670082092,
    "learning_rate": 1.909661275908819e-05
  },
  {
    "step": 2520,
    "epoch": 1.1195289935569874,
    "loss": 0.8357,
    "grad_norm": 1.410448431968689,
    "learning_rate": 1.9083686576426503e-05
  },
  {
    "step": 2530,
    "epoch": 1.1239724505665407,
    "loss": 0.8361,
    "grad_norm": 2.851680040359497,
    "learning_rate": 1.9070673010474033e-05
  },
  {
    "step": 2540,
    "epoch": 1.1284159075760942,
    "loss": 0.8941,
    "grad_norm": 1.0989906787872314,
    "learning_rate": 1.9057572186418737e-05
  },
  {
    "step": 2550,
    "epoch": 1.1328593645856477,
    "loss": 0.8228,
    "grad_norm": 1.440018892288208,
    "learning_rate": 1.9044384230287983e-05
  },
  {
    "step": 2560,
    "epoch": 1.137302821595201,
    "loss": 0.8976,
    "grad_norm": 2.310421943664551,
    "learning_rate": 1.9031109268947333e-05
  },
  {
    "step": 2570,
    "epoch": 1.1417462786047545,
    "loss": 0.8661,
    "grad_norm": 1.4059604406356812,
    "learning_rate": 1.9017747430099334e-05
  },
  {
    "step": 2580,
    "epoch": 1.1461897356143078,
    "loss": 0.8125,
    "grad_norm": 1.542900562286377,
    "learning_rate": 1.9004298842282253e-05
  },
  {
    "step": 2590,
    "epoch": 1.1506331926238613,
    "loss": 0.8501,
    "grad_norm": 1.2751737833023071,
    "learning_rate": 1.899076363486888e-05
  },
  {
    "step": 2600,
    "epoch": 1.1550766496334148,
    "loss": 0.8692,
    "grad_norm": 1.0184378623962402,
    "learning_rate": 1.8977141938065273e-05
  },
  {
    "step": 2600,
    "epoch": 1.1550766496334148,
    "eval_loss": 0.7976304888725281,
    "eval_f1": 0.39892811371315384,
    "eval_precision": 0.5513687600644123,
    "eval_recall": 0.31252281854691494,
    "eval_runtime": 38.0813,
    "eval_samples_per_second": 52.546,
    "eval_steps_per_second": 6.591
  },
  {
    "step": 2610,
    "epoch": 1.1595201066429683,
    "loss": 0.849,
    "grad_norm": 3.4854283332824707,
    "learning_rate": 1.8963433882909488e-05
  },
  {
    "step": 2620,
    "epoch": 1.1639635636525216,
    "loss": 0.7578,
    "grad_norm": 1.5663784742355347,
    "learning_rate": 1.8949639601270348e-05
  },
  {
    "step": 2630,
    "epoch": 1.1684070206620751,
    "loss": 0.8073,
    "grad_norm": 0.7045918703079224,
    "learning_rate": 1.8935759225846137e-05
  },
  {
    "step": 2640,
    "epoch": 1.1728504776716284,
    "loss": 0.8221,
    "grad_norm": 1.5516384840011597,
    "learning_rate": 1.892179289016336e-05
  },
  {
    "step": 2650,
    "epoch": 1.177293934681182,
    "loss": 0.829,
    "grad_norm": 1.6561391353607178,
    "learning_rate": 1.8907740728575442e-05
  },
  {
    "step": 2660,
    "epoch": 1.1817373916907354,
    "loss": 0.7836,
    "grad_norm": 1.2721800804138184,
    "learning_rate": 1.8893602876261425e-05
  },
  {
    "step": 2670,
    "epoch": 1.186180848700289,
    "loss": 0.8721,
    "grad_norm": 1.3241485357284546,
    "learning_rate": 1.88793794692247e-05
  },
  {
    "step": 2680,
    "epoch": 1.1906243057098422,
    "loss": 0.8676,
    "grad_norm": 1.8385424613952637,
    "learning_rate": 1.8865070644291652e-05
  },
  {
    "step": 2690,
    "epoch": 1.1950677627193957,
    "loss": 0.8131,
    "grad_norm": 0.8456515073776245,
    "learning_rate": 1.8850676539110386e-05
  },
  {
    "step": 2700,
    "epoch": 1.199511219728949,
    "loss": 0.806,
    "grad_norm": 1.6699109077453613,
    "learning_rate": 1.8836197292149388e-05
  },
  {
    "step": 2700,
    "epoch": 1.199511219728949,
    "eval_loss": 0.7949811816215515,
    "eval_f1": 0.41912605811027226,
    "eval_precision": 0.5612745098039216,
    "eval_recall": 0.3344286235852501,
    "eval_runtime": 38.0874,
    "eval_samples_per_second": 52.537,
    "eval_steps_per_second": 6.59
  },
  {
    "step": 2710,
    "epoch": 1.2039546767385025,
    "loss": 0.7881,
    "grad_norm": 0.8330662846565247,
    "learning_rate": 1.8821633042696183e-05
  },
  {
    "step": 2720,
    "epoch": 1.208398133748056,
    "loss": 0.779,
    "grad_norm": 1.1943204402923584,
    "learning_rate": 1.8806983930856e-05
  },
  {
    "step": 2730,
    "epoch": 1.2128415907576093,
    "loss": 0.8325,
    "grad_norm": 0.8394848108291626,
    "learning_rate": 1.8792250097550443e-05
  },
  {
    "step": 2740,
    "epoch": 1.2172850477671628,
    "loss": 0.8507,
    "grad_norm": 1.4704866409301758,
    "learning_rate": 1.877743168451611e-05
  },
  {
    "step": 2750,
    "epoch": 1.2217285047767164,
    "loss": 0.8207,
    "grad_norm": 1.2502938508987427,
    "learning_rate": 1.876252883430323e-05
  },
  {
    "step": 2760,
    "epoch": 1.2261719617862696,
    "loss": 0.8902,
    "grad_norm": 1.7260454893112183,
    "learning_rate": 1.8747541690274323e-05
  },
  {
    "step": 2770,
    "epoch": 1.2306154187958231,
    "loss": 0.8219,
    "grad_norm": 1.4131594896316528,
    "learning_rate": 1.8732470396602783e-05
  },
  {
    "step": 2780,
    "epoch": 1.2350588758053767,
    "loss": 0.7405,
    "grad_norm": 1.1974291801452637,
    "learning_rate": 1.8717315098271508e-05
  },
  {
    "step": 2790,
    "epoch": 1.23950233281493,
    "loss": 0.8234,
    "grad_norm": 1.103468418121338,
    "learning_rate": 1.8702075941071517e-05
  },
  {
    "step": 2800,
    "epoch": 1.2439457898244834,
    "loss": 0.8131,
    "grad_norm": 2.366527795791626,
    "learning_rate": 1.8686753071600522e-05
  },
  {
    "step": 2800,
    "epoch": 1.2439457898244834,
    "eval_loss": 0.7934647798538208,
    "eval_f1": 0.4317617866004963,
    "eval_precision": 0.564935064935065,
    "eval_recall": 0.3493975903614458,
    "eval_runtime": 38.1444,
    "eval_samples_per_second": 52.459,
    "eval_steps_per_second": 6.58
  },
  {
    "step": 2810,
    "epoch": 1.248389246834037,
    "loss": 0.8509,
    "grad_norm": 1.3758246898651123,
    "learning_rate": 1.867134663726153e-05
  },
  {
    "step": 2820,
    "epoch": 1.2528327038435902,
    "loss": 0.8092,
    "grad_norm": 1.9765868186950684,
    "learning_rate": 1.8655856786261432e-05
  },
  {
    "step": 2830,
    "epoch": 1.2572761608531438,
    "loss": 0.8239,
    "grad_norm": 0.6310551762580872,
    "learning_rate": 1.8640283667609575e-05
  },
  {
    "step": 2840,
    "epoch": 1.2617196178626973,
    "loss": 0.8723,
    "grad_norm": 1.4749763011932373,
    "learning_rate": 1.862462743111632e-05
  },
  {
    "step": 2850,
    "epoch": 1.2661630748722505,
    "loss": 0.8234,
    "grad_norm": 1.908955693244934,
    "learning_rate": 1.860888822739159e-05
  },
  {
    "step": 2860,
    "epoch": 1.270606531881804,
    "loss": 0.8221,
    "grad_norm": 1.1460577249526978,
    "learning_rate": 1.8593066207843468e-05
  },
  {
    "step": 2870,
    "epoch": 1.2750499888913573,
    "loss": 0.7887,
    "grad_norm": 1.0669549703598022,
    "learning_rate": 1.857716152467668e-05
  },
  {
    "step": 2880,
    "epoch": 1.2794934459009109,
    "loss": 0.8795,
    "grad_norm": 1.3095226287841797,
    "learning_rate": 1.8561174330891178e-05
  },
  {
    "step": 2890,
    "epoch": 1.2839369029104644,
    "loss": 0.8466,
    "grad_norm": 1.2424992322921753,
    "learning_rate": 1.8545104780280643e-05
  },
  {
    "step": 2900,
    "epoch": 1.2883803599200179,
    "loss": 0.8963,
    "grad_norm": 2.593909740447998,
    "learning_rate": 1.8528953027431013e-05
  },
  {
    "step": 2900,
    "epoch": 1.2883803599200179,
    "eval_loss": 0.7885923981666565,
    "eval_f1": 0.4522546419098143,
    "eval_precision": 0.573109243697479,
    "eval_recall": 0.37349397590361444,
    "eval_runtime": 38.2187,
    "eval_samples_per_second": 52.357,
    "eval_steps_per_second": 6.567
  },
  {
    "step": 2910,
    "epoch": 1.2928238169295712,
    "loss": 0.8312,
    "grad_norm": 1.7733874320983887,
    "learning_rate": 1.8512719227718992e-05
  },
  {
    "step": 2920,
    "epoch": 1.2972672739391247,
    "loss": 0.8342,
    "grad_norm": 2.8603267669677734,
    "learning_rate": 1.849640353731057e-05
  },
  {
    "step": 2930,
    "epoch": 1.301710730948678,
    "loss": 0.8105,
    "grad_norm": 1.1353833675384521,
    "learning_rate": 1.8480006113159498e-05
  },
  {
    "step": 2940,
    "epoch": 1.3061541879582315,
    "loss": 0.7397,
    "grad_norm": 1.1782138347625732,
    "learning_rate": 1.8463527113005794e-05
  },
  {
    "step": 2950,
    "epoch": 1.310597644967785,
    "loss": 0.8075,
    "grad_norm": 0.8527458310127258,
    "learning_rate": 1.844696669537422e-05
  },
  {
    "step": 2960,
    "epoch": 1.3150411019773385,
    "loss": 0.8647,
    "grad_norm": 1.0459741353988647,
    "learning_rate": 1.8430325019572763e-05
  },
  {
    "step": 2970,
    "epoch": 1.3194845589868918,
    "loss": 0.8396,
    "grad_norm": 1.491353988647461,
    "learning_rate": 1.8413602245691093e-05
  },
  {
    "step": 2980,
    "epoch": 1.3239280159964453,
    "loss": 0.8618,
    "grad_norm": 1.3013505935668945,
    "learning_rate": 1.8396798534599025e-05
  },
  {
    "step": 2990,
    "epoch": 1.3283714730059986,
    "loss": 0.8319,
    "grad_norm": 0.7281301617622375,
    "learning_rate": 1.8379914047944984e-05
  },
  {
    "step": 3000,
    "epoch": 1.332814930015552,
    "loss": 0.8496,
    "grad_norm": 1.1183629035949707,
    "learning_rate": 1.8362948948154425e-05
  },
  {
    "step": 3000,
    "epoch": 1.332814930015552,
    "eval_loss": 0.7857515215873718,
    "eval_f1": 0.4757281553398058,
    "eval_precision": 0.5814873417721519,
    "eval_recall": 0.40251916757940853,
    "eval_runtime": 38.9503,
    "eval_samples_per_second": 51.373,
    "eval_steps_per_second": 6.444
  },
  {
    "step": 3010,
    "epoch": 1.3372583870251056,
    "loss": 0.8271,
    "grad_norm": 1.4663652181625366,
    "learning_rate": 1.83459033984283e-05
  },
  {
    "step": 3020,
    "epoch": 1.341701844034659,
    "loss": 0.8665,
    "grad_norm": 0.8850257396697998,
    "learning_rate": 1.8328777562741473e-05
  },
  {
    "step": 3030,
    "epoch": 1.3461453010442124,
    "loss": 0.865,
    "grad_norm": 3.765793561935425,
    "learning_rate": 1.8311571605841132e-05
  },
  {
    "step": 3040,
    "epoch": 1.3505887580537659,
    "loss": 0.8245,
    "grad_norm": 1.3588995933532715,
    "learning_rate": 1.8294285693245223e-05
  },
  {
    "step": 3050,
    "epoch": 1.3550322150633192,
    "loss": 0.7759,
    "grad_norm": 1.6949994564056396,
    "learning_rate": 1.8276919991240852e-05
  },
  {
    "step": 3060,
    "epoch": 1.3594756720728727,
    "loss": 0.8019,
    "grad_norm": 0.8197965025901794,
    "learning_rate": 1.8259474666882676e-05
  },
  {
    "step": 3070,
    "epoch": 1.3639191290824262,
    "loss": 0.8502,
    "grad_norm": 1.4889851808547974,
    "learning_rate": 1.8241949887991313e-05
  },
  {
    "step": 3080,
    "epoch": 1.3683625860919797,
    "loss": 0.8004,
    "grad_norm": 1.305491328239441,
    "learning_rate": 1.822434582315171e-05
  },
  {
    "step": 3090,
    "epoch": 1.372806043101533,
    "loss": 0.8426,
    "grad_norm": 1.6806035041809082,
    "learning_rate": 1.8206662641711536e-05
  },
  {
    "step": 3100,
    "epoch": 1.3772495001110865,
    "loss": 0.8428,
    "grad_norm": 1.180118441581726,
    "learning_rate": 1.8188900513779538e-05
  },
  {
    "step": 3100,
    "epoch": 1.3772495001110865,
    "eval_loss": 0.7821686267852783,
    "eval_f1": 0.4782980543083173,
    "eval_precision": 0.577141382868937,
    "eval_recall": 0.4083607155896313,
    "eval_runtime": 46.51,
    "eval_samples_per_second": 43.023,
    "eval_steps_per_second": 5.397
  },
  {
    "step": 3110,
    "epoch": 1.3816929571206398,
    "loss": 0.8211,
    "grad_norm": 1.2799344062805176,
    "learning_rate": 1.8171059610223922e-05
  },
  {
    "step": 3120,
    "epoch": 1.3861364141301933,
    "loss": 0.849,
    "grad_norm": 2.517327070236206,
    "learning_rate": 1.8153140102670693e-05
  },
  {
    "step": 3130,
    "epoch": 1.3905798711397468,
    "loss": 0.8121,
    "grad_norm": 1.4918609857559204,
    "learning_rate": 1.8135142163502018e-05
  },
  {
    "step": 3140,
    "epoch": 1.3950233281493,
    "loss": 0.927,
    "grad_norm": 1.6580921411514282,
    "learning_rate": 1.811706596585455e-05
  },
  {
    "step": 3150,
    "epoch": 1.3994667851588536,
    "loss": 0.8418,
    "grad_norm": 1.5542912483215332,
    "learning_rate": 1.809891168361779e-05
  },
  {
    "step": 3160,
    "epoch": 1.403910242168407,
    "loss": 0.8402,
    "grad_norm": 1.1554553508758545,
    "learning_rate": 1.8080679491432372e-05
  },
  {
    "step": 3170,
    "epoch": 1.4083536991779604,
    "loss": 0.835,
    "grad_norm": 1.6065183877944946,
    "learning_rate": 1.806236956468844e-05
  },
  {
    "step": 3180,
    "epoch": 1.412797156187514,
    "loss": 0.8644,
    "grad_norm": 1.9069265127182007,
    "learning_rate": 1.8043982079523905e-05
  },
  {
    "step": 3190,
    "epoch": 1.4172406131970674,
    "loss": 0.8469,
    "grad_norm": 2.253533363342285,
    "learning_rate": 1.8025517212822786e-05
  },
  {
    "step": 3200,
    "epoch": 1.4216840702066207,
    "loss": 0.7904,
    "grad_norm": 2.0271425247192383,
    "learning_rate": 1.800697514221349e-05
  },
  {
    "step": 3200,
    "epoch": 1.4216840702066207,
    "eval_loss": 0.7809255719184875,
    "eval_f1": 0.47670364500792395,
    "eval_precision": 0.5658389766741911,
    "eval_recall": 0.411829134720701,
    "eval_runtime": 46.2234,
    "eval_samples_per_second": 43.29,
    "eval_steps_per_second": 5.43
  },
  {
    "step": 3210,
    "epoch": 1.4261275272161742,
    "loss": 0.8123,
    "grad_norm": 1.3303050994873047,
    "learning_rate": 1.7988356046067125e-05
  },
  {
    "step": 3220,
    "epoch": 1.4305709842257275,
    "loss": 0.8205,
    "grad_norm": 0.5793967247009277,
    "learning_rate": 1.7969660103495746e-05
  },
  {
    "step": 3230,
    "epoch": 1.435014441235281,
    "loss": 0.8,
    "grad_norm": 0.7830901145935059,
    "learning_rate": 1.795088749435068e-05
  },
  {
    "step": 3240,
    "epoch": 1.4394578982448345,
    "loss": 0.8159,
    "grad_norm": 0.9917310476303101,
    "learning_rate": 1.793203839922075e-05
  },
  {
    "step": 3250,
    "epoch": 1.443901355254388,
    "loss": 0.779,
    "grad_norm": 1.6282334327697754,
    "learning_rate": 1.7913112999430586e-05
  },
  {
    "step": 3260,
    "epoch": 1.4483448122639413,
    "loss": 0.8604,
    "grad_norm": 0.8282161951065063,
    "learning_rate": 1.7894111477038824e-05
  },
  {
    "step": 3270,
    "epoch": 1.4527882692734948,
    "loss": 0.796,
    "grad_norm": 1.1817200183868408,
    "learning_rate": 1.78750340148364e-05
  },
  {
    "step": 3280,
    "epoch": 1.457231726283048,
    "loss": 0.805,
    "grad_norm": 1.009642243385315,
    "learning_rate": 1.7855880796344776e-05
  },
  {
    "step": 3290,
    "epoch": 1.4616751832926016,
    "loss": 0.8312,
    "grad_norm": 1.985615611076355,
    "learning_rate": 1.783665200581418e-05
  },
  {
    "step": 3300,
    "epoch": 1.466118640302155,
    "loss": 0.8006,
    "grad_norm": 1.159493327140808,
    "learning_rate": 1.781734782822181e-05
  },
  {
    "step": 3300,
    "epoch": 1.466118640302155,
    "eval_loss": 0.7786352038383484,
    "eval_f1": 0.4955899138736121,
    "eval_precision": 0.5741764847319067,
    "eval_recall": 0.4359255202628697,
    "eval_runtime": 46.1045,
    "eval_samples_per_second": 43.401,
    "eval_steps_per_second": 5.444
  },
  {
    "step": 3310,
    "epoch": 1.4705620973117086,
    "loss": 0.7864,
    "grad_norm": 0.7886967658996582,
    "learning_rate": 1.779796844927009e-05
  },
  {
    "step": 3320,
    "epoch": 1.475005554321262,
    "loss": 0.7159,
    "grad_norm": 1.2627763748168945,
    "learning_rate": 1.7778514055384866e-05
  },
  {
    "step": 3330,
    "epoch": 1.4794490113308154,
    "loss": 0.8082,
    "grad_norm": 1.4315354824066162,
    "learning_rate": 1.7758984833713598e-05
  },
  {
    "step": 3340,
    "epoch": 1.4838924683403687,
    "loss": 0.7902,
    "grad_norm": 0.7648746371269226,
    "learning_rate": 1.773938097212359e-05
  },
  {
    "step": 3350,
    "epoch": 1.4883359253499222,
    "loss": 0.8175,
    "grad_norm": 0.7658151388168335,
    "learning_rate": 1.771970265920016e-05
  },
  {
    "step": 3360,
    "epoch": 1.4927793823594757,
    "loss": 0.7944,
    "grad_norm": 2.1197195053100586,
    "learning_rate": 1.7699950084244833e-05
  },
  {
    "step": 3370,
    "epoch": 1.4972228393690292,
    "loss": 0.7623,
    "grad_norm": 1.8242708444595337,
    "learning_rate": 1.7680123437273525e-05
  },
  {
    "step": 3380,
    "epoch": 1.5016662963785825,
    "loss": 0.8058,
    "grad_norm": 0.9659824967384338,
    "learning_rate": 1.766022290901471e-05
  },
  {
    "step": 3390,
    "epoch": 1.506109753388136,
    "loss": 0.816,
    "grad_norm": 1.326048731803894,
    "learning_rate": 1.7640248690907583e-05
  },
  {
    "step": 3400,
    "epoch": 1.5105532103976893,
    "loss": 0.7708,
    "grad_norm": 1.515369176864624,
    "learning_rate": 1.7620200975100213e-05
  },
  {
    "step": 3400,
    "epoch": 1.5105532103976893,
    "eval_loss": 0.7771151661872864,
    "eval_f1": 0.4991708126036484,
    "eval_precision": 0.5774580335731415,
    "eval_recall": 0.43957648776925884,
    "eval_runtime": 45.8236,
    "eval_samples_per_second": 43.667,
    "eval_steps_per_second": 5.478
  },
  {
    "step": 3410,
    "epoch": 1.5149966674072428,
    "loss": 0.8351,
    "grad_norm": 0.7137500047683716,
    "learning_rate": 1.760007995444772e-05
  },
  {
    "step": 3420,
    "epoch": 1.5194401244167963,
    "loss": 0.7803,
    "grad_norm": 1.6988321542739868,
    "learning_rate": 1.7579885822510388e-05
  },
  {
    "step": 3430,
    "epoch": 1.5238835814263498,
    "loss": 0.778,
    "grad_norm": 1.3225315809249878,
    "learning_rate": 1.7559618773551822e-05
  },
  {
    "step": 3440,
    "epoch": 1.5283270384359031,
    "loss": 0.803,
    "grad_norm": 2.3643786907196045,
    "learning_rate": 1.7539279002537076e-05
  },
  {
    "step": 3450,
    "epoch": 1.5327704954454564,
    "loss": 0.8275,
    "grad_norm": 1.6174986362457275,
    "learning_rate": 1.7518866705130778e-05
  },
  {
    "step": 3460,
    "epoch": 1.53721395245501,
    "loss": 0.8148,
    "grad_norm": 0.7952206134796143,
    "learning_rate": 1.7498382077695238e-05
  },
  {
    "step": 3470,
    "epoch": 1.5416574094645634,
    "loss": 0.8509,
    "grad_norm": 1.3976694345474243,
    "learning_rate": 1.7477825317288573e-05
  },
  {
    "step": 3480,
    "epoch": 1.546100866474117,
    "loss": 0.8015,
    "grad_norm": 1.285666823387146,
    "learning_rate": 1.7457196621662805e-05
  },
  {
    "step": 3490,
    "epoch": 1.5505443234836704,
    "loss": 0.8752,
    "grad_norm": 2.064208745956421,
    "learning_rate": 1.7436496189261954e-05
  },
  {
    "step": 3500,
    "epoch": 1.5549877804932237,
    "loss": 0.8227,
    "grad_norm": 1.0616506338119507,
    "learning_rate": 1.7415724219220135e-05
  },
  {
    "step": 3500,
    "epoch": 1.5549877804932237,
    "eval_loss": 0.7740690112113953,
    "eval_f1": 0.5120881362848109,
    "eval_precision": 0.5803468208092486,
    "eval_recall": 0.45819642205184374,
    "eval_runtime": 45.8368,
    "eval_samples_per_second": 43.655,
    "eval_steps_per_second": 5.476
  },
  {
    "step": 3510,
    "epoch": 1.559431237502777,
    "loss": 0.8366,
    "grad_norm": 1.5943564176559448,
    "learning_rate": 1.739488091135965e-05
  },
  {
    "step": 3520,
    "epoch": 1.5638746945123305,
    "loss": 0.8399,
    "grad_norm": 0.9542149901390076,
    "learning_rate": 1.7373966466189042e-05
  },
  {
    "step": 3530,
    "epoch": 1.568318151521884,
    "loss": 0.8075,
    "grad_norm": 1.7851437330245972,
    "learning_rate": 1.7352981084901195e-05
  },
  {
    "step": 3540,
    "epoch": 1.5727616085314375,
    "loss": 0.7796,
    "grad_norm": 0.8576468825340271,
    "learning_rate": 1.733192496937137e-05
  },
  {
    "step": 3550,
    "epoch": 1.577205065540991,
    "loss": 0.748,
    "grad_norm": 2.6451213359832764,
    "learning_rate": 1.73107983221553e-05
  },
  {
    "step": 3560,
    "epoch": 1.5816485225505443,
    "loss": 0.8304,
    "grad_norm": 1.615954875946045,
    "learning_rate": 1.7289601346487196e-05
  },
  {
    "step": 3570,
    "epoch": 1.5860919795600976,
    "loss": 0.7952,
    "grad_norm": 0.8043391108512878,
    "learning_rate": 1.7268334246277826e-05
  },
  {
    "step": 3580,
    "epoch": 1.5905354365696511,
    "loss": 0.8238,
    "grad_norm": 0.7913157939910889,
    "learning_rate": 1.7246997226112533e-05
  },
  {
    "step": 3590,
    "epoch": 1.5949788935792046,
    "loss": 0.7754,
    "grad_norm": 0.7436711192131042,
    "learning_rate": 1.7225590491249296e-05
  },
  {
    "step": 3600,
    "epoch": 1.5994223505887581,
    "loss": 0.829,
    "grad_norm": 2.0698509216308594,
    "learning_rate": 1.7204114247616718e-05
  },
  {
    "step": 3600,
    "epoch": 1.5994223505887581,
    "eval_loss": 0.7726098895072937,
    "eval_f1": 0.5001035840066295,
    "eval_precision": 0.5780651340996169,
    "eval_recall": 0.44067177802117563,
    "eval_runtime": 38.461,
    "eval_samples_per_second": 52.027,
    "eval_steps_per_second": 6.526
  },
  {
    "step": 3610,
    "epoch": 1.6038658075983114,
    "loss": 0.759,
    "grad_norm": 1.2007466554641724,
    "learning_rate": 1.7182568701812065e-05
  },
  {
    "step": 3620,
    "epoch": 1.608309264607865,
    "loss": 0.8016,
    "grad_norm": 0.9628830552101135,
    "learning_rate": 1.7160954061099286e-05
  },
  {
    "step": 3630,
    "epoch": 1.6127527216174182,
    "loss": 0.8072,
    "grad_norm": 2.926926374435425,
    "learning_rate": 1.7139270533407e-05
  },
  {
    "step": 3640,
    "epoch": 1.6171961786269717,
    "loss": 0.8256,
    "grad_norm": 2.3399558067321777,
    "learning_rate": 1.711751832732651e-05
  },
  {
    "step": 3650,
    "epoch": 1.6216396356365252,
    "loss": 0.7788,
    "grad_norm": 1.863483190536499,
    "learning_rate": 1.709569765210979e-05
  },
  {
    "step": 3660,
    "epoch": 1.6260830926460788,
    "loss": 0.7845,
    "grad_norm": 1.0193040370941162,
    "learning_rate": 1.707380871766747e-05
  },
  {
    "step": 3670,
    "epoch": 1.630526549655632,
    "loss": 0.8509,
    "grad_norm": 0.5900788307189941,
    "learning_rate": 1.7051851734566827e-05
  },
  {
    "step": 3680,
    "epoch": 1.6349700066651855,
    "loss": 0.8118,
    "grad_norm": 1.5523656606674194,
    "learning_rate": 1.7029826914029752e-05
  },
  {
    "step": 3690,
    "epoch": 1.6394134636747388,
    "loss": 0.7505,
    "grad_norm": 1.296441674232483,
    "learning_rate": 1.7007734467930717e-05
  },
  {
    "step": 3700,
    "epoch": 1.6438569206842923,
    "loss": 0.8476,
    "grad_norm": 1.7130337953567505,
    "learning_rate": 1.6985574608794734e-05
  },
  {
    "step": 3700,
    "epoch": 1.6438569206842923,
    "eval_loss": 0.7716782689094543,
    "eval_f1": 0.5079201810327093,
    "eval_precision": 0.5817624882186616,
    "eval_recall": 0.45071193866374587,
    "eval_runtime": 38.6947,
    "eval_samples_per_second": 51.713,
    "eval_steps_per_second": 6.487
  },
  {
    "step": 3710,
    "epoch": 1.6483003776938459,
    "loss": 0.7854,
    "grad_norm": 1.0480161905288696,
    "learning_rate": 1.6963347549795326e-05
  },
  {
    "step": 3720,
    "epoch": 1.6527438347033994,
    "loss": 0.7589,
    "grad_norm": 0.9115371108055115,
    "learning_rate": 1.6941053504752457e-05
  },
  {
    "step": 3730,
    "epoch": 1.6571872917129526,
    "loss": 0.7882,
    "grad_norm": 0.6631249785423279,
    "learning_rate": 1.6918692688130484e-05
  },
  {
    "step": 3740,
    "epoch": 1.6616307487225062,
    "loss": 0.7628,
    "grad_norm": 1.2228569984436035,
    "learning_rate": 1.68962653150361e-05
  },
  {
    "step": 3750,
    "epoch": 1.6660742057320594,
    "loss": 0.7657,
    "grad_norm": 0.8250324130058289,
    "learning_rate": 1.6873771601216253e-05
  },
  {
    "step": 3760,
    "epoch": 1.670517662741613,
    "loss": 0.885,
    "grad_norm": 2.720008134841919,
    "learning_rate": 1.6851211763056074e-05
  },
  {
    "step": 3770,
    "epoch": 1.6749611197511665,
    "loss": 0.7951,
    "grad_norm": 1.2004903554916382,
    "learning_rate": 1.68285860175768e-05
  },
  {
    "step": 3780,
    "epoch": 1.67940457676072,
    "loss": 0.8036,
    "grad_norm": 0.5355662107467651,
    "learning_rate": 1.6805894582433686e-05
  },
  {
    "step": 3790,
    "epoch": 1.6838480337702733,
    "loss": 0.8382,
    "grad_norm": 0.8759582042694092,
    "learning_rate": 1.6783137675913908e-05
  },
  {
    "step": 3800,
    "epoch": 1.6882914907798265,
    "loss": 0.8079,
    "grad_norm": 1.3903931379318237,
    "learning_rate": 1.6760315516934457e-05
  },
  {
    "step": 3800,
    "epoch": 1.6882914907798265,
    "eval_loss": 0.7694268226623535,
    "eval_f1": 0.5225152943536255,
    "eval_precision": 0.5797907856665925,
    "eval_recall": 0.4755385177071924,
    "eval_runtime": 38.4446,
    "eval_samples_per_second": 52.049,
    "eval_steps_per_second": 6.529
  },
  {
    "step": 3810,
    "epoch": 1.69273494778938,
    "loss": 0.7562,
    "grad_norm": 0.7769196629524231,
    "learning_rate": 1.6737428325040047e-05
  },
  {
    "step": 3820,
    "epoch": 1.6971784047989336,
    "loss": 0.8289,
    "grad_norm": 1.6770073175430298,
    "learning_rate": 1.6714476320401002e-05
  },
  {
    "step": 3830,
    "epoch": 1.701621861808487,
    "loss": 0.7764,
    "grad_norm": 2.114057779312134,
    "learning_rate": 1.6691459723811113e-05
  },
  {
    "step": 3840,
    "epoch": 1.7060653188180406,
    "loss": 0.8138,
    "grad_norm": 1.3652030229568481,
    "learning_rate": 1.6668378756685544e-05
  },
  {
    "step": 3850,
    "epoch": 1.7105087758275939,
    "loss": 0.8107,
    "grad_norm": 0.8417023420333862,
    "learning_rate": 1.66452336410587e-05
  },
  {
    "step": 3860,
    "epoch": 1.7149522328371472,
    "loss": 0.8362,
    "grad_norm": 1.5937058925628662,
    "learning_rate": 1.6622024599582063e-05
  },
  {
    "step": 3870,
    "epoch": 1.7193956898467007,
    "loss": 0.8344,
    "grad_norm": 1.7252392768859863,
    "learning_rate": 1.659875185552209e-05
  },
  {
    "step": 3880,
    "epoch": 1.7238391468562542,
    "loss": 0.8151,
    "grad_norm": 1.9148287773132324,
    "learning_rate": 1.6575415632758028e-05
  },
  {
    "step": 3890,
    "epoch": 1.7282826038658077,
    "loss": 0.7776,
    "grad_norm": 1.1884320974349976,
    "learning_rate": 1.655201615577978e-05
  },
  {
    "step": 3900,
    "epoch": 1.7327260608753612,
    "loss": 0.7722,
    "grad_norm": 0.7878916263580322,
    "learning_rate": 1.6528553649685747e-05
  },
  {
    "step": 3900,
    "epoch": 1.7327260608753612,
    "eval_loss": 0.7691347002983093,
    "eval_f1": 0.517489607624455,
    "eval_precision": 0.5819840364880273,
    "eval_recall": 0.46586345381526106,
    "eval_runtime": 39.0874,
    "eval_samples_per_second": 51.193,
    "eval_steps_per_second": 6.422
  },
  {
    "step": 3910,
    "epoch": 1.7371695178849145,
    "loss": 0.7669,
    "grad_norm": 1.727759838104248,
    "learning_rate": 1.6505028340180655e-05
  },
  {
    "step": 3920,
    "epoch": 1.7416129748944678,
    "loss": 0.8305,
    "grad_norm": 1.0696102380752563,
    "learning_rate": 1.6481440453573384e-05
  },
  {
    "step": 3930,
    "epoch": 1.7460564319040213,
    "loss": 0.7845,
    "grad_norm": 1.480521321296692,
    "learning_rate": 1.6457790216774806e-05
  },
  {
    "step": 3940,
    "epoch": 1.7504998889135748,
    "loss": 0.7935,
    "grad_norm": 0.7958292961120605,
    "learning_rate": 1.6434077857295567e-05
  },
  {
    "step": 3950,
    "epoch": 1.7549433459231283,
    "loss": 0.7747,
    "grad_norm": 1.2830370664596558,
    "learning_rate": 1.6410303603243942e-05
  },
  {
    "step": 3960,
    "epoch": 1.7593868029326818,
    "loss": 0.8794,
    "grad_norm": 1.820063591003418,
    "learning_rate": 1.6386467683323613e-05
  },
  {
    "step": 3970,
    "epoch": 1.763830259942235,
    "loss": 0.7914,
    "grad_norm": 0.48322272300720215,
    "learning_rate": 1.6362570326831467e-05
  },
  {
    "step": 3980,
    "epoch": 1.7682737169517884,
    "loss": 0.7708,
    "grad_norm": 1.0422401428222656,
    "learning_rate": 1.6338611763655415e-05
  },
  {
    "step": 3990,
    "epoch": 1.7727171739613419,
    "loss": 0.7861,
    "grad_norm": 0.6640618443489075,
    "learning_rate": 1.631459222427215e-05
  },
  {
    "step": 4000,
    "epoch": 1.7771606309708954,
    "loss": 0.8879,
    "grad_norm": 1.1101360321044922,
    "learning_rate": 1.6290511939744948e-05
  },
  {
    "step": 4000,
    "epoch": 1.7771606309708954,
    "eval_loss": 0.766865611076355,
    "eval_f1": 0.5206477732793522,
    "eval_precision": 0.5842798727850976,
    "eval_recall": 0.4695144213216502,
    "eval_runtime": 41.5658,
    "eval_samples_per_second": 48.141,
    "eval_steps_per_second": 6.039
  },
  {
    "step": 4010,
    "epoch": 1.781604087980449,
    "loss": 0.8088,
    "grad_norm": 1.8772413730621338,
    "learning_rate": 1.6266371141721448e-05
  },
  {
    "step": 4020,
    "epoch": 1.7860475449900022,
    "loss": 0.8354,
    "grad_norm": 0.9397031664848328,
    "learning_rate": 1.624217006243141e-05
  },
  {
    "step": 4030,
    "epoch": 1.7904910019995557,
    "loss": 0.8472,
    "grad_norm": 1.301393747329712,
    "learning_rate": 1.6217908934684494e-05
  },
  {
    "step": 4040,
    "epoch": 1.794934459009109,
    "loss": 0.8455,
    "grad_norm": 0.9960203766822815,
    "learning_rate": 1.6193587991868003e-05
  },
  {
    "step": 4050,
    "epoch": 1.7993779160186625,
    "loss": 0.7794,
    "grad_norm": 0.9751725196838379,
    "learning_rate": 1.6169207467944663e-05
  },
  {
    "step": 4060,
    "epoch": 1.803821373028216,
    "loss": 0.8103,
    "grad_norm": 1.0209437608718872,
    "learning_rate": 1.6144767597450354e-05
  },
  {
    "step": 4070,
    "epoch": 1.8082648300377695,
    "loss": 0.839,
    "grad_norm": 2.611973762512207,
    "learning_rate": 1.612026861549185e-05
  },
  {
    "step": 4080,
    "epoch": 1.8127082870473228,
    "loss": 0.7783,
    "grad_norm": 1.2113423347473145,
    "learning_rate": 1.6095710757744575e-05
  },
  {
    "step": 4090,
    "epoch": 1.8171517440568763,
    "loss": 0.7813,
    "grad_norm": 1.0057594776153564,
    "learning_rate": 1.607109426045033e-05
  },
  {
    "step": 4100,
    "epoch": 1.8215952010664296,
    "loss": 0.7643,
    "grad_norm": 1.1477739810943604,
    "learning_rate": 1.6046419360415e-05
  },
  {
    "step": 4100,
    "epoch": 1.8215952010664296,
    "eval_loss": 0.7646351456642151,
    "eval_f1": 0.5311285984659828,
    "eval_precision": 0.5845209383907038,
    "eval_recall": 0.48667396860167944,
    "eval_runtime": 46.2602,
    "eval_samples_per_second": 43.255,
    "eval_steps_per_second": 5.426
  },
  {
    "step": 4110,
    "epoch": 1.826038658075983,
    "loss": 0.7897,
    "grad_norm": 1.9505479335784912,
    "learning_rate": 1.6021686295006317e-05
  },
  {
    "step": 4120,
    "epoch": 1.8304821150855366,
    "loss": 0.7882,
    "grad_norm": 1.0066508054733276,
    "learning_rate": 1.5996895302151535e-05
  },
  {
    "step": 4130,
    "epoch": 1.83492557209509,
    "loss": 0.7927,
    "grad_norm": 1.2792397737503052,
    "learning_rate": 1.5972046620335158e-05
  },
  {
    "step": 4140,
    "epoch": 1.8393690291046434,
    "loss": 0.7814,
    "grad_norm": 0.8292211890220642,
    "learning_rate": 1.594714048859666e-05
  },
  {
    "step": 4150,
    "epoch": 1.8438124861141967,
    "loss": 0.7874,
    "grad_norm": 1.5904734134674072,
    "learning_rate": 1.592217714652816e-05
  },
  {
    "step": 4160,
    "epoch": 1.8482559431237502,
    "loss": 0.7786,
    "grad_norm": 1.0893356800079346,
    "learning_rate": 1.5897156834272132e-05
  },
  {
    "step": 4170,
    "epoch": 1.8526994001333037,
    "loss": 0.7839,
    "grad_norm": 1.6305731534957886,
    "learning_rate": 1.5872079792519095e-05
  },
  {
    "step": 4180,
    "epoch": 1.8571428571428572,
    "loss": 0.8194,
    "grad_norm": 1.0052464008331299,
    "learning_rate": 1.5846946262505293e-05
  },
  {
    "step": 4190,
    "epoch": 1.8615863141524107,
    "loss": 0.7475,
    "grad_norm": 0.7298591136932373,
    "learning_rate": 1.582175648601038e-05
  },
  {
    "step": 4200,
    "epoch": 1.866029771161964,
    "loss": 0.811,
    "grad_norm": 0.6748696565628052,
    "learning_rate": 1.5796510705355077e-05
  },
  {
    "step": 4200,
    "epoch": 1.866029771161964,
    "eval_loss": 0.7647007703781128,
    "eval_f1": 0.5321777246463439,
    "eval_precision": 0.5857456140350877,
    "eval_recall": 0.48758671047827673,
    "eval_runtime": 46.0098,
    "eval_samples_per_second": 43.491,
    "eval_steps_per_second": 5.455
  },
  {
    "step": 4210,
    "epoch": 1.8704732281715173,
    "loss": 0.7938,
    "grad_norm": 1.551985502243042,
    "learning_rate": 1.5771209163398873e-05
  },
  {
    "step": 4220,
    "epoch": 1.8749166851810708,
    "loss": 0.7848,
    "grad_norm": 1.1744698286056519,
    "learning_rate": 1.5745852103537655e-05
  },
  {
    "step": 4230,
    "epoch": 1.8793601421906243,
    "loss": 0.8155,
    "grad_norm": 0.6469829082489014,
    "learning_rate": 1.5720439769701387e-05
  },
  {
    "step": 4240,
    "epoch": 1.8838035992001778,
    "loss": 0.8296,
    "grad_norm": 0.9390968680381775,
    "learning_rate": 1.5694972406351756e-05
  },
  {
    "step": 4250,
    "epoch": 1.8882470562097313,
    "loss": 0.8017,
    "grad_norm": 1.5381356477737427,
    "learning_rate": 1.5669450258479825e-05
  },
  {
    "step": 4260,
    "epoch": 1.8926905132192846,
    "loss": 0.7663,
    "grad_norm": 1.5151071548461914,
    "learning_rate": 1.5643873571603675e-05
  },
  {
    "step": 4270,
    "epoch": 1.897133970228838,
    "loss": 0.8147,
    "grad_norm": 1.508694052696228,
    "learning_rate": 1.5618242591766037e-05
  },
  {
    "step": 4280,
    "epoch": 1.9015774272383914,
    "loss": 0.8481,
    "grad_norm": 1.5507845878601074,
    "learning_rate": 1.5592557565531928e-05
  },
  {
    "step": 4290,
    "epoch": 1.906020884247945,
    "loss": 0.7938,
    "grad_norm": 1.618775725364685,
    "learning_rate": 1.5566818739986286e-05
  },
  {
    "step": 4300,
    "epoch": 1.9104643412574984,
    "loss": 0.8058,
    "grad_norm": 1.7165189981460571,
    "learning_rate": 1.5541026362731587e-05
  },
  {
    "step": 4300,
    "epoch": 1.9104643412574984,
    "eval_loss": 0.7623825073242188,
    "eval_f1": 0.5455252162083374,
    "eval_precision": 0.58321213380428,
    "eval_recall": 0.5124132895217233,
    "eval_runtime": 45.9612,
    "eval_samples_per_second": 43.537,
    "eval_steps_per_second": 5.461
  },
  {
    "step": 4310,
    "epoch": 1.914907798267052,
    "loss": 0.8111,
    "grad_norm": 1.3952852487564087,
    "learning_rate": 1.5515180681885462e-05
  },
  {
    "step": 4320,
    "epoch": 1.9193512552766052,
    "loss": 0.8227,
    "grad_norm": 1.5845743417739868,
    "learning_rate": 1.5489281946078308e-05
  },
  {
    "step": 4330,
    "epoch": 1.9237947122861585,
    "loss": 0.7305,
    "grad_norm": 1.1641415357589722,
    "learning_rate": 1.5463330404450914e-05
  },
  {
    "step": 4340,
    "epoch": 1.928238169295712,
    "loss": 0.8102,
    "grad_norm": 1.5547406673431396,
    "learning_rate": 1.543732630665204e-05
  },
  {
    "step": 4350,
    "epoch": 1.9326816263052655,
    "loss": 0.8202,
    "grad_norm": 1.0080195665359497,
    "learning_rate": 1.5411269902836025e-05
  },
  {
    "step": 4360,
    "epoch": 1.937125083314819,
    "loss": 0.8293,
    "grad_norm": 1.530392050743103,
    "learning_rate": 1.5385161443660384e-05
  },
  {
    "step": 4370,
    "epoch": 1.9415685403243723,
    "loss": 0.81,
    "grad_norm": 1.2210091352462769,
    "learning_rate": 1.53590011802834e-05
  },
  {
    "step": 4380,
    "epoch": 1.9460119973339258,
    "loss": 0.7956,
    "grad_norm": 0.7932589054107666,
    "learning_rate": 1.5332789364361695e-05
  },
  {
    "step": 4390,
    "epoch": 1.9504554543434791,
    "loss": 0.8176,
    "grad_norm": 1.0656752586364746,
    "learning_rate": 1.5306526248047813e-05
  },
  {
    "step": 4400,
    "epoch": 1.9548989113530326,
    "loss": 0.8241,
    "grad_norm": 0.7248679995536804,
    "learning_rate": 1.5280212083987812e-05
  },
  {
    "step": 4400,
    "epoch": 1.9548989113530326,
    "eval_loss": 0.7606831192970276,
    "eval_f1": 0.5424459022814061,
    "eval_precision": 0.5850052798310454,
    "eval_recall": 0.5056589996349032,
    "eval_runtime": 45.8264,
    "eval_samples_per_second": 43.665,
    "eval_steps_per_second": 5.477
  },
  {
    "step": 4410,
    "epoch": 1.9593423683625861,
    "loss": 0.7749,
    "grad_norm": 0.8571043610572815,
    "learning_rate": 1.525384712531881e-05
  },
  {
    "step": 4420,
    "epoch": 1.9637858253721396,
    "loss": 0.8144,
    "grad_norm": 2.2943811416625977,
    "learning_rate": 1.5227431625666557e-05
  },
  {
    "step": 4430,
    "epoch": 1.968229282381693,
    "loss": 0.7358,
    "grad_norm": 1.6299054622650146,
    "learning_rate": 1.5200965839143003e-05
  },
  {
    "step": 4440,
    "epoch": 1.9726727393912464,
    "loss": 0.8165,
    "grad_norm": 3.0016462802886963,
    "learning_rate": 1.5174450020343843e-05
  },
  {
    "step": 4450,
    "epoch": 1.9771161964007997,
    "loss": 0.8429,
    "grad_norm": 1.6530331373214722,
    "learning_rate": 1.514788442434608e-05
  },
  {
    "step": 4460,
    "epoch": 1.9815596534103532,
    "loss": 0.8155,
    "grad_norm": 0.9891660213470459,
    "learning_rate": 1.5121269306705552e-05
  },
  {
    "step": 4470,
    "epoch": 1.9860031104199067,
    "loss": 0.8307,
    "grad_norm": 0.9447828531265259,
    "learning_rate": 1.5094604923454501e-05
  },
  {
    "step": 4480,
    "epoch": 1.9904465674294602,
    "loss": 0.7863,
    "grad_norm": 1.3083653450012207,
    "learning_rate": 1.5067891531099078e-05
  },
  {
    "step": 4490,
    "epoch": 1.9948900244390135,
    "loss": 0.8304,
    "grad_norm": 1.6302423477172852,
    "learning_rate": 1.5041129386616905e-05
  },
  {
    "step": 4500,
    "epoch": 1.999333481448567,
    "loss": 0.7675,
    "grad_norm": 1.201593041419983,
    "learning_rate": 1.5014318747454586e-05
  },
  {
    "step": 4500,
    "epoch": 1.999333481448567,
    "eval_loss": 0.7598885893821716,
    "eval_f1": 0.5543331403204014,
    "eval_precision": 0.588042588042588,
    "eval_recall": 0.5242789339174881,
    "eval_runtime": 45.9679,
    "eval_samples_per_second": 43.53,
    "eval_steps_per_second": 5.46
  },
  {
    "step": 4510,
    "epoch": 2.003554765607643,
    "loss": 0.7656,
    "grad_norm": 2.01916766166687,
    "learning_rate": 1.498745987152523e-05
  },
  {
    "step": 4520,
    "epoch": 2.007998222617196,
    "loss": 0.7426,
    "grad_norm": 0.387290358543396,
    "learning_rate": 1.496055301720598e-05
  },
  {
    "step": 4530,
    "epoch": 2.0124416796267495,
    "loss": 0.7936,
    "grad_norm": 1.6806267499923706,
    "learning_rate": 1.493359844333552e-05
  },
  {
    "step": 4540,
    "epoch": 2.016885136636303,
    "loss": 0.7687,
    "grad_norm": 1.2028099298477173,
    "learning_rate": 1.4906596409211584e-05
  },
  {
    "step": 4550,
    "epoch": 2.0213285936458565,
    "loss": 0.8016,
    "grad_norm": 1.2325419187545776,
    "learning_rate": 1.4879547174588467e-05
  },
  {
    "step": 4560,
    "epoch": 2.02577205065541,
    "loss": 0.8337,
    "grad_norm": 0.8894459009170532,
    "learning_rate": 1.4852450999674526e-05
  },
  {
    "step": 4570,
    "epoch": 2.0302155076649635,
    "loss": 0.8096,
    "grad_norm": 0.7720032930374146,
    "learning_rate": 1.4825308145129668e-05
  },
  {
    "step": 4580,
    "epoch": 2.0346589646745166,
    "loss": 0.8058,
    "grad_norm": 0.8804692625999451,
    "learning_rate": 1.4798118872062856e-05
  },
  {
    "step": 4590,
    "epoch": 2.03910242168407,
    "loss": 0.7469,
    "grad_norm": 0.9615058302879333,
    "learning_rate": 1.4770883442029586e-05
  },
  {
    "step": 4600,
    "epoch": 2.0435458786936236,
    "loss": 0.7903,
    "grad_norm": 1.2345083951950073,
    "learning_rate": 1.4743602117029376e-05
  },
  {
    "step": 4600,
    "epoch": 2.0435458786936236,
    "eval_loss": 0.7597180604934692,
    "eval_f1": 0.5476586176556848,
    "eval_precision": 0.5895600926120816,
    "eval_recall": 0.5113179992698065,
    "eval_runtime": 43.617,
    "eval_samples_per_second": 45.877,
    "eval_steps_per_second": 5.755
  },
  {
    "step": 4610,
    "epoch": 2.047989335703177,
    "loss": 0.8271,
    "grad_norm": 1.0996602773666382,
    "learning_rate": 1.4716275159503241e-05
  },
  {
    "step": 4620,
    "epoch": 2.0524327927127306,
    "loss": 0.8438,
    "grad_norm": 1.9352891445159912,
    "learning_rate": 1.4688902832331182e-05
  },
  {
    "step": 4630,
    "epoch": 2.056876249722284,
    "loss": 0.7994,
    "grad_norm": 0.8316235542297363,
    "learning_rate": 1.4661485398829633e-05
  },
  {
    "step": 4640,
    "epoch": 2.061319706731837,
    "loss": 0.8165,
    "grad_norm": 0.7239857912063599,
    "learning_rate": 1.4634023122748952e-05
  },
  {
    "step": 4650,
    "epoch": 2.0657631637413907,
    "loss": 0.7467,
    "grad_norm": 0.6142390966415405,
    "learning_rate": 1.4606516268270874e-05
  },
  {
    "step": 4660,
    "epoch": 2.070206620750944,
    "loss": 0.756,
    "grad_norm": 1.7615573406219482,
    "learning_rate": 1.4578965100005965e-05
  },
  {
    "step": 4670,
    "epoch": 2.0746500777604977,
    "loss": 0.8472,
    "grad_norm": 1.126076579093933,
    "learning_rate": 1.455136988299108e-05
  },
  {
    "step": 4680,
    "epoch": 2.079093534770051,
    "loss": 0.7398,
    "grad_norm": 1.845129132270813,
    "learning_rate": 1.4523730882686824e-05
  },
  {
    "step": 4690,
    "epoch": 2.0835369917796047,
    "loss": 0.8657,
    "grad_norm": 1.8077778816223145,
    "learning_rate": 1.4496048364974977e-05
  },
  {
    "step": 4700,
    "epoch": 2.087980448789158,
    "loss": 0.7822,
    "grad_norm": 1.7686042785644531,
    "learning_rate": 1.4468322596155954e-05
  },
  {
    "step": 4700,
    "epoch": 2.087980448789158,
    "eval_loss": 0.7572851777076721,
    "eval_f1": 0.5601775890358074,
    "eval_precision": 0.594306778619701,
    "eval_recall": 0.5297553851770719,
    "eval_runtime": 39.6073,
    "eval_samples_per_second": 50.521,
    "eval_steps_per_second": 6.337
  },
  {
    "step": 4710,
    "epoch": 2.0924239057987113,
    "loss": 0.7714,
    "grad_norm": 1.6093183755874634,
    "learning_rate": 1.4440553842946237e-05
  },
  {
    "step": 4720,
    "epoch": 2.096867362808265,
    "loss": 0.7687,
    "grad_norm": 0.9539095163345337,
    "learning_rate": 1.4412742372475808e-05
  },
  {
    "step": 4730,
    "epoch": 2.1013108198178183,
    "loss": 0.7588,
    "grad_norm": 1.3378993272781372,
    "learning_rate": 1.4384888452285577e-05
  },
  {
    "step": 4740,
    "epoch": 2.105754276827372,
    "loss": 0.8173,
    "grad_norm": 0.620913565158844,
    "learning_rate": 1.4356992350324824e-05
  },
  {
    "step": 4750,
    "epoch": 2.1101977338369253,
    "loss": 0.7623,
    "grad_norm": 1.15662682056427,
    "learning_rate": 1.4329054334948595e-05
  },
  {
    "step": 4760,
    "epoch": 2.1146411908464784,
    "loss": 0.8072,
    "grad_norm": 1.6490437984466553,
    "learning_rate": 1.4301074674915148e-05
  },
  {
    "step": 4770,
    "epoch": 2.119084647856032,
    "loss": 0.8001,
    "grad_norm": 1.3423213958740234,
    "learning_rate": 1.4273053639383342e-05
  },
  {
    "step": 4780,
    "epoch": 2.1235281048655854,
    "loss": 0.7991,
    "grad_norm": 0.8000847101211548,
    "learning_rate": 1.424499149791007e-05
  },
  {
    "step": 4790,
    "epoch": 2.127971561875139,
    "loss": 0.7725,
    "grad_norm": 1.452755331993103,
    "learning_rate": 1.421688852044765e-05
  },
  {
    "step": 4800,
    "epoch": 2.1324150188846924,
    "loss": 0.7833,
    "grad_norm": 1.4590728282928467,
    "learning_rate": 1.4188744977341235e-05
  },
  {
    "step": 4800,
    "epoch": 2.1324150188846924,
    "eval_loss": 0.7560269832611084,
    "eval_f1": 0.5587532268859356,
    "eval_precision": 0.586629190925517,
    "eval_recall": 0.5334063526834611,
    "eval_runtime": 41.202,
    "eval_samples_per_second": 48.566,
    "eval_steps_per_second": 6.092
  },
  {
    "step": 4810,
    "epoch": 2.136858475894246,
    "loss": 0.7462,
    "grad_norm": 1.4436988830566406,
    "learning_rate": 1.4160561139326216e-05
  },
  {
    "step": 4820,
    "epoch": 2.141301932903799,
    "loss": 0.7831,
    "grad_norm": 1.3336472511291504,
    "learning_rate": 1.4132337277525613e-05
  },
  {
    "step": 4830,
    "epoch": 2.1457453899133525,
    "loss": 0.7665,
    "grad_norm": 1.0578246116638184,
    "learning_rate": 1.4104073663447459e-05
  },
  {
    "step": 4840,
    "epoch": 2.150188846922906,
    "loss": 0.7321,
    "grad_norm": 0.7688273787498474,
    "learning_rate": 1.4075770568982208e-05
  },
  {
    "step": 4850,
    "epoch": 2.1546323039324595,
    "loss": 0.7604,
    "grad_norm": 0.8582286238670349,
    "learning_rate": 1.4047428266400092e-05
  },
  {
    "step": 4860,
    "epoch": 2.159075760942013,
    "loss": 0.7902,
    "grad_norm": 1.2300498485565186,
    "learning_rate": 1.4019047028348532e-05
  },
  {
    "step": 4870,
    "epoch": 2.163519217951566,
    "loss": 0.8258,
    "grad_norm": 1.245930552482605,
    "learning_rate": 1.3990627127849496e-05
  },
  {
    "step": 4880,
    "epoch": 2.1679626749611196,
    "loss": 0.7961,
    "grad_norm": 0.6462326049804688,
    "learning_rate": 1.3962168838296872e-05
  },
  {
    "step": 4890,
    "epoch": 2.172406131970673,
    "loss": 0.7989,
    "grad_norm": 1.3211159706115723,
    "learning_rate": 1.393367243345385e-05
  },
  {
    "step": 4900,
    "epoch": 2.1768495889802266,
    "loss": 0.7757,
    "grad_norm": 1.3109008073806763,
    "learning_rate": 1.3905138187450277e-05
  },
  {
    "step": 4900,
    "epoch": 2.1768495889802266,
    "eval_loss": 0.7554078698158264,
    "eval_f1": 0.5554283533676779,
    "eval_precision": 0.5817346123101519,
    "eval_recall": 0.5313983205549471,
    "eval_runtime": 41.849,
    "eval_samples_per_second": 47.815,
    "eval_steps_per_second": 5.998
  },
  {
    "step": 4910,
    "epoch": 2.18129304598978,
    "loss": 0.8174,
    "grad_norm": 1.6845794916152954,
    "learning_rate": 1.3876566374780033e-05
  },
  {
    "step": 4920,
    "epoch": 2.1857365029993336,
    "loss": 0.7899,
    "grad_norm": 0.8763622045516968,
    "learning_rate": 1.3847957270298374e-05
  },
  {
    "step": 4930,
    "epoch": 2.1901799600088867,
    "loss": 0.7799,
    "grad_norm": 1.3271288871765137,
    "learning_rate": 1.381931114921929e-05
  },
  {
    "step": 4940,
    "epoch": 2.19462341701844,
    "loss": 0.809,
    "grad_norm": 1.3978753089904785,
    "learning_rate": 1.379062828711288e-05
  },
  {
    "step": 4950,
    "epoch": 2.1990668740279937,
    "loss": 0.8766,
    "grad_norm": 1.1368576288223267,
    "learning_rate": 1.3761908959902667e-05
  },
  {
    "step": 4960,
    "epoch": 2.2035103310375472,
    "loss": 0.7984,
    "grad_norm": 1.542711853981018,
    "learning_rate": 1.3733153443862982e-05
  },
  {
    "step": 4970,
    "epoch": 2.2079537880471007,
    "loss": 0.8032,
    "grad_norm": 0.9348105788230896,
    "learning_rate": 1.370436201561626e-05
  },
  {
    "step": 4980,
    "epoch": 2.2123972450566542,
    "loss": 0.7882,
    "grad_norm": 1.7396490573883057,
    "learning_rate": 1.3675534952130423e-05
  },
  {
    "step": 4990,
    "epoch": 2.2168407020662073,
    "loss": 0.7704,
    "grad_norm": 0.8747305274009705,
    "learning_rate": 1.3646672530716197e-05
  },
  {
    "step": 5000,
    "epoch": 2.221284159075761,
    "loss": 0.8372,
    "grad_norm": 0.7445057034492493,
    "learning_rate": 1.361777502902443e-05
  },
  {
    "step": 5000,
    "epoch": 2.221284159075761,
    "eval_loss": 0.755267858505249,
    "eval_f1": 0.5569717297556301,
    "eval_precision": 0.586241678434537,
    "eval_recall": 0.5304855786783498,
    "eval_runtime": 47.0656,
    "eval_samples_per_second": 42.515,
    "eval_steps_per_second": 5.333
  },
  {
    "step": 5000,
    "epoch": 2.221284159075761,
    "train_runtime": 3322.1231,
    "train_samples_per_second": 27.096,
    "train_steps_per_second": 3.388,
    "total_flos": 2.818295633392128e+16,
    "train_loss": 1.1445852293968202
  }
]