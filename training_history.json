[
  {
    "step": 10,
    "epoch": 0.006091989034419738,
    "loss": 2.9445,
    "grad_norm": 18.662139892578125,
    "learning_rate": 1.94884287454324e-07
  },
  {
    "step": 20,
    "epoch": 0.012183978068839476,
    "loss": 2.9356,
    "grad_norm": 15.001505851745605,
    "learning_rate": 4.38489646772229e-07
  },
  {
    "step": 30,
    "epoch": 0.018275967103259214,
    "loss": 2.9282,
    "grad_norm": 15.573018074035645,
    "learning_rate": 6.82095006090134e-07
  },
  {
    "step": 40,
    "epoch": 0.02436795613767895,
    "loss": 2.9333,
    "grad_norm": 14.322751998901367,
    "learning_rate": 9.25700365408039e-07
  },
  {
    "step": 50,
    "epoch": 0.03045994517209869,
    "loss": 2.9056,
    "grad_norm": 20.554061889648438,
    "learning_rate": 1.169305724725944e-06
  },
  {
    "step": 60,
    "epoch": 0.03655193420651843,
    "loss": 2.9072,
    "grad_norm": 14.495504379272461,
    "learning_rate": 1.412911084043849e-06
  },
  {
    "step": 70,
    "epoch": 0.042643923240938165,
    "loss": 2.9011,
    "grad_norm": 13.865497589111328,
    "learning_rate": 1.6565164433617542e-06
  },
  {
    "step": 80,
    "epoch": 0.0487359122753579,
    "loss": 2.8775,
    "grad_norm": 15.771997451782227,
    "learning_rate": 1.9001218026796592e-06
  },
  {
    "step": 90,
    "epoch": 0.05482790130977764,
    "loss": 2.8848,
    "grad_norm": 15.769919395446777,
    "learning_rate": 2.1437271619975643e-06
  },
  {
    "step": 100,
    "epoch": 0.06091989034419738,
    "loss": 2.8712,
    "grad_norm": 14.70002555847168,
    "learning_rate": 2.387332521315469e-06
  },
  {
    "step": 100,
    "epoch": 0.06091989034419738,
    "eval_loss": 2.8493452072143555,
    "eval_f1": 0.003745162498439515,
    "eval_precision": 0.0024328269449099852,
    "eval_recall": 0.008131550415612577,
    "eval_runtime": 29.2567,
    "eval_samples_per_second": 49.869,
    "eval_steps_per_second": 6.255
  },
  {
    "step": 110,
    "epoch": 0.06701187937861712,
    "loss": 2.8226,
    "grad_norm": 17.890111923217773,
    "learning_rate": 2.6309378806333742e-06
  },
  {
    "step": 120,
    "epoch": 0.07310386841303686,
    "loss": 2.8134,
    "grad_norm": 19.01093292236328,
    "learning_rate": 2.874543239951279e-06
  },
  {
    "step": 130,
    "epoch": 0.0791958574474566,
    "loss": 2.7625,
    "grad_norm": 20.636247634887695,
    "learning_rate": 3.118148599269184e-06
  },
  {
    "step": 140,
    "epoch": 0.08528784648187633,
    "loss": 2.7457,
    "grad_norm": 17.518190383911133,
    "learning_rate": 3.361753958587089e-06
  },
  {
    "step": 150,
    "epoch": 0.09137983551629607,
    "loss": 2.738,
    "grad_norm": 15.868224143981934,
    "learning_rate": 3.605359317904994e-06
  },
  {
    "step": 160,
    "epoch": 0.0974718245507158,
    "loss": 2.7227,
    "grad_norm": 14.090787887573242,
    "learning_rate": 3.8489646772229e-06
  },
  {
    "step": 170,
    "epoch": 0.10356381358513554,
    "loss": 2.6524,
    "grad_norm": 20.887657165527344,
    "learning_rate": 4.092570036540804e-06
  },
  {
    "step": 180,
    "epoch": 0.10965580261955528,
    "loss": 2.6663,
    "grad_norm": 14.383499145507812,
    "learning_rate": 4.336175395858709e-06
  },
  {
    "step": 190,
    "epoch": 0.11574779165397503,
    "loss": 2.6185,
    "grad_norm": 18.664485931396484,
    "learning_rate": 4.579780755176614e-06
  },
  {
    "step": 200,
    "epoch": 0.12183978068839477,
    "loss": 2.5722,
    "grad_norm": 17.364547729492188,
    "learning_rate": 4.8233861144945195e-06
  },
  {
    "step": 200,
    "epoch": 0.12183978068839477,
    "eval_loss": 2.550232410430908,
    "eval_f1": 0.004535740764970125,
    "eval_precision": 0.0029893647599885022,
    "eval_recall": 0.0093964582580412,
    "eval_runtime": 29.3793,
    "eval_samples_per_second": 49.661,
    "eval_steps_per_second": 6.229
  },
  {
    "step": 210,
    "epoch": 0.1279317697228145,
    "loss": 2.5771,
    "grad_norm": 12.713515281677246,
    "learning_rate": 5.066991473812424e-06
  },
  {
    "step": 220,
    "epoch": 0.13402375875723424,
    "loss": 2.5197,
    "grad_norm": 15.820499420166016,
    "learning_rate": 5.310596833130329e-06
  },
  {
    "step": 230,
    "epoch": 0.14011574779165398,
    "loss": 2.4831,
    "grad_norm": 16.75676727294922,
    "learning_rate": 5.554202192448235e-06
  },
  {
    "step": 240,
    "epoch": 0.14620773682607371,
    "loss": 2.4278,
    "grad_norm": 18.696636199951172,
    "learning_rate": 5.797807551766139e-06
  },
  {
    "step": 250,
    "epoch": 0.15229972586049345,
    "loss": 2.4012,
    "grad_norm": 15.032949447631836,
    "learning_rate": 6.0414129110840445e-06
  },
  {
    "step": 260,
    "epoch": 0.1583917148949132,
    "loss": 2.3646,
    "grad_norm": 14.45523452758789,
    "learning_rate": 6.285018270401949e-06
  },
  {
    "step": 270,
    "epoch": 0.16448370392933293,
    "loss": 2.3132,
    "grad_norm": 13.136865615844727,
    "learning_rate": 6.528623629719855e-06
  },
  {
    "step": 280,
    "epoch": 0.17057569296375266,
    "loss": 2.2476,
    "grad_norm": 16.420886993408203,
    "learning_rate": 6.772228989037759e-06
  },
  {
    "step": 290,
    "epoch": 0.1766676819981724,
    "loss": 2.2117,
    "grad_norm": 12.708630561828613,
    "learning_rate": 7.015834348355664e-06
  },
  {
    "step": 300,
    "epoch": 0.18275967103259214,
    "loss": 2.1819,
    "grad_norm": 11.33543872833252,
    "learning_rate": 7.259439707673569e-06
  },
  {
    "step": 300,
    "epoch": 0.18275967103259214,
    "eval_loss": 2.0906503200531006,
    "eval_f1": 0.0025591030952961252,
    "eval_precision": 0.0019305019305019305,
    "eval_recall": 0.0037947235272858693,
    "eval_runtime": 29.4298,
    "eval_samples_per_second": 49.576,
    "eval_steps_per_second": 6.218
  },
  {
    "step": 310,
    "epoch": 0.18885166006701187,
    "loss": 2.1169,
    "grad_norm": 16.231279373168945,
    "learning_rate": 7.503045066991475e-06
  },
  {
    "step": 320,
    "epoch": 0.1949436491014316,
    "loss": 2.0531,
    "grad_norm": 13.521736145019531,
    "learning_rate": 7.746650426309378e-06
  },
  {
    "step": 330,
    "epoch": 0.20103563813585135,
    "loss": 2.0107,
    "grad_norm": 14.066987991333008,
    "learning_rate": 7.990255785627284e-06
  },
  {
    "step": 340,
    "epoch": 0.20712762717027108,
    "loss": 1.9812,
    "grad_norm": 14.496182441711426,
    "learning_rate": 8.23386114494519e-06
  },
  {
    "step": 350,
    "epoch": 0.21321961620469082,
    "loss": 1.9837,
    "grad_norm": 11.458542823791504,
    "learning_rate": 8.477466504263095e-06
  },
  {
    "step": 360,
    "epoch": 0.21931160523911056,
    "loss": 1.8307,
    "grad_norm": 9.156317710876465,
    "learning_rate": 8.721071863581e-06
  },
  {
    "step": 370,
    "epoch": 0.2254035942735303,
    "loss": 1.7753,
    "grad_norm": 10.427329063415527,
    "learning_rate": 8.964677222898905e-06
  },
  {
    "step": 380,
    "epoch": 0.23149558330795006,
    "loss": 1.7112,
    "grad_norm": 10.258520126342773,
    "learning_rate": 9.20828258221681e-06
  },
  {
    "step": 390,
    "epoch": 0.2375875723423698,
    "loss": 1.67,
    "grad_norm": 9.234811782836914,
    "learning_rate": 9.451887941534714e-06
  },
  {
    "step": 400,
    "epoch": 0.24367956137678953,
    "loss": 1.6764,
    "grad_norm": 9.363555908203125,
    "learning_rate": 9.69549330085262e-06
  },
  {
    "step": 400,
    "epoch": 0.24367956137678953,
    "eval_loss": 1.591393232345581,
    "eval_f1": 0.009946949602122017,
    "eval_precision": 0.009188361408882083,
    "eval_recall": 0.01084206722081677,
    "eval_runtime": 29.429,
    "eval_samples_per_second": 49.577,
    "eval_steps_per_second": 6.218
  },
  {
    "step": 410,
    "epoch": 0.24977155041120927,
    "loss": 1.5396,
    "grad_norm": 8.67454719543457,
    "learning_rate": 9.939098660170524e-06
  },
  {
    "step": 420,
    "epoch": 0.255863539445629,
    "loss": 1.6048,
    "grad_norm": 8.11093521118164,
    "learning_rate": 1.018270401948843e-05
  },
  {
    "step": 430,
    "epoch": 0.2619555284800487,
    "loss": 1.5835,
    "grad_norm": 7.409318447113037,
    "learning_rate": 1.0426309378806334e-05
  },
  {
    "step": 440,
    "epoch": 0.2680475175144685,
    "loss": 1.5751,
    "grad_norm": 7.325122833251953,
    "learning_rate": 1.0669914738124239e-05
  },
  {
    "step": 450,
    "epoch": 0.2741395065488882,
    "loss": 1.514,
    "grad_norm": 6.283978462219238,
    "learning_rate": 1.0913520097442145e-05
  },
  {
    "step": 460,
    "epoch": 0.28023149558330795,
    "loss": 1.4615,
    "grad_norm": 5.372857570648193,
    "learning_rate": 1.1157125456760049e-05
  },
  {
    "step": 470,
    "epoch": 0.28632348461772766,
    "loss": 1.3643,
    "grad_norm": 5.2060723304748535,
    "learning_rate": 1.1400730816077953e-05
  },
  {
    "step": 480,
    "epoch": 0.29241547365214743,
    "loss": 1.4175,
    "grad_norm": 4.1048583984375,
    "learning_rate": 1.1644336175395861e-05
  },
  {
    "step": 490,
    "epoch": 0.29850746268656714,
    "loss": 1.3421,
    "grad_norm": 5.311193943023682,
    "learning_rate": 1.1887941534713765e-05
  },
  {
    "step": 500,
    "epoch": 0.3045994517209869,
    "loss": 1.2124,
    "grad_norm": 5.263890743255615,
    "learning_rate": 1.213154689403167e-05
  },
  {
    "step": 500,
    "epoch": 0.3045994517209869,
    "eval_loss": 1.216655969619751,
    "eval_f1": 0.08884754041167578,
    "eval_precision": 0.12463295269168026,
    "eval_recall": 0.06902782797253343,
    "eval_runtime": 29.8254,
    "eval_samples_per_second": 48.918,
    "eval_steps_per_second": 6.136
  },
  {
    "step": 510,
    "epoch": 0.31069144075540667,
    "loss": 1.208,
    "grad_norm": 4.3338446617126465,
    "learning_rate": 1.2375152253349574e-05
  },
  {
    "step": 520,
    "epoch": 0.3167834297898264,
    "loss": 1.2325,
    "grad_norm": 3.2728960514068604,
    "learning_rate": 1.261875761266748e-05
  },
  {
    "step": 530,
    "epoch": 0.32287541882424614,
    "loss": 1.1632,
    "grad_norm": 3.2742950916290283,
    "learning_rate": 1.2862362971985384e-05
  },
  {
    "step": 540,
    "epoch": 0.32896740785866585,
    "loss": 1.1437,
    "grad_norm": 3.7063610553741455,
    "learning_rate": 1.3105968331303289e-05
  },
  {
    "step": 550,
    "epoch": 0.3350593968930856,
    "loss": 1.1521,
    "grad_norm": 2.6175217628479004,
    "learning_rate": 1.3349573690621193e-05
  },
  {
    "step": 560,
    "epoch": 0.3411513859275053,
    "loss": 1.2191,
    "grad_norm": 2.1880908012390137,
    "learning_rate": 1.35931790499391e-05
  },
  {
    "step": 570,
    "epoch": 0.3472433749619251,
    "loss": 1.1296,
    "grad_norm": 2.762251377105713,
    "learning_rate": 1.3836784409257005e-05
  },
  {
    "step": 580,
    "epoch": 0.3533353639963448,
    "loss": 1.1083,
    "grad_norm": 2.8939170837402344,
    "learning_rate": 1.408038976857491e-05
  },
  {
    "step": 590,
    "epoch": 0.35942735303076456,
    "loss": 1.0834,
    "grad_norm": 2.4013962745666504,
    "learning_rate": 1.4323995127892815e-05
  },
  {
    "step": 600,
    "epoch": 0.36551934206518427,
    "loss": 1.0186,
    "grad_norm": 2.5943007469177246,
    "learning_rate": 1.456760048721072e-05
  },
  {
    "step": 600,
    "epoch": 0.36551934206518427,
    "eval_loss": 1.0307972431182861,
    "eval_f1": 0.14492753623188406,
    "eval_precision": 0.2611764705882353,
    "eval_recall": 0.10028912179255511,
    "eval_runtime": 30.4888,
    "eval_samples_per_second": 47.854,
    "eval_steps_per_second": 6.002
  },
  {
    "step": 610,
    "epoch": 0.37161133109960404,
    "loss": 1.0198,
    "grad_norm": 2.246659517288208,
    "learning_rate": 1.4811205846528624e-05
  },
  {
    "step": 620,
    "epoch": 0.37770332013402375,
    "loss": 1.0288,
    "grad_norm": 1.4508130550384521,
    "learning_rate": 1.5054811205846528e-05
  },
  {
    "step": 630,
    "epoch": 0.3837953091684435,
    "loss": 1.0155,
    "grad_norm": 2.846419095993042,
    "learning_rate": 1.5298416565164434e-05
  },
  {
    "step": 640,
    "epoch": 0.3898872982028632,
    "loss": 1.0253,
    "grad_norm": 1.6855401992797852,
    "learning_rate": 1.554202192448234e-05
  },
  {
    "step": 650,
    "epoch": 0.395979287237283,
    "loss": 1.0288,
    "grad_norm": 1.471238613128662,
    "learning_rate": 1.5785627283800243e-05
  },
  {
    "step": 660,
    "epoch": 0.4020712762717027,
    "loss": 1.0026,
    "grad_norm": 2.0655744075775146,
    "learning_rate": 1.6029232643118147e-05
  },
  {
    "step": 670,
    "epoch": 0.40816326530612246,
    "loss": 1.0235,
    "grad_norm": 1.4489110708236694,
    "learning_rate": 1.6272838002436055e-05
  },
  {
    "step": 680,
    "epoch": 0.41425525434054217,
    "loss": 0.975,
    "grad_norm": 1.9829386472702026,
    "learning_rate": 1.651644336175396e-05
  },
  {
    "step": 690,
    "epoch": 0.42034724337496193,
    "loss": 0.9243,
    "grad_norm": 2.4144699573516846,
    "learning_rate": 1.6760048721071864e-05
  },
  {
    "step": 700,
    "epoch": 0.42643923240938164,
    "loss": 0.9815,
    "grad_norm": 1.8678444623947144,
    "learning_rate": 1.700365408038977e-05
  },
  {
    "step": 700,
    "epoch": 0.42643923240938164,
    "eval_loss": 0.953133225440979,
    "eval_f1": 0.19091146513449983,
    "eval_precision": 0.3441619585687382,
    "eval_recall": 0.13209251897361762,
    "eval_runtime": 33.0761,
    "eval_samples_per_second": 44.11,
    "eval_steps_per_second": 5.533
  },
  {
    "step": 710,
    "epoch": 0.4325312214438014,
    "loss": 0.9652,
    "grad_norm": 1.0930224657058716,
    "learning_rate": 1.7247259439707676e-05
  },
  {
    "step": 720,
    "epoch": 0.4386232104782211,
    "loss": 1.0251,
    "grad_norm": 2.9863412380218506,
    "learning_rate": 1.749086479902558e-05
  },
  {
    "step": 730,
    "epoch": 0.4447151995126409,
    "loss": 0.8996,
    "grad_norm": 1.1679153442382812,
    "learning_rate": 1.7734470158343484e-05
  },
  {
    "step": 740,
    "epoch": 0.4508071885470606,
    "loss": 0.9268,
    "grad_norm": 1.1867763996124268,
    "learning_rate": 1.7978075517661392e-05
  },
  {
    "step": 750,
    "epoch": 0.45689917758148035,
    "loss": 0.9743,
    "grad_norm": 1.256999135017395,
    "learning_rate": 1.8221680876979296e-05
  },
  {
    "step": 760,
    "epoch": 0.4629911666159001,
    "loss": 0.9064,
    "grad_norm": 1.253122091293335,
    "learning_rate": 1.84652862362972e-05
  },
  {
    "step": 770,
    "epoch": 0.4690831556503198,
    "loss": 0.9391,
    "grad_norm": 1.064028024673462,
    "learning_rate": 1.8708891595615105e-05
  },
  {
    "step": 780,
    "epoch": 0.4751751446847396,
    "loss": 0.9498,
    "grad_norm": 0.7738329172134399,
    "learning_rate": 1.895249695493301e-05
  },
  {
    "step": 790,
    "epoch": 0.4812671337191593,
    "loss": 0.9946,
    "grad_norm": 1.1105916500091553,
    "learning_rate": 1.9196102314250914e-05
  },
  {
    "step": 800,
    "epoch": 0.48735912275357907,
    "loss": 0.8884,
    "grad_norm": 1.207162618637085,
    "learning_rate": 1.9439707673568818e-05
  },
  {
    "step": 800,
    "epoch": 0.48735912275357907,
    "eval_loss": 0.9126753807067871,
    "eval_f1": 0.2355818743563337,
    "eval_precision": 0.40957923008057295,
    "eval_recall": 0.16534152511745573,
    "eval_runtime": 39.0909,
    "eval_samples_per_second": 37.323,
    "eval_steps_per_second": 4.681
  },
  {
    "step": 810,
    "epoch": 0.4934511117879988,
    "loss": 0.9605,
    "grad_norm": 1.853307843208313,
    "learning_rate": 1.9683313032886726e-05
  },
  {
    "step": 820,
    "epoch": 0.49954310082241854,
    "loss": 0.9311,
    "grad_norm": 0.9380223751068115,
    "learning_rate": 1.992691839220463e-05
  },
  {
    "step": 830,
    "epoch": 0.5056350898568382,
    "loss": 0.9088,
    "grad_norm": 1.9981215000152588,
    "learning_rate": 1.9999955711173205e-05
  },
  {
    "step": 840,
    "epoch": 0.511727078891258,
    "loss": 0.9435,
    "grad_norm": 1.07861328125,
    "learning_rate": 1.999973878725165e-05
  },
  {
    "step": 850,
    "epoch": 0.5178190679256778,
    "loss": 0.9161,
    "grad_norm": 1.8805345296859741,
    "learning_rate": 1.9999341097469313e-05
  },
  {
    "step": 860,
    "epoch": 0.5239110569600974,
    "loss": 0.8855,
    "grad_norm": 1.0693228244781494,
    "learning_rate": 1.9998762649015257e-05
  },
  {
    "step": 870,
    "epoch": 0.5300030459945172,
    "loss": 0.9384,
    "grad_norm": 1.8698467016220093,
    "learning_rate": 1.9998003452346123e-05
  },
  {
    "step": 880,
    "epoch": 0.536095035028937,
    "loss": 0.9742,
    "grad_norm": 1.7009344100952148,
    "learning_rate": 1.9997063521185956e-05
  },
  {
    "step": 890,
    "epoch": 0.5421870240633567,
    "loss": 0.877,
    "grad_norm": 0.9742613434791565,
    "learning_rate": 1.999594287252595e-05
  },
  {
    "step": 900,
    "epoch": 0.5482790130977764,
    "loss": 0.9449,
    "grad_norm": 1.075216293334961,
    "learning_rate": 1.9994641526624126e-05
  },
  {
    "step": 900,
    "epoch": 0.5482790130977764,
    "eval_loss": 0.8884426355361938,
    "eval_f1": 0.266581956797967,
    "eval_precision": 0.4490582191780822,
    "eval_recall": 0.1895554752439465,
    "eval_runtime": 33.0083,
    "eval_samples_per_second": 44.201,
    "eval_steps_per_second": 5.544
  },
  {
    "step": 910,
    "epoch": 0.5543710021321961,
    "loss": 0.9374,
    "grad_norm": 2.907327175140381,
    "learning_rate": 1.9993159507005e-05
  },
  {
    "step": 920,
    "epoch": 0.5604629911666159,
    "loss": 0.9482,
    "grad_norm": 1.5831040143966675,
    "learning_rate": 1.999149684045912e-05
  },
  {
    "step": 930,
    "epoch": 0.5665549802010357,
    "loss": 0.8923,
    "grad_norm": 1.52166748046875,
    "learning_rate": 1.9989653557042613e-05
  },
  {
    "step": 940,
    "epoch": 0.5726469692354553,
    "loss": 0.8696,
    "grad_norm": 0.8552747964859009,
    "learning_rate": 1.9987629690076615e-05
  },
  {
    "step": 950,
    "epoch": 0.5787389582698751,
    "loss": 0.8725,
    "grad_norm": 1.6673502922058105,
    "learning_rate": 1.9985425276146685e-05
  },
  {
    "step": 960,
    "epoch": 0.5848309473042949,
    "loss": 0.8752,
    "grad_norm": 1.5835177898406982,
    "learning_rate": 1.9983040355102152e-05
  },
  {
    "step": 970,
    "epoch": 0.5909229363387146,
    "loss": 0.8722,
    "grad_norm": 1.1462593078613281,
    "learning_rate": 1.9980474970055367e-05
  },
  {
    "step": 980,
    "epoch": 0.5970149253731343,
    "loss": 0.83,
    "grad_norm": 1.2565025091171265,
    "learning_rate": 1.997772916738094e-05
  },
  {
    "step": 990,
    "epoch": 0.603106914407554,
    "loss": 0.8437,
    "grad_norm": 1.1732136011123657,
    "learning_rate": 1.9974802996714914e-05
  },
  {
    "step": 1000,
    "epoch": 0.6091989034419738,
    "loss": 0.878,
    "grad_norm": 1.671773076057434,
    "learning_rate": 1.997169651095384e-05
  },
  {
    "step": 1000,
    "epoch": 0.6091989034419738,
    "eval_loss": 0.8756174445152283,
    "eval_f1": 0.2790461694571284,
    "eval_precision": 0.46808510638297873,
    "eval_recall": 0.19877123238164077,
    "eval_runtime": 29.8345,
    "eval_samples_per_second": 48.903,
    "eval_steps_per_second": 6.134
  },
  {
    "step": 1010,
    "epoch": 0.6152908924763936,
    "loss": 0.8934,
    "grad_norm": 1.1586849689483643,
    "learning_rate": 1.9968409766253846e-05
  },
  {
    "step": 1020,
    "epoch": 0.6213828815108133,
    "loss": 0.8707,
    "grad_norm": 1.2032748460769653,
    "learning_rate": 1.996494282202961e-05
  },
  {
    "step": 1030,
    "epoch": 0.627474870545233,
    "loss": 0.9214,
    "grad_norm": 1.3075906038284302,
    "learning_rate": 1.996129574095328e-05
  },
  {
    "step": 1040,
    "epoch": 0.6335668595796528,
    "loss": 0.9289,
    "grad_norm": 1.0910924673080444,
    "learning_rate": 1.9957468588953354e-05
  },
  {
    "step": 1050,
    "epoch": 0.6396588486140725,
    "loss": 0.8992,
    "grad_norm": 1.6921321153640747,
    "learning_rate": 1.9953461435213485e-05
  },
  {
    "step": 1060,
    "epoch": 0.6457508376484923,
    "loss": 0.8843,
    "grad_norm": 1.5609982013702393,
    "learning_rate": 1.9949274352171218e-05
  },
  {
    "step": 1070,
    "epoch": 0.6518428266829119,
    "loss": 0.8597,
    "grad_norm": 1.3706691265106201,
    "learning_rate": 1.9944907415516703e-05
  },
  {
    "step": 1080,
    "epoch": 0.6579348157173317,
    "loss": 0.8784,
    "grad_norm": 1.7960004806518555,
    "learning_rate": 1.994036070419131e-05
  },
  {
    "step": 1090,
    "epoch": 0.6640268047517515,
    "loss": 0.8746,
    "grad_norm": 2.263765811920166,
    "learning_rate": 1.99356343003862e-05
  },
  {
    "step": 1100,
    "epoch": 0.6701187937861712,
    "loss": 0.9582,
    "grad_norm": 1.4437227249145508,
    "learning_rate": 1.9930728289540848e-05
  },
  {
    "step": 1100,
    "epoch": 0.6701187937861712,
    "eval_loss": 0.8596062660217285,
    "eval_f1": 0.29621240719768466,
    "eval_precision": 0.48777455449647744,
    "eval_recall": 0.21268521864835563,
    "eval_runtime": 30.2097,
    "eval_samples_per_second": 48.296,
    "eval_steps_per_second": 6.058
  },
  {
    "step": 1110,
    "epoch": 0.6762107828205909,
    "loss": 0.8635,
    "grad_norm": 1.3091572523117065,
    "learning_rate": 1.9925642760341503e-05
  },
  {
    "step": 1120,
    "epoch": 0.6823027718550106,
    "loss": 0.8892,
    "grad_norm": 0.9952411651611328,
    "learning_rate": 1.9920377804719573e-05
  },
  {
    "step": 1130,
    "epoch": 0.6883947608894304,
    "loss": 0.9035,
    "grad_norm": 1.434762954711914,
    "learning_rate": 1.9914933517849962e-05
  },
  {
    "step": 1140,
    "epoch": 0.6944867499238502,
    "loss": 0.8511,
    "grad_norm": 1.0902725458145142,
    "learning_rate": 1.990930999814937e-05
  },
  {
    "step": 1150,
    "epoch": 0.7005787389582698,
    "loss": 0.8661,
    "grad_norm": 1.9823004007339478,
    "learning_rate": 1.9903507347274478e-05
  },
  {
    "step": 1160,
    "epoch": 0.7066707279926896,
    "loss": 0.9303,
    "grad_norm": 1.2190210819244385,
    "learning_rate": 1.9897525670120154e-05
  },
  {
    "step": 1170,
    "epoch": 0.7127627170271094,
    "loss": 0.9227,
    "grad_norm": 2.70273494720459,
    "learning_rate": 1.9891365074817524e-05
  },
  {
    "step": 1180,
    "epoch": 0.7188547060615291,
    "loss": 0.8812,
    "grad_norm": 1.723663330078125,
    "learning_rate": 1.9885025672732024e-05
  },
  {
    "step": 1190,
    "epoch": 0.7249466950959488,
    "loss": 0.8949,
    "grad_norm": 1.2012016773223877,
    "learning_rate": 1.9878507578461394e-05
  },
  {
    "step": 1200,
    "epoch": 0.7310386841303685,
    "loss": 0.8358,
    "grad_norm": 1.0577797889709473,
    "learning_rate": 1.9871810909833612e-05
  }
]