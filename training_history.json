[
  {
    "step": 10,
    "epoch": 0.004443457009553432,
    "loss": 2.4283,
    "grad_norm": 15.484232902526855,
    "learning_rate": 1.4209591474245118e-07
  },
  {
    "step": 20,
    "epoch": 0.008886914019106865,
    "loss": 2.4136,
    "grad_norm": 22.037944793701172,
    "learning_rate": 3.1971580817051514e-07
  },
  {
    "step": 30,
    "epoch": 0.013330371028660297,
    "loss": 2.4298,
    "grad_norm": 11.131356239318848,
    "learning_rate": 4.97335701598579e-07
  },
  {
    "step": 40,
    "epoch": 0.01777382803821373,
    "loss": 2.4196,
    "grad_norm": 16.957712173461914,
    "learning_rate": 6.749555950266431e-07
  },
  {
    "step": 50,
    "epoch": 0.02221728504776716,
    "loss": 2.3975,
    "grad_norm": 11.319293022155762,
    "learning_rate": 8.52575488454707e-07
  },
  {
    "step": 60,
    "epoch": 0.026660742057320594,
    "loss": 2.4056,
    "grad_norm": 10.968162536621094,
    "learning_rate": 1.030195381882771e-06
  },
  {
    "step": 70,
    "epoch": 0.03110419906687403,
    "loss": 2.4208,
    "grad_norm": 13.368660926818848,
    "learning_rate": 1.207815275310835e-06
  },
  {
    "step": 80,
    "epoch": 0.03554765607642746,
    "loss": 2.3978,
    "grad_norm": 16.14052391052246,
    "learning_rate": 1.385435168738899e-06
  },
  {
    "step": 90,
    "epoch": 0.03999111308598089,
    "loss": 2.3717,
    "grad_norm": 16.05356216430664,
    "learning_rate": 1.563055062166963e-06
  },
  {
    "step": 100,
    "epoch": 0.04443457009553432,
    "loss": 2.3257,
    "grad_norm": 14.091784477233887,
    "learning_rate": 1.7406749555950267e-06
  },
  {
    "step": 110,
    "epoch": 0.048878027105087755,
    "loss": 2.3546,
    "grad_norm": 11.752869606018066,
    "learning_rate": 1.9182948490230907e-06
  },
  {
    "step": 120,
    "epoch": 0.05332148411464119,
    "loss": 2.3278,
    "grad_norm": 10.529034614562988,
    "learning_rate": 2.0959147424511548e-06
  },
  {
    "step": 130,
    "epoch": 0.05776494112419462,
    "loss": 2.3262,
    "grad_norm": 15.615443229675293,
    "learning_rate": 2.273534635879219e-06
  },
  {
    "step": 140,
    "epoch": 0.06220839813374806,
    "loss": 2.3314,
    "grad_norm": 10.36075496673584,
    "learning_rate": 2.4511545293072824e-06
  },
  {
    "step": 150,
    "epoch": 0.06665185514330149,
    "loss": 2.3143,
    "grad_norm": 13.088807106018066,
    "learning_rate": 2.628774422735347e-06
  },
  {
    "step": 160,
    "epoch": 0.07109531215285492,
    "loss": 2.285,
    "grad_norm": 16.24871253967285,
    "learning_rate": 2.8063943161634105e-06
  },
  {
    "step": 170,
    "epoch": 0.07553876916240836,
    "loss": 2.2423,
    "grad_norm": 15.782776832580566,
    "learning_rate": 2.984014209591474e-06
  },
  {
    "step": 180,
    "epoch": 0.07998222617196178,
    "loss": 2.2428,
    "grad_norm": 11.645222663879395,
    "learning_rate": 3.1616341030195386e-06
  },
  {
    "step": 190,
    "epoch": 0.08442568318151522,
    "loss": 2.1993,
    "grad_norm": 11.994476318359375,
    "learning_rate": 3.339253996447602e-06
  },
  {
    "step": 200,
    "epoch": 0.08886914019106865,
    "loss": 2.121,
    "grad_norm": 13.911176681518555,
    "learning_rate": 3.5168738898756667e-06
  },
  {
    "step": 210,
    "epoch": 0.09331259720062209,
    "loss": 2.1682,
    "grad_norm": 13.759034156799316,
    "learning_rate": 3.6944937833037303e-06
  },
  {
    "step": 220,
    "epoch": 0.09775605421017551,
    "loss": 2.1854,
    "grad_norm": 11.05042552947998,
    "learning_rate": 3.872113676731794e-06
  },
  {
    "step": 230,
    "epoch": 0.10219951121972895,
    "loss": 2.1421,
    "grad_norm": 10.175942420959473,
    "learning_rate": 4.049733570159858e-06
  },
  {
    "step": 240,
    "epoch": 0.10664296822928238,
    "loss": 2.0742,
    "grad_norm": 12.56050968170166,
    "learning_rate": 4.227353463587922e-06
  },
  {
    "step": 250,
    "epoch": 0.11108642523883581,
    "loss": 2.0833,
    "grad_norm": 10.502552032470703,
    "learning_rate": 4.404973357015986e-06
  },
  {
    "step": 260,
    "epoch": 0.11552988224838924,
    "loss": 2.0369,
    "grad_norm": 15.41727352142334,
    "learning_rate": 4.58259325044405e-06
  },
  {
    "step": 270,
    "epoch": 0.11997333925794268,
    "loss": 1.9383,
    "grad_norm": 10.963820457458496,
    "learning_rate": 4.760213143872114e-06
  },
  {
    "step": 280,
    "epoch": 0.12441679626749612,
    "loss": 2.0399,
    "grad_norm": 9.63045883178711,
    "learning_rate": 4.937833037300178e-06
  },
  {
    "step": 290,
    "epoch": 0.12886025327704956,
    "loss": 1.9601,
    "grad_norm": 11.973691940307617,
    "learning_rate": 5.115452930728242e-06
  },
  {
    "step": 300,
    "epoch": 0.13330371028660298,
    "loss": 1.8609,
    "grad_norm": 11.819704055786133,
    "learning_rate": 5.293072824156305e-06
  },
  {
    "step": 310,
    "epoch": 0.1377471672961564,
    "loss": 1.8344,
    "grad_norm": 11.310672760009766,
    "learning_rate": 5.4706927175843694e-06
  },
  {
    "step": 320,
    "epoch": 0.14219062430570983,
    "loss": 1.7301,
    "grad_norm": 10.567749977111816,
    "learning_rate": 5.648312611012434e-06
  },
  {
    "step": 330,
    "epoch": 0.1466340813152633,
    "loss": 1.809,
    "grad_norm": 12.567418098449707,
    "learning_rate": 5.825932504440498e-06
  },
  {
    "step": 340,
    "epoch": 0.1510775383248167,
    "loss": 1.8579,
    "grad_norm": 11.471304893493652,
    "learning_rate": 6.0035523978685616e-06
  },
  {
    "step": 350,
    "epoch": 0.15552099533437014,
    "loss": 1.6546,
    "grad_norm": 13.432111740112305,
    "learning_rate": 6.181172291296626e-06
  },
  {
    "step": 360,
    "epoch": 0.15996445234392356,
    "loss": 1.6673,
    "grad_norm": 8.604889869689941,
    "learning_rate": 6.358792184724689e-06
  },
  {
    "step": 370,
    "epoch": 0.16440790935347702,
    "loss": 1.6792,
    "grad_norm": 9.377952575683594,
    "learning_rate": 6.536412078152754e-06
  },
  {
    "step": 380,
    "epoch": 0.16885136636303044,
    "loss": 1.6026,
    "grad_norm": 10.427748680114746,
    "learning_rate": 6.714031971580818e-06
  },
  {
    "step": 390,
    "epoch": 0.17329482337258387,
    "loss": 1.5718,
    "grad_norm": 6.782504081726074,
    "learning_rate": 6.891651865008882e-06
  },
  {
    "step": 400,
    "epoch": 0.1777382803821373,
    "loss": 1.5988,
    "grad_norm": 8.511553764343262,
    "learning_rate": 7.069271758436945e-06
  },
  {
    "step": 410,
    "epoch": 0.18218173739169075,
    "loss": 1.5891,
    "grad_norm": 8.435262680053711,
    "learning_rate": 7.246891651865009e-06
  },
  {
    "step": 420,
    "epoch": 0.18662519440124417,
    "loss": 1.449,
    "grad_norm": 7.555228233337402,
    "learning_rate": 7.424511545293074e-06
  },
  {
    "step": 430,
    "epoch": 0.1910686514107976,
    "loss": 1.4564,
    "grad_norm": 7.960641384124756,
    "learning_rate": 7.602131438721138e-06
  },
  {
    "step": 440,
    "epoch": 0.19551210842035102,
    "loss": 1.4201,
    "grad_norm": 8.804156303405762,
    "learning_rate": 7.779751332149202e-06
  },
  {
    "step": 450,
    "epoch": 0.19995556542990447,
    "loss": 1.5279,
    "grad_norm": 7.307713031768799,
    "learning_rate": 7.957371225577264e-06
  },
  {
    "step": 460,
    "epoch": 0.2043990224394579,
    "loss": 1.4314,
    "grad_norm": 5.541622638702393,
    "learning_rate": 8.134991119005328e-06
  },
  {
    "step": 470,
    "epoch": 0.20884247944901133,
    "loss": 1.3532,
    "grad_norm": 7.902400970458984,
    "learning_rate": 8.312611012433394e-06
  },
  {
    "step": 480,
    "epoch": 0.21328593645856475,
    "loss": 1.5251,
    "grad_norm": 4.998037338256836,
    "learning_rate": 8.490230905861458e-06
  },
  {
    "step": 490,
    "epoch": 0.2177293934681182,
    "loss": 1.2935,
    "grad_norm": 5.439553737640381,
    "learning_rate": 8.66785079928952e-06
  },
  {
    "step": 500,
    "epoch": 0.22217285047767163,
    "loss": 1.4464,
    "grad_norm": 4.4420166015625,
    "learning_rate": 8.845470692717585e-06
  },
  {
    "step": 500,
    "epoch": 0.22217285047767163,
    "eval_loss": 1.2465559244155884,
    "eval_f1": 0.07497803377916626,
    "eval_precision": 0.07339449541284404,
    "eval_recall": 0.07663141089602873,
    "eval_runtime": 38.5632,
    "eval_samples_per_second": 51.889,
    "eval_steps_per_second": 6.509
  },
  {
    "step": 510,
    "epoch": 0.22661630748722505,
    "loss": 1.3284,
    "grad_norm": 4.2929277420043945,
    "learning_rate": 9.023090586145649e-06
  },
  {
    "step": 520,
    "epoch": 0.23105976449677848,
    "loss": 1.3328,
    "grad_norm": 4.258148670196533,
    "learning_rate": 9.200710479573713e-06
  },
  {
    "step": 530,
    "epoch": 0.23550322150633193,
    "loss": 1.2076,
    "grad_norm": 4.079315185546875,
    "learning_rate": 9.378330373001777e-06
  },
  {
    "step": 540,
    "epoch": 0.23994667851588536,
    "loss": 1.2072,
    "grad_norm": 3.456613540649414,
    "learning_rate": 9.55595026642984e-06
  },
  {
    "step": 550,
    "epoch": 0.24439013552543878,
    "loss": 1.2181,
    "grad_norm": 4.458498477935791,
    "learning_rate": 9.733570159857905e-06
  },
  {
    "step": 560,
    "epoch": 0.24883359253499224,
    "loss": 1.1753,
    "grad_norm": 3.3567159175872803,
    "learning_rate": 9.911190053285969e-06
  },
  {
    "step": 570,
    "epoch": 0.25327704954454566,
    "loss": 1.1658,
    "grad_norm": 3.6796271800994873,
    "learning_rate": 1.0088809946714033e-05
  },
  {
    "step": 580,
    "epoch": 0.2577205065540991,
    "loss": 1.1491,
    "grad_norm": 3.7875895500183105,
    "learning_rate": 1.0266429840142095e-05
  },
  {
    "step": 590,
    "epoch": 0.2621639635636525,
    "loss": 1.1041,
    "grad_norm": 2.842137336730957,
    "learning_rate": 1.0444049733570161e-05
  },
  {
    "step": 600,
    "epoch": 0.26660742057320597,
    "loss": 1.032,
    "grad_norm": 2.5492656230926514,
    "learning_rate": 1.0621669626998225e-05
  },
  {
    "step": 610,
    "epoch": 0.27105087758275936,
    "loss": 1.1042,
    "grad_norm": 2.6674094200134277,
    "learning_rate": 1.0799289520426289e-05
  },
  {
    "step": 620,
    "epoch": 0.2754943345923128,
    "loss": 1.0492,
    "grad_norm": 1.9542409181594849,
    "learning_rate": 1.0976909413854353e-05
  },
  {
    "step": 630,
    "epoch": 0.27993779160186627,
    "loss": 1.0922,
    "grad_norm": 1.983305811882019,
    "learning_rate": 1.1154529307282415e-05
  },
  {
    "step": 640,
    "epoch": 0.28438124861141967,
    "loss": 1.115,
    "grad_norm": 2.0277295112609863,
    "learning_rate": 1.1332149200710481e-05
  },
  {
    "step": 650,
    "epoch": 0.2888247056209731,
    "loss": 1.0605,
    "grad_norm": 1.8451143503189087,
    "learning_rate": 1.1509769094138545e-05
  },
  {
    "step": 660,
    "epoch": 0.2932681626305266,
    "loss": 1.0065,
    "grad_norm": 2.812058925628662,
    "learning_rate": 1.1687388987566608e-05
  },
  {
    "step": 670,
    "epoch": 0.29771161964007997,
    "loss": 1.0241,
    "grad_norm": 1.7246507406234741,
    "learning_rate": 1.1865008880994673e-05
  },
  {
    "step": 680,
    "epoch": 0.3021550766496334,
    "loss": 1.1539,
    "grad_norm": 2.867011785507202,
    "learning_rate": 1.2042628774422736e-05
  },
  {
    "step": 690,
    "epoch": 0.3065985336591868,
    "loss": 1.0269,
    "grad_norm": 2.890437364578247,
    "learning_rate": 1.22202486678508e-05
  },
  {
    "step": 700,
    "epoch": 0.3110419906687403,
    "loss": 1.0781,
    "grad_norm": 3.2259981632232666,
    "learning_rate": 1.2397868561278865e-05
  },
  {
    "step": 710,
    "epoch": 0.31548544767829373,
    "loss": 1.0371,
    "grad_norm": 1.4932100772857666,
    "learning_rate": 1.2575488454706928e-05
  },
  {
    "step": 720,
    "epoch": 0.3199289046878471,
    "loss": 0.9387,
    "grad_norm": 1.4572322368621826,
    "learning_rate": 1.2753108348134993e-05
  },
  {
    "step": 730,
    "epoch": 0.3243723616974006,
    "loss": 1.0782,
    "grad_norm": 2.08225154876709,
    "learning_rate": 1.2930728241563056e-05
  },
  {
    "step": 740,
    "epoch": 0.32881581870695403,
    "loss": 0.9461,
    "grad_norm": 2.3929500579833984,
    "learning_rate": 1.310834813499112e-05
  },
  {
    "step": 750,
    "epoch": 0.33325927571650743,
    "loss": 0.9366,
    "grad_norm": 1.6925544738769531,
    "learning_rate": 1.3285968028419186e-05
  },
  {
    "step": 760,
    "epoch": 0.3377027327260609,
    "loss": 0.9778,
    "grad_norm": 1.4673380851745605,
    "learning_rate": 1.3463587921847248e-05
  },
  {
    "step": 770,
    "epoch": 0.3421461897356143,
    "loss": 0.9868,
    "grad_norm": 1.2080738544464111,
    "learning_rate": 1.3641207815275312e-05
  },
  {
    "step": 780,
    "epoch": 0.34658964674516773,
    "loss": 0.8803,
    "grad_norm": 2.5883047580718994,
    "learning_rate": 1.3818827708703374e-05
  },
  {
    "step": 790,
    "epoch": 0.3510331037547212,
    "loss": 1.0682,
    "grad_norm": 2.9351840019226074,
    "learning_rate": 1.399644760213144e-05
  },
  {
    "step": 800,
    "epoch": 0.3554765607642746,
    "loss": 0.9622,
    "grad_norm": 2.270653247833252,
    "learning_rate": 1.4174067495559504e-05
  },
  {
    "step": 810,
    "epoch": 0.35992001777382804,
    "loss": 0.931,
    "grad_norm": 1.9909296035766602,
    "learning_rate": 1.4351687388987568e-05
  },
  {
    "step": 820,
    "epoch": 0.3643634747833815,
    "loss": 0.8765,
    "grad_norm": 1.8299506902694702,
    "learning_rate": 1.4529307282415632e-05
  },
  {
    "step": 830,
    "epoch": 0.3688069317929349,
    "loss": 0.9062,
    "grad_norm": 1.3986259698867798,
    "learning_rate": 1.4706927175843695e-05
  },
  {
    "step": 840,
    "epoch": 0.37325038880248834,
    "loss": 1.0445,
    "grad_norm": 1.2321579456329346,
    "learning_rate": 1.488454706927176e-05
  },
  {
    "step": 850,
    "epoch": 0.3776938458120418,
    "loss": 0.9121,
    "grad_norm": 1.4590023756027222,
    "learning_rate": 1.5062166962699824e-05
  },
  {
    "step": 860,
    "epoch": 0.3821373028215952,
    "loss": 0.9505,
    "grad_norm": 1.1232690811157227,
    "learning_rate": 1.5239786856127887e-05
  },
  {
    "step": 870,
    "epoch": 0.38658075983114865,
    "loss": 0.9299,
    "grad_norm": 1.3881338834762573,
    "learning_rate": 1.541740674955595e-05
  },
  {
    "step": 880,
    "epoch": 0.39102421684070204,
    "loss": 1.0066,
    "grad_norm": 1.8108148574829102,
    "learning_rate": 1.5595026642984015e-05
  },
  {
    "step": 890,
    "epoch": 0.3954676738502555,
    "loss": 0.9627,
    "grad_norm": 1.5171844959259033,
    "learning_rate": 1.577264653641208e-05
  },
  {
    "step": 900,
    "epoch": 0.39991113085980895,
    "loss": 1.0057,
    "grad_norm": 1.9575915336608887,
    "learning_rate": 1.5950266429840143e-05
  },
  {
    "step": 910,
    "epoch": 0.40435458786936235,
    "loss": 0.974,
    "grad_norm": 1.0139949321746826,
    "learning_rate": 1.6127886323268207e-05
  },
  {
    "step": 920,
    "epoch": 0.4087980448789158,
    "loss": 1.0526,
    "grad_norm": 2.734691858291626,
    "learning_rate": 1.630550621669627e-05
  },
  {
    "step": 930,
    "epoch": 0.41324150188846925,
    "loss": 1.0141,
    "grad_norm": 1.352540135383606,
    "learning_rate": 1.6483126110124335e-05
  },
  {
    "step": 940,
    "epoch": 0.41768495889802265,
    "loss": 0.9237,
    "grad_norm": 1.7752840518951416,
    "learning_rate": 1.66607460035524e-05
  },
  {
    "step": 950,
    "epoch": 0.4221284159075761,
    "loss": 1.0763,
    "grad_norm": 1.8641761541366577,
    "learning_rate": 1.6838365896980463e-05
  },
  {
    "step": 960,
    "epoch": 0.4265718729171295,
    "loss": 1.0012,
    "grad_norm": 3.3195836544036865,
    "learning_rate": 1.7015985790408527e-05
  },
  {
    "step": 970,
    "epoch": 0.43101532992668296,
    "loss": 0.9012,
    "grad_norm": 1.2560666799545288,
    "learning_rate": 1.719360568383659e-05
  },
  {
    "step": 980,
    "epoch": 0.4354587869362364,
    "loss": 0.9383,
    "grad_norm": 1.7764296531677246,
    "learning_rate": 1.7371225577264655e-05
  },
  {
    "step": 990,
    "epoch": 0.4399022439457898,
    "loss": 0.8678,
    "grad_norm": 1.8695186376571655,
    "learning_rate": 1.754884547069272e-05
  },
  {
    "step": 1000,
    "epoch": 0.44434570095534326,
    "loss": 0.9514,
    "grad_norm": 1.146554708480835,
    "learning_rate": 1.7726465364120783e-05
  },
  {
    "step": 1000,
    "epoch": 0.44434570095534326,
    "eval_loss": 0.9136641621589661,
    "eval_f1": 0.2161945483698557,
    "eval_precision": 0.32713303679741207,
    "eval_recall": 0.16144482139293553,
    "eval_runtime": 39.0424,
    "eval_samples_per_second": 51.252,
    "eval_steps_per_second": 6.429
  },
  {
    "step": 1010,
    "epoch": 0.4487891579648967,
    "loss": 0.8808,
    "grad_norm": 1.3365494012832642,
    "learning_rate": 1.7904085257548847e-05
  },
  {
    "step": 1020,
    "epoch": 0.4532326149744501,
    "loss": 0.9393,
    "grad_norm": 1.3615162372589111,
    "learning_rate": 1.808170515097691e-05
  },
  {
    "step": 1030,
    "epoch": 0.45767607198400356,
    "loss": 0.8805,
    "grad_norm": 1.2430099248886108,
    "learning_rate": 1.8259325044404975e-05
  },
  {
    "step": 1040,
    "epoch": 0.46211952899355696,
    "loss": 0.9184,
    "grad_norm": 2.218092679977417,
    "learning_rate": 1.843694493783304e-05
  },
  {
    "step": 1050,
    "epoch": 0.4665629860031104,
    "loss": 0.9808,
    "grad_norm": 1.4209649562835693,
    "learning_rate": 1.8614564831261103e-05
  },
  {
    "step": 1060,
    "epoch": 0.47100644301266387,
    "loss": 0.9551,
    "grad_norm": 2.7941787242889404,
    "learning_rate": 1.8792184724689168e-05
  },
  {
    "step": 1070,
    "epoch": 0.47544990002221726,
    "loss": 1.0431,
    "grad_norm": 1.3083739280700684,
    "learning_rate": 1.896980461811723e-05
  },
  {
    "step": 1080,
    "epoch": 0.4798933570317707,
    "loss": 0.9298,
    "grad_norm": 1.8501712083816528,
    "learning_rate": 1.9147424511545296e-05
  },
  {
    "step": 1090,
    "epoch": 0.48433681404132417,
    "loss": 0.8794,
    "grad_norm": 2.407371759414673,
    "learning_rate": 1.932504440497336e-05
  },
  {
    "step": 1100,
    "epoch": 0.48878027105087757,
    "loss": 0.9004,
    "grad_norm": 1.9103068113327026,
    "learning_rate": 1.9502664298401424e-05
  },
  {
    "step": 1110,
    "epoch": 0.493223728060431,
    "loss": 0.9769,
    "grad_norm": 2.1347100734710693,
    "learning_rate": 1.9680284191829488e-05
  },
  {
    "step": 1120,
    "epoch": 0.4976671850699845,
    "loss": 0.8747,
    "grad_norm": 1.5993915796279907,
    "learning_rate": 1.9857904085257552e-05
  },
  {
    "step": 1130,
    "epoch": 0.5021106420795379,
    "loss": 0.8997,
    "grad_norm": 4.696140289306641,
    "learning_rate": 1.999999807603758e-05
  },
  {
    "step": 1140,
    "epoch": 0.5065540990890913,
    "loss": 0.9324,
    "grad_norm": 1.527108073234558,
    "learning_rate": 1.999993073743062e-05
  },
  {
    "step": 1150,
    "epoch": 0.5109975560986447,
    "loss": 0.8433,
    "grad_norm": 1.571716070175171,
    "learning_rate": 1.999976720144299e-05
  },
  {
    "step": 1160,
    "epoch": 0.5154410131081982,
    "loss": 0.9229,
    "grad_norm": 1.3697139024734497,
    "learning_rate": 1.9999507469647866e-05
  },
  {
    "step": 1170,
    "epoch": 0.5198844701177516,
    "loss": 0.9227,
    "grad_norm": 2.634467124938965,
    "learning_rate": 1.9999151544543834e-05
  },
  {
    "step": 1180,
    "epoch": 0.524327927127305,
    "loss": 0.8743,
    "grad_norm": 1.5114126205444336,
    "learning_rate": 1.999869942955481e-05
  },
  {
    "step": 1190,
    "epoch": 0.5287713841368584,
    "loss": 0.9379,
    "grad_norm": 2.0463271141052246,
    "learning_rate": 1.999815112903006e-05
  },
  {
    "step": 1200,
    "epoch": 0.5332148411464119,
    "loss": 0.8799,
    "grad_norm": 1.6570247411727905,
    "learning_rate": 1.9997506648244126e-05
  },
  {
    "step": 1210,
    "epoch": 0.5376582981559653,
    "loss": 0.8489,
    "grad_norm": 1.874881386756897,
    "learning_rate": 1.9996765993396784e-05
  },
  {
    "step": 1220,
    "epoch": 0.5421017551655187,
    "loss": 0.9026,
    "grad_norm": 1.7879925966262817,
    "learning_rate": 1.9995929171612994e-05
  },
  {
    "step": 1230,
    "epoch": 0.5465452121750722,
    "loss": 0.877,
    "grad_norm": 2.7293405532836914,
    "learning_rate": 1.9994996190942812e-05
  },
  {
    "step": 1240,
    "epoch": 0.5509886691846256,
    "loss": 0.9417,
    "grad_norm": 1.4242842197418213,
    "learning_rate": 1.9993967060361338e-05
  },
  {
    "step": 1250,
    "epoch": 0.555432126194179,
    "loss": 0.8946,
    "grad_norm": 1.693068504333496,
    "learning_rate": 1.99928417897686e-05
  },
  {
    "step": 1260,
    "epoch": 0.5598755832037325,
    "loss": 0.8863,
    "grad_norm": 2.1313529014587402,
    "learning_rate": 1.9991620389989485e-05
  },
  {
    "step": 1270,
    "epoch": 0.5643190402132859,
    "loss": 0.9122,
    "grad_norm": 1.5249029397964478,
    "learning_rate": 1.9990302872773614e-05
  },
  {
    "step": 1280,
    "epoch": 0.5687624972228393,
    "loss": 0.8545,
    "grad_norm": 1.4499967098236084,
    "learning_rate": 1.9988889250795255e-05
  },
  {
    "step": 1290,
    "epoch": 0.5732059542323928,
    "loss": 0.9666,
    "grad_norm": 1.7061660289764404,
    "learning_rate": 1.998737953765317e-05
  },
  {
    "step": 1300,
    "epoch": 0.5776494112419462,
    "loss": 0.9679,
    "grad_norm": 1.2506558895111084,
    "learning_rate": 1.9985773747870506e-05
  },
  {
    "step": 1310,
    "epoch": 0.5820928682514996,
    "loss": 0.9054,
    "grad_norm": 1.6214652061462402,
    "learning_rate": 1.9984071896894644e-05
  },
  {
    "step": 1320,
    "epoch": 0.5865363252610531,
    "loss": 0.8792,
    "grad_norm": 2.1228129863739014,
    "learning_rate": 1.9982274001097066e-05
  },
  {
    "step": 1330,
    "epoch": 0.5909797822706065,
    "loss": 0.8452,
    "grad_norm": 1.0585805177688599,
    "learning_rate": 1.998038007777317e-05
  },
  {
    "step": 1340,
    "epoch": 0.5954232392801599,
    "loss": 0.9095,
    "grad_norm": 0.9081672430038452,
    "learning_rate": 1.997839014514213e-05
  },
  {
    "step": 1350,
    "epoch": 0.5998666962897135,
    "loss": 0.8984,
    "grad_norm": 1.4625921249389648,
    "learning_rate": 1.9976304222346713e-05
  },
  {
    "step": 1360,
    "epoch": 0.6043101532992669,
    "loss": 0.9141,
    "grad_norm": 1.4792637825012207,
    "learning_rate": 1.9974122329453088e-05
  },
  {
    "step": 1370,
    "epoch": 0.6087536103088202,
    "loss": 0.9071,
    "grad_norm": 0.9399383068084717,
    "learning_rate": 1.9971844487450633e-05
  },
  {
    "step": 1380,
    "epoch": 0.6131970673183736,
    "loss": 0.9015,
    "grad_norm": 1.4185657501220703,
    "learning_rate": 1.996947071825175e-05
  },
  {
    "step": 1390,
    "epoch": 0.6176405243279272,
    "loss": 0.9184,
    "grad_norm": 1.8439898490905762,
    "learning_rate": 1.996700104469163e-05
  },
  {
    "step": 1400,
    "epoch": 0.6220839813374806,
    "loss": 0.8617,
    "grad_norm": 1.7193925380706787,
    "learning_rate": 1.9964435490528053e-05
  },
  {
    "step": 1410,
    "epoch": 0.626527438347034,
    "loss": 0.9124,
    "grad_norm": 2.648144483566284,
    "learning_rate": 1.9961774080441152e-05
  },
  {
    "step": 1420,
    "epoch": 0.6309708953565875,
    "loss": 0.972,
    "grad_norm": 1.3107783794403076,
    "learning_rate": 1.995901684003317e-05
  },
  {
    "step": 1430,
    "epoch": 0.6354143523661409,
    "loss": 0.9292,
    "grad_norm": 1.1988368034362793,
    "learning_rate": 1.9956163795828212e-05
  },
  {
    "step": 1440,
    "epoch": 0.6398578093756943,
    "loss": 0.9604,
    "grad_norm": 2.9486939907073975,
    "learning_rate": 1.995321497527202e-05
  },
  {
    "step": 1450,
    "epoch": 0.6443012663852478,
    "loss": 0.8436,
    "grad_norm": 2.4242711067199707,
    "learning_rate": 1.9950170406731668e-05
  },
  {
    "step": 1460,
    "epoch": 0.6487447233948012,
    "loss": 0.8995,
    "grad_norm": 1.3683120012283325,
    "learning_rate": 1.9947030119495308e-05
  },
  {
    "step": 1470,
    "epoch": 0.6531881804043546,
    "loss": 0.8181,
    "grad_norm": 1.2229657173156738,
    "learning_rate": 1.9943794143771887e-05
  },
  {
    "step": 1480,
    "epoch": 0.6576316374139081,
    "loss": 0.8806,
    "grad_norm": 2.903233051300049,
    "learning_rate": 1.9940462510690864e-05
  },
  {
    "step": 1490,
    "epoch": 0.6620750944234615,
    "loss": 0.9175,
    "grad_norm": 1.6772830486297607,
    "learning_rate": 1.99370352523019e-05
  },
  {
    "step": 1500,
    "epoch": 0.6665185514330149,
    "loss": 0.8272,
    "grad_norm": 2.934760093688965,
    "learning_rate": 1.993351240157455e-05
  },
  {
    "step": 1500,
    "epoch": 0.6665185514330149,
    "eval_loss": 0.8645132780075073,
    "eval_f1": 0.2884939680892463,
    "eval_precision": 0.41215715344699777,
    "eval_recall": 0.22191179405308323,
    "eval_runtime": 39.3651,
    "eval_samples_per_second": 50.832,
    "eval_steps_per_second": 6.376
  },
  {
    "step": 1510,
    "epoch": 0.6709620084425684,
    "loss": 0.8834,
    "grad_norm": 1.1376994848251343,
    "learning_rate": 1.9929893992397948e-05
  },
  {
    "step": 1520,
    "epoch": 0.6754054654521218,
    "loss": 0.8721,
    "grad_norm": 2.111264705657959,
    "learning_rate": 1.992618005958048e-05
  },
  {
    "step": 1530,
    "epoch": 0.6798489224616752,
    "loss": 0.9181,
    "grad_norm": 1.703609585762024,
    "learning_rate": 1.9922370638849466e-05
  },
  {
    "step": 1540,
    "epoch": 0.6842923794712286,
    "loss": 0.8716,
    "grad_norm": 0.9760016798973083,
    "learning_rate": 1.991846576685078e-05
  },
  {
    "step": 1550,
    "epoch": 0.6887358364807821,
    "loss": 0.8603,
    "grad_norm": 3.17802357673645,
    "learning_rate": 1.991446548114853e-05
  },
  {
    "step": 1560,
    "epoch": 0.6931792934903355,
    "loss": 0.9337,
    "grad_norm": 1.4078484773635864,
    "learning_rate": 1.9910369820224683e-05
  },
  {
    "step": 1570,
    "epoch": 0.6976227504998889,
    "loss": 0.9637,
    "grad_norm": 1.1846116781234741,
    "learning_rate": 1.9906178823478698e-05
  },
  {
    "step": 1580,
    "epoch": 0.7020662075094424,
    "loss": 0.8722,
    "grad_norm": 1.513060212135315,
    "learning_rate": 1.9901892531227146e-05
  },
  {
    "step": 1590,
    "epoch": 0.7065096645189958,
    "loss": 0.8509,
    "grad_norm": 1.2356799840927124,
    "learning_rate": 1.9897510984703317e-05
  },
  {
    "step": 1600,
    "epoch": 0.7109531215285492,
    "loss": 0.8763,
    "grad_norm": 2.0685415267944336,
    "learning_rate": 1.989303422605684e-05
  },
  {
    "step": 1610,
    "epoch": 0.7153965785381027,
    "loss": 0.86,
    "grad_norm": 1.1289223432540894,
    "learning_rate": 1.9888462298353255e-05
  },
  {
    "step": 1620,
    "epoch": 0.7198400355476561,
    "loss": 0.9209,
    "grad_norm": 3.500856637954712,
    "learning_rate": 1.9883795245573615e-05
  },
  {
    "step": 1630,
    "epoch": 0.7242834925572095,
    "loss": 0.9155,
    "grad_norm": 0.9357694983482361,
    "learning_rate": 1.987903311261405e-05
  },
  {
    "step": 1640,
    "epoch": 0.728726949566763,
    "loss": 0.8302,
    "grad_norm": 1.248526692390442,
    "learning_rate": 1.9874175945285356e-05
  },
  {
    "step": 1650,
    "epoch": 0.7331704065763164,
    "loss": 0.898,
    "grad_norm": 0.8956077098846436,
    "learning_rate": 1.986922379031253e-05
  },
  {
    "step": 1660,
    "epoch": 0.7376138635858698,
    "loss": 0.8965,
    "grad_norm": 2.0848708152770996,
    "learning_rate": 1.986417669533434e-05
  },
  {
    "step": 1670,
    "epoch": 0.7420573205954233,
    "loss": 0.9135,
    "grad_norm": 2.07122802734375,
    "learning_rate": 1.9859034708902853e-05
  },
  {
    "step": 1680,
    "epoch": 0.7465007776049767,
    "loss": 0.9098,
    "grad_norm": 1.8553369045257568,
    "learning_rate": 1.985379788048297e-05
  },
  {
    "step": 1690,
    "epoch": 0.7509442346145301,
    "loss": 0.8383,
    "grad_norm": 1.9760273694992065,
    "learning_rate": 1.9848466260451964e-05
  },
  {
    "step": 1700,
    "epoch": 0.7553876916240836,
    "loss": 0.8904,
    "grad_norm": 1.8449522256851196,
    "learning_rate": 1.984303990009897e-05
  },
  {
    "step": 1710,
    "epoch": 0.759831148633637,
    "loss": 0.8521,
    "grad_norm": 0.7816470265388489,
    "learning_rate": 1.9837518851624523e-05
  },
  {
    "step": 1720,
    "epoch": 0.7642746056431904,
    "loss": 0.9247,
    "grad_norm": 2.560896396636963,
    "learning_rate": 1.983190316814003e-05
  },
  {
    "step": 1730,
    "epoch": 0.7687180626527438,
    "loss": 0.8675,
    "grad_norm": 1.2622485160827637,
    "learning_rate": 1.9826192903667262e-05
  },
  {
    "step": 1740,
    "epoch": 0.7731615196622973,
    "loss": 0.8489,
    "grad_norm": 1.058362603187561,
    "learning_rate": 1.9820388113137853e-05
  },
  {
    "step": 1750,
    "epoch": 0.7776049766718507,
    "loss": 0.8645,
    "grad_norm": 1.5934783220291138,
    "learning_rate": 1.9814488852392757e-05
  },
  {
    "step": 1760,
    "epoch": 0.7820484336814041,
    "loss": 0.8315,
    "grad_norm": 2.972032070159912,
    "learning_rate": 1.9808495178181707e-05
  },
  {
    "step": 1770,
    "epoch": 0.7864918906909576,
    "loss": 0.8391,
    "grad_norm": 1.5541527271270752,
    "learning_rate": 1.980240714816268e-05
  },
  {
    "step": 1780,
    "epoch": 0.790935347700511,
    "loss": 0.8715,
    "grad_norm": 0.9400880336761475,
    "learning_rate": 1.979622482090133e-05
  },
  {
    "step": 1790,
    "epoch": 0.7953788047100644,
    "loss": 0.9934,
    "grad_norm": 1.1710363626480103,
    "learning_rate": 1.9789948255870445e-05
  },
  {
    "step": 1800,
    "epoch": 0.7998222617196179,
    "loss": 0.8526,
    "grad_norm": 2.1549909114837646,
    "learning_rate": 1.978357751344935e-05
  },
  {
    "step": 1810,
    "epoch": 0.8042657187291713,
    "loss": 0.9107,
    "grad_norm": 1.6373196840286255,
    "learning_rate": 1.977711265492335e-05
  },
  {
    "step": 1820,
    "epoch": 0.8087091757387247,
    "loss": 0.9853,
    "grad_norm": 1.218651294708252,
    "learning_rate": 1.9770553742483113e-05
  },
  {
    "step": 1830,
    "epoch": 0.8131526327482782,
    "loss": 0.8357,
    "grad_norm": 1.5695242881774902,
    "learning_rate": 1.97639008392241e-05
  },
  {
    "step": 1840,
    "epoch": 0.8175960897578316,
    "loss": 0.9225,
    "grad_norm": 1.451088547706604,
    "learning_rate": 1.975715400914594e-05
  },
  {
    "step": 1850,
    "epoch": 0.822039546767385,
    "loss": 0.8338,
    "grad_norm": 0.8360202312469482,
    "learning_rate": 1.975031331715182e-05
  },
  {
    "step": 1860,
    "epoch": 0.8264830037769385,
    "loss": 0.9092,
    "grad_norm": 1.2381848096847534,
    "learning_rate": 1.9743378829047864e-05
  },
  {
    "step": 1870,
    "epoch": 0.8309264607864919,
    "loss": 0.8768,
    "grad_norm": 1.4260793924331665,
    "learning_rate": 1.9736350611542487e-05
  },
  {
    "step": 1880,
    "epoch": 0.8353699177960453,
    "loss": 0.8995,
    "grad_norm": 0.9043282866477966,
    "learning_rate": 1.9729228732245777e-05
  },
  {
    "step": 1890,
    "epoch": 0.8398133748055988,
    "loss": 0.8693,
    "grad_norm": 2.5896005630493164,
    "learning_rate": 1.9722013259668817e-05
  },
  {
    "step": 1900,
    "epoch": 0.8442568318151522,
    "loss": 0.8837,
    "grad_norm": 1.3038442134857178,
    "learning_rate": 1.9714704263223044e-05
  },
  {
    "step": 1910,
    "epoch": 0.8487002888247056,
    "loss": 0.8317,
    "grad_norm": 1.783197283744812,
    "learning_rate": 1.9707301813219575e-05
  },
  {
    "step": 1920,
    "epoch": 0.853143745834259,
    "loss": 0.8213,
    "grad_norm": 1.782646656036377,
    "learning_rate": 1.9699805980868535e-05
  },
  {
    "step": 1930,
    "epoch": 0.8575872028438125,
    "loss": 0.8133,
    "grad_norm": 2.7438037395477295,
    "learning_rate": 1.9692216838278372e-05
  },
  {
    "step": 1940,
    "epoch": 0.8620306598533659,
    "loss": 0.8939,
    "grad_norm": 2.0570788383483887,
    "learning_rate": 1.9684534458455147e-05
  },
  {
    "step": 1950,
    "epoch": 0.8664741168629193,
    "loss": 0.9494,
    "grad_norm": 0.8017882704734802,
    "learning_rate": 1.9676758915301858e-05
  },
  {
    "step": 1960,
    "epoch": 0.8709175738724728,
    "loss": 0.884,
    "grad_norm": 1.7666542530059814,
    "learning_rate": 1.9668890283617713e-05
  },
  {
    "step": 1970,
    "epoch": 0.8753610308820262,
    "loss": 0.8146,
    "grad_norm": 1.5410616397857666,
    "learning_rate": 1.966092863909741e-05
  },
  {
    "step": 1980,
    "epoch": 0.8798044878915796,
    "loss": 0.752,
    "grad_norm": 1.0648601055145264,
    "learning_rate": 1.965287405833041e-05
  },
  {
    "step": 1990,
    "epoch": 0.8842479449011331,
    "loss": 0.817,
    "grad_norm": 0.6462675333023071,
    "learning_rate": 1.9644726618800217e-05
  },
  {
    "step": 2000,
    "epoch": 0.8886914019106865,
    "loss": 0.9251,
    "grad_norm": 2.076558828353882,
    "learning_rate": 1.96364863988836e-05
  },
  {
    "step": 2000,
    "epoch": 0.8886914019106865,
    "eval_loss": 0.834928035736084,
    "eval_f1": 0.3402954661232807,
    "eval_precision": 0.4702569517775431,
    "eval_recall": 0.2666134504091,
    "eval_runtime": 39.5564,
    "eval_samples_per_second": 50.586,
    "eval_steps_per_second": 6.345
  },
  {
    "step": 2010,
    "epoch": 0.8931348589202399,
    "loss": 0.8956,
    "grad_norm": 1.9371494054794312,
    "learning_rate": 1.9628153477849867e-05
  },
  {
    "step": 2020,
    "epoch": 0.8975783159297934,
    "loss": 0.8398,
    "grad_norm": 1.4334532022476196,
    "learning_rate": 1.9619727935860095e-05
  },
  {
    "step": 2030,
    "epoch": 0.9020217729393468,
    "loss": 0.9135,
    "grad_norm": 1.678261399269104,
    "learning_rate": 1.9611209853966343e-05
  },
  {
    "step": 2040,
    "epoch": 0.9064652299489002,
    "loss": 0.7974,
    "grad_norm": 1.9912545680999756,
    "learning_rate": 1.9602599314110905e-05
  },
  {
    "step": 2050,
    "epoch": 0.9109086869584537,
    "loss": 0.9448,
    "grad_norm": 1.375253677368164,
    "learning_rate": 1.959389639912549e-05
  },
  {
    "step": 2060,
    "epoch": 0.9153521439680071,
    "loss": 0.7862,
    "grad_norm": 1.5246518850326538,
    "learning_rate": 1.9585101192730437e-05
  },
  {
    "step": 2070,
    "epoch": 0.9197956009775605,
    "loss": 0.8915,
    "grad_norm": 1.4973050355911255,
    "learning_rate": 1.9576213779533918e-05
  },
  {
    "step": 2080,
    "epoch": 0.9242390579871139,
    "loss": 0.8815,
    "grad_norm": 1.0333483219146729,
    "learning_rate": 1.9567234245031108e-05
  },
  {
    "step": 2090,
    "epoch": 0.9286825149966674,
    "loss": 0.9446,
    "grad_norm": 2.828660726547241,
    "learning_rate": 1.955816267560338e-05
  },
  {
    "step": 2100,
    "epoch": 0.9331259720062208,
    "loss": 0.9141,
    "grad_norm": 1.2625819444656372,
    "learning_rate": 1.9548999158517455e-05
  },
  {
    "step": 2110,
    "epoch": 0.9375694290157742,
    "loss": 0.8222,
    "grad_norm": 1.8356587886810303,
    "learning_rate": 1.9539743781924584e-05
  },
  {
    "step": 2120,
    "epoch": 0.9420128860253277,
    "loss": 0.7946,
    "grad_norm": 0.7954835295677185,
    "learning_rate": 1.9530396634859675e-05
  },
  {
    "step": 2130,
    "epoch": 0.9464563430348811,
    "loss": 0.8481,
    "grad_norm": 1.8961156606674194,
    "learning_rate": 1.9520957807240465e-05
  },
  {
    "step": 2140,
    "epoch": 0.9508998000444345,
    "loss": 0.9228,
    "grad_norm": 4.335397243499756,
    "learning_rate": 1.9511427389866624e-05
  },
  {
    "step": 2150,
    "epoch": 0.955343257053988,
    "loss": 0.9653,
    "grad_norm": 0.8383762836456299,
    "learning_rate": 1.9501805474418912e-05
  },
  {
    "step": 2160,
    "epoch": 0.9597867140635414,
    "loss": 0.8772,
    "grad_norm": 1.9472135305404663,
    "learning_rate": 1.9492092153458274e-05
  },
  {
    "step": 2170,
    "epoch": 0.9642301710730948,
    "loss": 0.849,
    "grad_norm": 1.0470695495605469,
    "learning_rate": 1.948228752042496e-05
  },
  {
    "step": 2180,
    "epoch": 0.9686736280826483,
    "loss": 0.8368,
    "grad_norm": 1.1332383155822754,
    "learning_rate": 1.9472391669637626e-05
  },
  {
    "step": 2190,
    "epoch": 0.9731170850922017,
    "loss": 0.8764,
    "grad_norm": 1.304438591003418,
    "learning_rate": 1.9462404696292422e-05
  },
  {
    "step": 2200,
    "epoch": 0.9775605421017551,
    "loss": 0.7931,
    "grad_norm": 1.0059975385665894,
    "learning_rate": 1.9452326696462088e-05
  },
  {
    "step": 2210,
    "epoch": 0.9820039991113086,
    "loss": 0.8338,
    "grad_norm": 1.3006350994110107,
    "learning_rate": 1.9442157767095003e-05
  },
  {
    "step": 2220,
    "epoch": 0.986447456120862,
    "loss": 0.7989,
    "grad_norm": 1.5037175416946411,
    "learning_rate": 1.943189800601429e-05
  },
  {
    "step": 2230,
    "epoch": 0.9908909131304154,
    "loss": 0.7565,
    "grad_norm": 1.6733266115188599,
    "learning_rate": 1.9421547511916846e-05
  },
  {
    "step": 2240,
    "epoch": 0.995334370139969,
    "loss": 0.8267,
    "grad_norm": 1.7091691493988037,
    "learning_rate": 1.94111063843724e-05
  },
  {
    "step": 2250,
    "epoch": 0.9997778271495223,
    "loss": 0.8935,
    "grad_norm": 0.9681334495544434,
    "learning_rate": 1.940057472382256e-05
  },
  {
    "step": 2260,
    "epoch": 1.003999111308598,
    "loss": 0.8835,
    "grad_norm": 0.8935150504112244,
    "learning_rate": 1.9389952631579845e-05
  },
  {
    "step": 2270,
    "epoch": 1.0084425683181515,
    "loss": 0.8242,
    "grad_norm": 0.6592676639556885,
    "learning_rate": 1.9379240209826705e-05
  },
  {
    "step": 2280,
    "epoch": 1.012886025327705,
    "loss": 0.8188,
    "grad_norm": 0.7490793466567993,
    "learning_rate": 1.936843756161455e-05
  },
  {
    "step": 2290,
    "epoch": 1.0173294823372583,
    "loss": 0.8525,
    "grad_norm": 1.5999125242233276,
    "learning_rate": 1.9357544790862743e-05
  },
  {
    "step": 2300,
    "epoch": 1.0217729393468118,
    "loss": 0.8492,
    "grad_norm": 2.1684823036193848,
    "learning_rate": 1.934656200235761e-05
  },
  {
    "step": 2310,
    "epoch": 1.0262163963563653,
    "loss": 0.8165,
    "grad_norm": 1.1122649908065796,
    "learning_rate": 1.9335489301751433e-05
  },
  {
    "step": 2320,
    "epoch": 1.0306598533659186,
    "loss": 0.8128,
    "grad_norm": 1.4920114278793335,
    "learning_rate": 1.932432679556143e-05
  },
  {
    "step": 2330,
    "epoch": 1.035103310375472,
    "loss": 0.8708,
    "grad_norm": 1.5475714206695557,
    "learning_rate": 1.9313074591168728e-05
  },
  {
    "step": 2340,
    "epoch": 1.0395467673850256,
    "loss": 0.9004,
    "grad_norm": 0.8346595168113708,
    "learning_rate": 1.9301732796817337e-05
  },
  {
    "step": 2350,
    "epoch": 1.043990224394579,
    "loss": 0.8602,
    "grad_norm": 1.9595084190368652,
    "learning_rate": 1.9290301521613108e-05
  },
  {
    "step": 2360,
    "epoch": 1.0484336814041324,
    "loss": 0.8327,
    "grad_norm": 1.210796594619751,
    "learning_rate": 1.9278780875522668e-05
  },
  {
    "step": 2370,
    "epoch": 1.052877138413686,
    "loss": 0.7986,
    "grad_norm": 0.8152985572814941,
    "learning_rate": 1.9267170969372388e-05
  },
  {
    "step": 2380,
    "epoch": 1.0573205954232392,
    "loss": 0.8439,
    "grad_norm": 1.1084182262420654,
    "learning_rate": 1.9255471914847296e-05
  },
  {
    "step": 2390,
    "epoch": 1.0617640524327927,
    "loss": 0.8169,
    "grad_norm": 1.0935781002044678,
    "learning_rate": 1.924368382449001e-05
  },
  {
    "step": 2400,
    "epoch": 1.0662075094423462,
    "loss": 0.898,
    "grad_norm": 1.0708253383636475,
    "learning_rate": 1.923180681169966e-05
  },
  {
    "step": 2410,
    "epoch": 1.0706509664518995,
    "loss": 0.8067,
    "grad_norm": 2.4790985584259033,
    "learning_rate": 1.9219840990730787e-05
  },
  {
    "step": 2420,
    "epoch": 1.075094423461453,
    "loss": 0.8732,
    "grad_norm": 1.2692927122116089,
    "learning_rate": 1.9207786476692254e-05
  },
  {
    "step": 2430,
    "epoch": 1.0795378804710065,
    "loss": 0.87,
    "grad_norm": 1.6266839504241943,
    "learning_rate": 1.919564338554613e-05
  },
  {
    "step": 2440,
    "epoch": 1.0839813374805598,
    "loss": 0.8659,
    "grad_norm": 1.7715624570846558,
    "learning_rate": 1.9183411834106577e-05
  },
  {
    "step": 2450,
    "epoch": 1.0884247944901133,
    "loss": 0.8127,
    "grad_norm": 0.9097241163253784,
    "learning_rate": 1.917109194003874e-05
  },
  {
    "step": 2460,
    "epoch": 1.0928682514996668,
    "loss": 0.8715,
    "grad_norm": 1.213839054107666,
    "learning_rate": 1.9158683821857587e-05
  },
  {
    "step": 2470,
    "epoch": 1.09731170850922,
    "loss": 0.8732,
    "grad_norm": 1.2188414335250854,
    "learning_rate": 1.914618759892679e-05
  },
  {
    "step": 2480,
    "epoch": 1.1017551655187736,
    "loss": 0.8097,
    "grad_norm": 1.593318223953247,
    "learning_rate": 1.913360339145758e-05
  },
  {
    "step": 2490,
    "epoch": 1.1061986225283271,
    "loss": 0.8638,
    "grad_norm": 1.314681053161621,
    "learning_rate": 1.912093132050757e-05
  },
  {
    "step": 2500,
    "epoch": 1.1106420795378804,
    "loss": 0.817,
    "grad_norm": 1.6614450216293335,
    "learning_rate": 1.9108171507979606e-05
  },
  {
    "step": 2500,
    "epoch": 1.1106420795378804,
    "eval_loss": 0.8091325759887695,
    "eval_f1": 0.38365408647838034,
    "eval_precision": 0.5132062855232363,
    "eval_recall": 0.30632608261823985,
    "eval_runtime": 39.4391,
    "eval_samples_per_second": 50.736,
    "eval_steps_per_second": 6.364
  },
  {
    "step": 2510,
    "epoch": 1.115085536547434,
    "loss": 0.8277,
    "grad_norm": 1.9796435832977295,
    "learning_rate": 1.9095324076620597e-05
  },
  {
    "step": 2520,
    "epoch": 1.1195289935569874,
    "loss": 0.846,
    "grad_norm": 1.8983033895492554,
    "learning_rate": 1.9082389150020325e-05
  },
  {
    "step": 2530,
    "epoch": 1.1239724505665407,
    "loss": 0.8194,
    "grad_norm": 0.8581651449203491,
    "learning_rate": 1.906936685261025e-05
  },
  {
    "step": 2540,
    "epoch": 1.1284159075760942,
    "loss": 0.8984,
    "grad_norm": 1.5537670850753784,
    "learning_rate": 1.9056257309662335e-05
  },
  {
    "step": 2550,
    "epoch": 1.1328593645856477,
    "loss": 0.8078,
    "grad_norm": 1.4718263149261475,
    "learning_rate": 1.9043060647287824e-05
  },
  {
    "step": 2560,
    "epoch": 1.137302821595201,
    "loss": 0.8302,
    "grad_norm": 1.227765679359436,
    "learning_rate": 1.9029776992436032e-05
  },
  {
    "step": 2570,
    "epoch": 1.1417462786047545,
    "loss": 0.8076,
    "grad_norm": 0.8264322876930237,
    "learning_rate": 1.9016406472893117e-05
  },
  {
    "step": 2580,
    "epoch": 1.1461897356143078,
    "loss": 0.8802,
    "grad_norm": 0.8021348118782043,
    "learning_rate": 1.9002949217280876e-05
  },
  {
    "step": 2590,
    "epoch": 1.1506331926238613,
    "loss": 0.7923,
    "grad_norm": 1.3526852130889893,
    "learning_rate": 1.8989405355055468e-05
  },
  {
    "step": 2600,
    "epoch": 1.1550766496334148,
    "loss": 0.8213,
    "grad_norm": 0.6588752269744873,
    "learning_rate": 1.8975775016506213e-05
  },
  {
    "step": 2610,
    "epoch": 1.1595201066429683,
    "loss": 0.8343,
    "grad_norm": 1.906115174293518,
    "learning_rate": 1.89620583327543e-05
  },
  {
    "step": 2620,
    "epoch": 1.1639635636525216,
    "loss": 0.8081,
    "grad_norm": 1.2208739519119263,
    "learning_rate": 1.8948255435751553e-05
  },
  {
    "step": 2630,
    "epoch": 1.1684070206620751,
    "loss": 0.7885,
    "grad_norm": 1.574245810508728,
    "learning_rate": 1.893436645827914e-05
  },
  {
    "step": 2640,
    "epoch": 1.1728504776716284,
    "loss": 0.824,
    "grad_norm": 1.059705376625061,
    "learning_rate": 1.892039153394631e-05
  },
  {
    "step": 2650,
    "epoch": 1.177293934681182,
    "loss": 0.7561,
    "grad_norm": 1.3807648420333862,
    "learning_rate": 1.8906330797189115e-05
  },
  {
    "step": 2660,
    "epoch": 1.1817373916907354,
    "loss": 0.832,
    "grad_norm": 0.743744969367981,
    "learning_rate": 1.8892184383269088e-05
  },
  {
    "step": 2670,
    "epoch": 1.186180848700289,
    "loss": 0.7805,
    "grad_norm": 0.6817585229873657,
    "learning_rate": 1.8877952428271967e-05
  },
  {
    "step": 2680,
    "epoch": 1.1906243057098422,
    "loss": 0.8469,
    "grad_norm": 0.7488411068916321,
    "learning_rate": 1.886363506910639e-05
  },
  {
    "step": 2690,
    "epoch": 1.1950677627193957,
    "loss": 0.8531,
    "grad_norm": 1.758238434791565,
    "learning_rate": 1.8849232443502545e-05
  },
  {
    "step": 2700,
    "epoch": 1.199511219728949,
    "loss": 0.8457,
    "grad_norm": 1.16036856174469,
    "learning_rate": 1.8834744690010886e-05
  },
  {
    "step": 2710,
    "epoch": 1.2039546767385025,
    "loss": 0.8363,
    "grad_norm": 1.1080279350280762,
    "learning_rate": 1.8820171948000766e-05
  },
  {
    "step": 2720,
    "epoch": 1.208398133748056,
    "loss": 0.8429,
    "grad_norm": 1.4731683731079102,
    "learning_rate": 1.8805514357659116e-05
  },
  {
    "step": 2730,
    "epoch": 1.2128415907576093,
    "loss": 0.8925,
    "grad_norm": 1.362763524055481,
    "learning_rate": 1.87907720599891e-05
  },
  {
    "step": 2740,
    "epoch": 1.2172850477671628,
    "loss": 0.8225,
    "grad_norm": 1.1925128698349,
    "learning_rate": 1.8775945196808733e-05
  },
  {
    "step": 2750,
    "epoch": 1.2217285047767164,
    "loss": 0.7678,
    "grad_norm": 1.815755009651184,
    "learning_rate": 1.876103391074955e-05
  },
  {
    "step": 2760,
    "epoch": 1.2261719617862696,
    "loss": 0.8227,
    "grad_norm": 0.7663726806640625,
    "learning_rate": 1.8746038345255207e-05
  },
  {
    "step": 2770,
    "epoch": 1.2306154187958231,
    "loss": 0.8149,
    "grad_norm": 2.6165952682495117,
    "learning_rate": 1.8730958644580122e-05
  },
  {
    "step": 2780,
    "epoch": 1.2350588758053767,
    "loss": 0.8483,
    "grad_norm": 0.9403592944145203,
    "learning_rate": 1.871579495378806e-05
  },
  {
    "step": 2790,
    "epoch": 1.23950233281493,
    "loss": 0.8535,
    "grad_norm": 1.697872281074524,
    "learning_rate": 1.870054741875077e-05
  },
  {
    "step": 2800,
    "epoch": 1.2439457898244834,
    "loss": 0.8298,
    "grad_norm": 1.180753469467163,
    "learning_rate": 1.8685216186146565e-05
  },
  {
    "step": 2810,
    "epoch": 1.248389246834037,
    "loss": 0.8327,
    "grad_norm": 0.9853799939155579,
    "learning_rate": 1.86698014034589e-05
  },
  {
    "step": 2820,
    "epoch": 1.2528327038435902,
    "loss": 0.8786,
    "grad_norm": 1.6172066926956177,
    "learning_rate": 1.865430321897498e-05
  },
  {
    "step": 2830,
    "epoch": 1.2572761608531438,
    "loss": 0.8205,
    "grad_norm": 0.9975627660751343,
    "learning_rate": 1.863872178178431e-05
  },
  {
    "step": 2840,
    "epoch": 1.2617196178626973,
    "loss": 0.8021,
    "grad_norm": 1.3521775007247925,
    "learning_rate": 1.8623057241777278e-05
  },
  {
    "step": 2850,
    "epoch": 1.2661630748722505,
    "loss": 0.7551,
    "grad_norm": 1.5417624711990356,
    "learning_rate": 1.8607309749643693e-05
  },
  {
    "step": 2860,
    "epoch": 1.270606531881804,
    "loss": 0.78,
    "grad_norm": 0.8446804285049438,
    "learning_rate": 1.8591479456871356e-05
  },
  {
    "step": 2870,
    "epoch": 1.2750499888913573,
    "loss": 0.8912,
    "grad_norm": 1.8684380054473877,
    "learning_rate": 1.857556651574459e-05
  },
  {
    "step": 2880,
    "epoch": 1.2794934459009109,
    "loss": 0.762,
    "grad_norm": 1.0683637857437134,
    "learning_rate": 1.8559571079342787e-05
  },
  {
    "step": 2890,
    "epoch": 1.2839369029104644,
    "loss": 0.8309,
    "grad_norm": 1.3939393758773804,
    "learning_rate": 1.8543493301538915e-05
  },
  {
    "step": 2900,
    "epoch": 1.2883803599200179,
    "loss": 0.8144,
    "grad_norm": 1.8423545360565186,
    "learning_rate": 1.852733333699806e-05
  },
  {
    "step": 2910,
    "epoch": 1.2928238169295712,
    "loss": 0.8632,
    "grad_norm": 2.789184331893921,
    "learning_rate": 1.851109134117592e-05
  },
  {
    "step": 2920,
    "epoch": 1.2972672739391247,
    "loss": 0.8843,
    "grad_norm": 1.1125532388687134,
    "learning_rate": 1.8494767470317332e-05
  },
  {
    "step": 2930,
    "epoch": 1.301710730948678,
    "loss": 0.7545,
    "grad_norm": 0.6240168213844299,
    "learning_rate": 1.8478361881454732e-05
  },
  {
    "step": 2940,
    "epoch": 1.3061541879582315,
    "loss": 0.8516,
    "grad_norm": 1.058553695678711,
    "learning_rate": 1.8461874732406695e-05
  },
  {
    "step": 2950,
    "epoch": 1.310597644967785,
    "loss": 0.836,
    "grad_norm": 1.2948977947235107,
    "learning_rate": 1.8445306181776365e-05
  },
  {
    "step": 2960,
    "epoch": 1.3150411019773385,
    "loss": 0.8435,
    "grad_norm": 2.4386608600616455,
    "learning_rate": 1.8428656388949965e-05
  },
  {
    "step": 2970,
    "epoch": 1.3194845589868918,
    "loss": 0.8345,
    "grad_norm": 1.4501742124557495,
    "learning_rate": 1.8411925514095254e-05
  },
  {
    "step": 2980,
    "epoch": 1.3239280159964453,
    "loss": 0.8436,
    "grad_norm": 3.1420371532440186,
    "learning_rate": 1.8395113718159976e-05
  },
  {
    "step": 2990,
    "epoch": 1.3283714730059986,
    "loss": 0.7988,
    "grad_norm": 0.5754866003990173,
    "learning_rate": 1.8378221162870328e-05
  },
  {
    "step": 3000,
    "epoch": 1.332814930015552,
    "loss": 0.8627,
    "grad_norm": 1.5057177543640137,
    "learning_rate": 1.8361248010729388e-05
  },
  {
    "step": 3000,
    "epoch": 1.332814930015552,
    "eval_loss": 0.7952356934547424,
    "eval_f1": 0.4219939577039275,
    "eval_precision": 0.5349264705882353,
    "eval_recall": 0.34843344641788065,
    "eval_runtime": 39.685,
    "eval_samples_per_second": 50.422,
    "eval_steps_per_second": 6.325
  },
  {
    "step": 3010,
    "epoch": 1.3372583870251056,
    "loss": 0.8723,
    "grad_norm": 1.6415003538131714,
    "learning_rate": 1.834419442501557e-05
  },
  {
    "step": 3020,
    "epoch": 1.341701844034659,
    "loss": 0.7777,
    "grad_norm": 1.4913249015808105,
    "learning_rate": 1.8327060569781035e-05
  },
  {
    "step": 3030,
    "epoch": 1.3461453010442124,
    "loss": 0.791,
    "grad_norm": 1.5558847188949585,
    "learning_rate": 1.8309846609850127e-05
  },
  {
    "step": 3040,
    "epoch": 1.3505887580537659,
    "loss": 0.8283,
    "grad_norm": 0.6005372405052185,
    "learning_rate": 1.8292552710817774e-05
  },
  {
    "step": 3050,
    "epoch": 1.3550322150633192,
    "loss": 0.7922,
    "grad_norm": 0.7427674531936646,
    "learning_rate": 1.8275179039047914e-05
  },
  {
    "step": 3060,
    "epoch": 1.3594756720728727,
    "loss": 0.7834,
    "grad_norm": 0.6746142506599426,
    "learning_rate": 1.825772576167187e-05
  },
  {
    "step": 3070,
    "epoch": 1.3639191290824262,
    "loss": 0.8425,
    "grad_norm": 1.2069857120513916,
    "learning_rate": 1.824019304658676e-05
  },
  {
    "step": 3080,
    "epoch": 1.3683625860919797,
    "loss": 0.8325,
    "grad_norm": 1.1804168224334717,
    "learning_rate": 1.8222581062453883e-05
  },
  {
    "step": 3090,
    "epoch": 1.372806043101533,
    "loss": 0.8272,
    "grad_norm": 2.0788254737854004,
    "learning_rate": 1.820488997869709e-05
  },
  {
    "step": 3100,
    "epoch": 1.3772495001110865,
    "loss": 0.8205,
    "grad_norm": 0.4300878345966339,
    "learning_rate": 1.8187119965501146e-05
  },
  {
    "step": 3110,
    "epoch": 1.3816929571206398,
    "loss": 0.872,
    "grad_norm": 3.680058479309082,
    "learning_rate": 1.8169271193810106e-05
  },
  {
    "step": 3120,
    "epoch": 1.3861364141301933,
    "loss": 0.8391,
    "grad_norm": 1.5612720251083374,
    "learning_rate": 1.8151343835325676e-05
  },
  {
    "step": 3130,
    "epoch": 1.3905798711397468,
    "loss": 0.794,
    "grad_norm": 1.146183729171753,
    "learning_rate": 1.8133338062505535e-05
  },
  {
    "step": 3140,
    "epoch": 1.3950233281493,
    "loss": 0.8394,
    "grad_norm": 1.6163101196289062,
    "learning_rate": 1.8115254048561707e-05
  },
  {
    "step": 3150,
    "epoch": 1.3994667851588536,
    "loss": 0.8566,
    "grad_norm": 2.2338876724243164,
    "learning_rate": 1.8097091967458866e-05
  },
  {
    "step": 3160,
    "epoch": 1.403910242168407,
    "loss": 0.7933,
    "grad_norm": 1.3339987993240356,
    "learning_rate": 1.8078851993912695e-05
  },
  {
    "step": 3170,
    "epoch": 1.4083536991779604,
    "loss": 0.8294,
    "grad_norm": 1.6653316020965576,
    "learning_rate": 1.806053430338817e-05
  },
  {
    "step": 3180,
    "epoch": 1.412797156187514,
    "loss": 0.8156,
    "grad_norm": 1.1107679605484009,
    "learning_rate": 1.80421390720979e-05
  },
  {
    "step": 3190,
    "epoch": 1.4172406131970674,
    "loss": 0.8351,
    "grad_norm": 1.6188405752182007,
    "learning_rate": 1.8023666477000416e-05
  },
  {
    "step": 3200,
    "epoch": 1.4216840702066207,
    "loss": 0.7604,
    "grad_norm": 0.9696834087371826,
    "learning_rate": 1.8005116695798476e-05
  },
  {
    "step": 3210,
    "epoch": 1.4261275272161742,
    "loss": 0.799,
    "grad_norm": 0.6051840782165527,
    "learning_rate": 1.798648990693735e-05
  },
  {
    "step": 3220,
    "epoch": 1.4305709842257275,
    "loss": 0.8374,
    "grad_norm": 1.3934624195098877,
    "learning_rate": 1.7967786289603115e-05
  },
  {
    "step": 3230,
    "epoch": 1.435014441235281,
    "loss": 0.8792,
    "grad_norm": 1.008629560470581,
    "learning_rate": 1.794900602372091e-05
  },
  {
    "step": 3240,
    "epoch": 1.4394578982448345,
    "loss": 0.8457,
    "grad_norm": 0.6901261210441589,
    "learning_rate": 1.7930149289953226e-05
  },
  {
    "step": 3250,
    "epoch": 1.443901355254388,
    "loss": 0.8204,
    "grad_norm": 1.1243325471878052,
    "learning_rate": 1.7911216269698163e-05
  },
  {
    "step": 3260,
    "epoch": 1.4483448122639413,
    "loss": 0.7822,
    "grad_norm": 0.9959455132484436,
    "learning_rate": 1.7892207145087678e-05
  },
  {
    "step": 3270,
    "epoch": 1.4527882692734948,
    "loss": 0.8387,
    "grad_norm": 1.7582913637161255,
    "learning_rate": 1.7873122098985826e-05
  },
  {
    "step": 3280,
    "epoch": 1.457231726283048,
    "loss": 0.7665,
    "grad_norm": 0.834402859210968,
    "learning_rate": 1.7853961314987042e-05
  },
  {
    "step": 3290,
    "epoch": 1.4616751832926016,
    "loss": 0.8384,
    "grad_norm": 0.8079286217689514,
    "learning_rate": 1.783472497741431e-05
  },
  {
    "step": 3300,
    "epoch": 1.466118640302155,
    "loss": 0.7891,
    "grad_norm": 1.8729126453399658,
    "learning_rate": 1.7815413271317448e-05
  },
  {
    "step": 3310,
    "epoch": 1.4705620973117086,
    "loss": 0.8287,
    "grad_norm": 1.5781522989273071,
    "learning_rate": 1.7796026382471295e-05
  },
  {
    "step": 3320,
    "epoch": 1.475005554321262,
    "loss": 0.8313,
    "grad_norm": 2.048630714416504,
    "learning_rate": 1.7776564497373935e-05
  },
  {
    "step": 3330,
    "epoch": 1.4794490113308154,
    "loss": 0.8279,
    "grad_norm": 1.620091199874878,
    "learning_rate": 1.7757027803244905e-05
  },
  {
    "step": 3340,
    "epoch": 1.4838924683403687,
    "loss": 0.8185,
    "grad_norm": 0.6623244881629944,
    "learning_rate": 1.7737416488023383e-05
  },
  {
    "step": 3350,
    "epoch": 1.4883359253499222,
    "loss": 0.8394,
    "grad_norm": 1.4732476472854614,
    "learning_rate": 1.7717730740366393e-05
  },
  {
    "step": 3360,
    "epoch": 1.4927793823594757,
    "loss": 0.7757,
    "grad_norm": 1.9329959154129028,
    "learning_rate": 1.769797074964698e-05
  },
  {
    "step": 3370,
    "epoch": 1.4972228393690292,
    "loss": 0.8389,
    "grad_norm": 1.3701387643814087,
    "learning_rate": 1.76781367059524e-05
  },
  {
    "step": 3380,
    "epoch": 1.5016662963785825,
    "loss": 0.8175,
    "grad_norm": 3.7628579139709473,
    "learning_rate": 1.765822880008228e-05
  },
  {
    "step": 3390,
    "epoch": 1.506109753388136,
    "loss": 0.7832,
    "grad_norm": 0.9098435044288635,
    "learning_rate": 1.763824722354678e-05
  },
  {
    "step": 3400,
    "epoch": 1.5105532103976893,
    "loss": 0.7946,
    "grad_norm": 0.6833556294441223,
    "learning_rate": 1.761819216856477e-05
  },
  {
    "step": 3410,
    "epoch": 1.5149966674072428,
    "loss": 0.8079,
    "grad_norm": 0.9851319789886475,
    "learning_rate": 1.759806382806196e-05
  },
  {
    "step": 3420,
    "epoch": 1.5194401244167963,
    "loss": 0.8397,
    "grad_norm": 1.292763113975525,
    "learning_rate": 1.7577862395669055e-05
  },
  {
    "step": 3430,
    "epoch": 1.5238835814263498,
    "loss": 0.8279,
    "grad_norm": 1.17168128490448,
    "learning_rate": 1.7557588065719887e-05
  },
  {
    "step": 3440,
    "epoch": 1.5283270384359031,
    "loss": 0.8461,
    "grad_norm": 1.4959694147109985,
    "learning_rate": 1.753724103324955e-05
  },
  {
    "step": 3450,
    "epoch": 1.5327704954454564,
    "loss": 0.7715,
    "grad_norm": 0.7159005999565125,
    "learning_rate": 1.7516821493992527e-05
  },
  {
    "step": 3460,
    "epoch": 1.53721395245501,
    "loss": 0.8292,
    "grad_norm": 1.210334300994873,
    "learning_rate": 1.74963296443808e-05
  },
  {
    "step": 3470,
    "epoch": 1.5416574094645634,
    "loss": 0.76,
    "grad_norm": 1.0989961624145508,
    "learning_rate": 1.7475765681541948e-05
  },
  {
    "step": 3480,
    "epoch": 1.546100866474117,
    "loss": 0.8208,
    "grad_norm": 0.5199999213218689,
    "learning_rate": 1.745512980329729e-05
  },
  {
    "step": 3490,
    "epoch": 1.5505443234836704,
    "loss": 0.8167,
    "grad_norm": 1.9192513227462769,
    "learning_rate": 1.7434422208159933e-05
  },
  {
    "step": 3500,
    "epoch": 1.5549877804932237,
    "loss": 0.8458,
    "grad_norm": 2.3087081909179688,
    "learning_rate": 1.7413643095332907e-05
  },
  {
    "step": 3500,
    "epoch": 1.5549877804932237,
    "eval_loss": 0.786218523979187,
    "eval_f1": 0.46866932644919035,
    "eval_precision": 0.5687838222728567,
    "eval_recall": 0.39852324885252444,
    "eval_runtime": 39.4964,
    "eval_samples_per_second": 50.663,
    "eval_steps_per_second": 6.355
  },
  {
    "step": 3510,
    "epoch": 1.559431237502777,
    "loss": 0.8997,
    "grad_norm": 3.628767967224121,
    "learning_rate": 1.739279266470722e-05
  },
  {
    "step": 3520,
    "epoch": 1.5638746945123305,
    "loss": 0.817,
    "grad_norm": 1.0592772960662842,
    "learning_rate": 1.737187111685993e-05
  },
  {
    "step": 3530,
    "epoch": 1.568318151521884,
    "loss": 0.8346,
    "grad_norm": 1.4885021448135376,
    "learning_rate": 1.7350878653052258e-05
  },
  {
    "step": 3540,
    "epoch": 1.5727616085314375,
    "loss": 0.8612,
    "grad_norm": 1.5517218112945557,
    "learning_rate": 1.7329815475227594e-05
  },
  {
    "step": 3550,
    "epoch": 1.577205065540991,
    "loss": 0.7893,
    "grad_norm": 1.5972678661346436,
    "learning_rate": 1.73086817860096e-05
  },
  {
    "step": 3560,
    "epoch": 1.5816485225505443,
    "loss": 0.9107,
    "grad_norm": 1.9850530624389648,
    "learning_rate": 1.7287477788700238e-05
  },
  {
    "step": 3570,
    "epoch": 1.5860919795600976,
    "loss": 0.8619,
    "grad_norm": 1.0412793159484863,
    "learning_rate": 1.726620368727782e-05
  },
  {
    "step": 3580,
    "epoch": 1.5905354365696511,
    "loss": 0.8207,
    "grad_norm": 0.6953343749046326,
    "learning_rate": 1.7244859686395046e-05
  },
  {
    "step": 3590,
    "epoch": 1.5949788935792046,
    "loss": 0.8512,
    "grad_norm": 1.6685847043991089,
    "learning_rate": 1.7223445991377036e-05
  },
  {
    "step": 3600,
    "epoch": 1.5994223505887581,
    "loss": 0.8684,
    "grad_norm": 1.7881032228469849,
    "learning_rate": 1.7201962808219358e-05
  },
  {
    "step": 3610,
    "epoch": 1.6038658075983114,
    "loss": 0.7744,
    "grad_norm": 0.7988823056221008,
    "learning_rate": 1.7180410343586036e-05
  },
  {
    "step": 3620,
    "epoch": 1.608309264607865,
    "loss": 0.8177,
    "grad_norm": 1.482759952545166,
    "learning_rate": 1.715878880480757e-05
  },
  {
    "step": 3630,
    "epoch": 1.6127527216174182,
    "loss": 0.8194,
    "grad_norm": 1.1328792572021484,
    "learning_rate": 1.713709839987894e-05
  },
  {
    "step": 3640,
    "epoch": 1.6171961786269717,
    "loss": 0.8539,
    "grad_norm": 0.6961564421653748,
    "learning_rate": 1.7115339337457596e-05
  },
  {
    "step": 3650,
    "epoch": 1.6216396356365252,
    "loss": 0.8202,
    "grad_norm": 1.1901326179504395,
    "learning_rate": 1.709351182686149e-05
  },
  {
    "step": 3660,
    "epoch": 1.6260830926460788,
    "loss": 0.8063,
    "grad_norm": 1.450379729270935,
    "learning_rate": 1.7071616078066993e-05
  },
  {
    "step": 3670,
    "epoch": 1.630526549655632,
    "loss": 0.8139,
    "grad_norm": 1.938758373260498,
    "learning_rate": 1.7049652301706938e-05
  },
  {
    "step": 3680,
    "epoch": 1.6349700066651855,
    "loss": 0.7576,
    "grad_norm": 1.275037169456482,
    "learning_rate": 1.7027620709068567e-05
  },
  {
    "step": 3690,
    "epoch": 1.6394134636747388,
    "loss": 0.9162,
    "grad_norm": 1.9036611318588257,
    "learning_rate": 1.7005521512091494e-05
  },
  {
    "step": 3700,
    "epoch": 1.6438569206842923,
    "loss": 0.8363,
    "grad_norm": 1.117032766342163,
    "learning_rate": 1.698335492336568e-05
  },
  {
    "step": 3710,
    "epoch": 1.6483003776938459,
    "loss": 0.8782,
    "grad_norm": 1.0460542440414429,
    "learning_rate": 1.696112115612938e-05
  },
  {
    "step": 3720,
    "epoch": 1.6527438347033994,
    "loss": 0.7851,
    "grad_norm": 1.219823956489563,
    "learning_rate": 1.693882042426709e-05
  },
  {
    "step": 3730,
    "epoch": 1.6571872917129526,
    "loss": 0.7994,
    "grad_norm": 0.7651201486587524,
    "learning_rate": 1.691645294230749e-05
  },
  {
    "step": 3740,
    "epoch": 1.6616307487225062,
    "loss": 0.7818,
    "grad_norm": 1.074705958366394,
    "learning_rate": 1.6894018925421402e-05
  },
  {
    "step": 3750,
    "epoch": 1.6660742057320594,
    "loss": 0.8797,
    "grad_norm": 2.2376716136932373,
    "learning_rate": 1.6871518589419676e-05
  },
  {
    "step": 3760,
    "epoch": 1.670517662741613,
    "loss": 0.7449,
    "grad_norm": 0.7504241466522217,
    "learning_rate": 1.6848952150751156e-05
  },
  {
    "step": 3770,
    "epoch": 1.6749611197511665,
    "loss": 0.8435,
    "grad_norm": 1.0909802913665771,
    "learning_rate": 1.6826319826500568e-05
  },
  {
    "step": 3780,
    "epoch": 1.67940457676072,
    "loss": 0.7985,
    "grad_norm": 1.3599467277526855,
    "learning_rate": 1.6803621834386458e-05
  },
  {
    "step": 3790,
    "epoch": 1.6838480337702733,
    "loss": 0.8155,
    "grad_norm": 1.6796226501464844,
    "learning_rate": 1.6780858392759073e-05
  },
  {
    "step": 3800,
    "epoch": 1.6882914907798265,
    "loss": 0.8242,
    "grad_norm": 0.9146791100502014,
    "learning_rate": 1.6758029720598274e-05
  },
  {
    "step": 3810,
    "epoch": 1.69273494778938,
    "loss": 0.8274,
    "grad_norm": 1.2766897678375244,
    "learning_rate": 1.6735136037511434e-05
  },
  {
    "step": 3820,
    "epoch": 1.6971784047989336,
    "loss": 0.798,
    "grad_norm": 1.2002112865447998,
    "learning_rate": 1.6712177563731312e-05
  },
  {
    "step": 3830,
    "epoch": 1.701621861808487,
    "loss": 0.8415,
    "grad_norm": 1.4809452295303345,
    "learning_rate": 1.668915452011394e-05
  },
  {
    "step": 3840,
    "epoch": 1.7060653188180406,
    "loss": 0.8716,
    "grad_norm": 2.739666223526001,
    "learning_rate": 1.6666067128136497e-05
  },
  {
    "step": 3850,
    "epoch": 1.7105087758275939,
    "loss": 0.7578,
    "grad_norm": 0.8494903445243835,
    "learning_rate": 1.6642915609895195e-05
  },
  {
    "step": 3860,
    "epoch": 1.7149522328371472,
    "loss": 0.7319,
    "grad_norm": 0.6741252541542053,
    "learning_rate": 1.6619700188103106e-05
  },
  {
    "step": 3870,
    "epoch": 1.7193956898467007,
    "loss": 0.8069,
    "grad_norm": 0.968590259552002,
    "learning_rate": 1.6596421086088065e-05
  },
  {
    "step": 3880,
    "epoch": 1.7238391468562542,
    "loss": 0.7609,
    "grad_norm": 2.288017988204956,
    "learning_rate": 1.6573078527790477e-05
  },
  {
    "step": 3890,
    "epoch": 1.7282826038658077,
    "loss": 0.7542,
    "grad_norm": 1.0897687673568726,
    "learning_rate": 1.6549672737761203e-05
  },
  {
    "step": 3900,
    "epoch": 1.7327260608753612,
    "loss": 0.8125,
    "grad_norm": 1.4809035062789917,
    "learning_rate": 1.6526203941159368e-05
  },
  {
    "step": 3910,
    "epoch": 1.7371695178849145,
    "loss": 0.8116,
    "grad_norm": 0.8553247451782227,
    "learning_rate": 1.650267236375021e-05
  },
  {
    "step": 3920,
    "epoch": 1.7416129748944678,
    "loss": 0.7748,
    "grad_norm": 2.413445472717285,
    "learning_rate": 1.6479078231902906e-05
  },
  {
    "step": 3930,
    "epoch": 1.7460564319040213,
    "loss": 0.8244,
    "grad_norm": 1.5232800245285034,
    "learning_rate": 1.64554217725884e-05
  },
  {
    "step": 3940,
    "epoch": 1.7504998889135748,
    "loss": 0.8203,
    "grad_norm": 0.9530349373817444,
    "learning_rate": 1.643170321337721e-05
  },
  {
    "step": 3950,
    "epoch": 1.7549433459231283,
    "loss": 0.8219,
    "grad_norm": 1.8388711214065552,
    "learning_rate": 1.6407922782437245e-05
  },
  {
    "step": 3960,
    "epoch": 1.7593868029326818,
    "loss": 0.8243,
    "grad_norm": 1.9162824153900146,
    "learning_rate": 1.63840807085316e-05
  },
  {
    "step": 3970,
    "epoch": 1.763830259942235,
    "loss": 0.7255,
    "grad_norm": 1.0027536153793335,
    "learning_rate": 1.636017722101638e-05
  },
  {
    "step": 3980,
    "epoch": 1.7682737169517884,
    "loss": 0.8316,
    "grad_norm": 0.8256595730781555,
    "learning_rate": 1.633621254983846e-05
  },
  {
    "step": 3990,
    "epoch": 1.7727171739613419,
    "loss": 0.8289,
    "grad_norm": 1.170169711112976,
    "learning_rate": 1.6312186925533292e-05
  },
  {
    "step": 4000,
    "epoch": 1.7771606309708954,
    "loss": 0.777,
    "grad_norm": 1.7245270013809204,
    "learning_rate": 1.6288100579222696e-05
  },
  {
    "step": 4000,
    "epoch": 1.7771606309708954,
    "eval_loss": 0.7759389281272888,
    "eval_f1": 0.48524365133836656,
    "eval_precision": 0.5684803001876173,
    "eval_recall": 0.4232688086210337,
    "eval_runtime": 39.6049,
    "eval_samples_per_second": 50.524,
    "eval_steps_per_second": 6.338
  },
  {
    "step": 4010,
    "epoch": 1.781604087980449,
    "loss": 0.8001,
    "grad_norm": 1.6715679168701172,
    "learning_rate": 1.6263953742612616e-05
  },
  {
    "step": 4020,
    "epoch": 1.7860475449900022,
    "loss": 0.7865,
    "grad_norm": 1.449970006942749,
    "learning_rate": 1.623974664799091e-05
  },
  {
    "step": 4030,
    "epoch": 1.7904910019995557,
    "loss": 0.7468,
    "grad_norm": 0.7248772978782654,
    "learning_rate": 1.6215479528225094e-05
  },
  {
    "step": 4040,
    "epoch": 1.794934459009109,
    "loss": 0.7777,
    "grad_norm": 1.305329442024231,
    "learning_rate": 1.6191152616760122e-05
  },
  {
    "step": 4050,
    "epoch": 1.7993779160186625,
    "loss": 0.7387,
    "grad_norm": 1.761825680732727,
    "learning_rate": 1.6166766147616134e-05
  },
  {
    "step": 4060,
    "epoch": 1.803821373028216,
    "loss": 0.7901,
    "grad_norm": 1.2556172609329224,
    "learning_rate": 1.6144767597450354e-05
  },
  {
    "step": 4070,
    "epoch": 1.8082648300377695,
    "loss": 0.827,
    "grad_norm": 1.7371405363082886,
    "learning_rate": 1.612026861549185e-05
  },
  {
    "step": 4080,
    "epoch": 1.8127082870473228,
    "loss": 0.7585,
    "grad_norm": 2.025395393371582,
    "learning_rate": 1.6095710757744575e-05
  },
  {
    "step": 4090,
    "epoch": 1.8171517440568763,
    "loss": 0.7938,
    "grad_norm": 1.2801002264022827,
    "learning_rate": 1.607109426045033e-05
  },
  {
    "step": 4100,
    "epoch": 1.8215952010664296,
    "loss": 0.7363,
    "grad_norm": 0.8749489188194275,
    "learning_rate": 1.6046419360415e-05
  },
  {
    "step": 4110,
    "epoch": 1.826038658075983,
    "loss": 0.8219,
    "grad_norm": 1.2999839782714844,
    "learning_rate": 1.6021686295006317e-05
  },
  {
    "step": 4120,
    "epoch": 1.8304821150855366,
    "loss": 0.7851,
    "grad_norm": 1.1274330615997314,
    "learning_rate": 1.5996895302151535e-05
  },
  {
    "step": 4130,
    "epoch": 1.83492557209509,
    "loss": 0.8891,
    "grad_norm": 1.2697904109954834,
    "learning_rate": 1.5972046620335158e-05
  },
  {
    "step": 4140,
    "epoch": 1.8393690291046434,
    "loss": 0.8895,
    "grad_norm": 2.385704517364502,
    "learning_rate": 1.594714048859666e-05
  },
  {
    "step": 4150,
    "epoch": 1.8438124861141967,
    "loss": 0.8355,
    "grad_norm": 1.4475252628326416,
    "learning_rate": 1.592217714652816e-05
  },
  {
    "step": 4160,
    "epoch": 1.8482559431237502,
    "loss": 0.8005,
    "grad_norm": 0.48376938700675964,
    "learning_rate": 1.5897156834272132e-05
  },
  {
    "step": 4170,
    "epoch": 1.8526994001333037,
    "loss": 0.7942,
    "grad_norm": 0.5218952298164368,
    "learning_rate": 1.5872079792519095e-05
  },
  {
    "step": 4180,
    "epoch": 1.8571428571428572,
    "loss": 0.8816,
    "grad_norm": 2.2140283584594727,
    "learning_rate": 1.5846946262505293e-05
  },
  {
    "step": 4190,
    "epoch": 1.8615863141524107,
    "loss": 0.8204,
    "grad_norm": 2.8049724102020264,
    "learning_rate": 1.582175648601038e-05
  },
  {
    "step": 4200,
    "epoch": 1.866029771161964,
    "loss": 0.7841,
    "grad_norm": 0.6276578903198242,
    "learning_rate": 1.5796510705355077e-05
  },
  {
    "step": 4210,
    "epoch": 1.8704732281715173,
    "loss": 0.7678,
    "grad_norm": 1.7742855548858643,
    "learning_rate": 1.5771209163398873e-05
  },
  {
    "step": 4220,
    "epoch": 1.8749166851810708,
    "loss": 0.7784,
    "grad_norm": 1.7445969581604004,
    "learning_rate": 1.5745852103537655e-05
  },
  {
    "step": 4230,
    "epoch": 1.8793601421906243,
    "loss": 0.8288,
    "grad_norm": 3.204752206802368,
    "learning_rate": 1.5720439769701387e-05
  },
  {
    "step": 4240,
    "epoch": 1.8838035992001778,
    "loss": 0.7842,
    "grad_norm": 1.4557713270187378,
    "learning_rate": 1.5694972406351756e-05
  },
  {
    "step": 4250,
    "epoch": 1.8882470562097313,
    "loss": 0.8228,
    "grad_norm": 1.100028157234192,
    "learning_rate": 1.5669450258479825e-05
  },
  {
    "step": 4260,
    "epoch": 1.8926905132192846,
    "loss": 0.7558,
    "grad_norm": 1.1354608535766602,
    "learning_rate": 1.5643873571603675e-05
  },
  {
    "step": 4270,
    "epoch": 1.897133970228838,
    "loss": 0.741,
    "grad_norm": 0.677173376083374,
    "learning_rate": 1.5618242591766037e-05
  },
  {
    "step": 4280,
    "epoch": 1.9015774272383914,
    "loss": 0.7899,
    "grad_norm": 1.017147421836853,
    "learning_rate": 1.5592557565531928e-05
  },
  {
    "step": 4290,
    "epoch": 1.906020884247945,
    "loss": 0.7506,
    "grad_norm": 1.5256032943725586,
    "learning_rate": 1.5566818739986286e-05
  },
  {
    "step": 4300,
    "epoch": 1.9104643412574984,
    "loss": 0.7148,
    "grad_norm": 1.2374839782714844,
    "learning_rate": 1.5541026362731587e-05
  },
  {
    "step": 4310,
    "epoch": 1.914907798267052,
    "loss": 0.8314,
    "grad_norm": 1.677157998085022,
    "learning_rate": 1.5515180681885462e-05
  },
  {
    "step": 4320,
    "epoch": 1.9193512552766052,
    "loss": 0.8338,
    "grad_norm": 1.1952972412109375,
    "learning_rate": 1.5489281946078308e-05
  },
  {
    "step": 4330,
    "epoch": 1.9237947122861585,
    "loss": 0.826,
    "grad_norm": 1.0568979978561401,
    "learning_rate": 1.5463330404450914e-05
  },
  {
    "step": 4340,
    "epoch": 1.928238169295712,
    "loss": 0.8252,
    "grad_norm": 0.547012448310852,
    "learning_rate": 1.543732630665204e-05
  },
  {
    "step": 4350,
    "epoch": 1.9326816263052655,
    "loss": 0.8283,
    "grad_norm": 0.7039554119110107,
    "learning_rate": 1.5411269902836025e-05
  },
  {
    "step": 4360,
    "epoch": 1.937125083314819,
    "loss": 0.8947,
    "grad_norm": 1.7424684762954712,
    "learning_rate": 1.5385161443660384e-05
  },
  {
    "step": 4370,
    "epoch": 1.9415685403243723,
    "loss": 0.8171,
    "grad_norm": 1.178085207939148,
    "learning_rate": 1.53590011802834e-05
  },
  {
    "step": 4380,
    "epoch": 1.9460119973339258,
    "loss": 0.7885,
    "grad_norm": 1.8038020133972168,
    "learning_rate": 1.5332789364361695e-05
  },
  {
    "step": 4390,
    "epoch": 1.9504554543434791,
    "loss": 0.7583,
    "grad_norm": 1.735389232635498,
    "learning_rate": 1.5306526248047813e-05
  },
  {
    "step": 4400,
    "epoch": 1.9548989113530326,
    "loss": 0.8539,
    "grad_norm": 1.7539581060409546,
    "learning_rate": 1.5280212083987812e-05
  },
  {
    "step": 4410,
    "epoch": 1.9593423683625861,
    "loss": 0.7562,
    "grad_norm": 1.108331561088562,
    "learning_rate": 1.525384712531881e-05
  },
  {
    "step": 4420,
    "epoch": 1.9637858253721396,
    "loss": 0.8571,
    "grad_norm": 3.782870054244995,
    "learning_rate": 1.5227431625666557e-05
  },
  {
    "step": 4430,
    "epoch": 1.968229282381693,
    "loss": 0.8486,
    "grad_norm": 1.8296334743499756,
    "learning_rate": 1.5200965839143003e-05
  },
  {
    "step": 4440,
    "epoch": 1.9726727393912464,
    "loss": 0.7957,
    "grad_norm": 1.1061859130859375,
    "learning_rate": 1.5174450020343843e-05
  },
  {
    "step": 4450,
    "epoch": 1.9771161964007997,
    "loss": 0.8416,
    "grad_norm": 1.107179880142212,
    "learning_rate": 1.514788442434608e-05
  },
  {
    "step": 4460,
    "epoch": 1.9815596534103532,
    "loss": 0.8627,
    "grad_norm": 2.3799171447753906,
    "learning_rate": 1.5121269306705552e-05
  },
  {
    "step": 4470,
    "epoch": 1.9860031104199067,
    "loss": 0.8083,
    "grad_norm": 0.7790019512176514,
    "learning_rate": 1.5094604923454501e-05
  },
  {
    "step": 4480,
    "epoch": 1.9904465674294602,
    "loss": 0.798,
    "grad_norm": 1.438144326210022,
    "learning_rate": 1.5067891531099078e-05
  },
  {
    "step": 4490,
    "epoch": 1.9948900244390135,
    "loss": 0.7179,
    "grad_norm": 1.1524848937988281,
    "learning_rate": 1.5041129386616905e-05
  },
  {
    "step": 4500,
    "epoch": 1.999333481448567,
    "loss": 0.7488,
    "grad_norm": 1.9009968042373657,
    "learning_rate": 1.5014318747454586e-05
  },
  {
    "step": 4500,
    "epoch": 1.999333481448567,
    "eval_loss": 0.7700429558753967,
    "eval_f1": 0.5132664437012263,
    "eval_precision": 0.5814599646375347,
    "eval_recall": 0.4593893434444223,
    "eval_runtime": 39.5206,
    "eval_samples_per_second": 50.632,
    "eval_steps_per_second": 6.351
  },
  {
    "step": 4510,
    "epoch": 2.003554765607643,
    "loss": 0.8531,
    "grad_norm": 2.8289520740509033,
    "learning_rate": 1.498745987152523e-05
  },
  {
    "step": 4520,
    "epoch": 2.007998222617196,
    "loss": 0.7717,
    "grad_norm": 0.5935288667678833,
    "learning_rate": 1.496055301720598e-05
  },
  {
    "step": 4530,
    "epoch": 2.0124416796267495,
    "loss": 0.867,
    "grad_norm": 1.9425876140594482,
    "learning_rate": 1.493359844333552e-05
  },
  {
    "step": 4540,
    "epoch": 2.016885136636303,
    "loss": 0.8116,
    "grad_norm": 1.1458306312561035,
    "learning_rate": 1.4906596409211584e-05
  },
  {
    "step": 4550,
    "epoch": 2.0213285936458565,
    "loss": 0.8363,
    "grad_norm": 0.8850024342536926,
    "learning_rate": 1.4879547174588467e-05
  },
  {
    "step": 4560,
    "epoch": 2.02577205065541,
    "loss": 0.7757,
    "grad_norm": 1.6525905132293701,
    "learning_rate": 1.4852450999674526e-05
  },
  {
    "step": 4570,
    "epoch": 2.0302155076649635,
    "loss": 0.7867,
    "grad_norm": 0.6353015303611755,
    "learning_rate": 1.4825308145129668e-05
  },
  {
    "step": 4580,
    "epoch": 2.0346589646745166,
    "loss": 0.864,
    "grad_norm": 2.1718103885650635,
    "learning_rate": 1.4798118872062856e-05
  },
  {
    "step": 4590,
    "epoch": 2.03910242168407,
    "loss": 0.7567,
    "grad_norm": 0.6804468631744385,
    "learning_rate": 1.4770883442029586e-05
  },
  {
    "step": 4600,
    "epoch": 2.0435458786936236,
    "loss": 0.7637,
    "grad_norm": 0.6308862566947937,
    "learning_rate": 1.4743602117029376e-05
  },
  {
    "step": 4610,
    "epoch": 2.047989335703177,
    "loss": 0.7453,
    "grad_norm": 1.0675677061080933,
    "learning_rate": 1.4716275159503241e-05
  },
  {
    "step": 4620,
    "epoch": 2.0524327927127306,
    "loss": 0.8117,
    "grad_norm": 1.3250095844268799,
    "learning_rate": 1.4688902832331182e-05
  },
  {
    "step": 4630,
    "epoch": 2.056876249722284,
    "loss": 0.8496,
    "grad_norm": 1.0880590677261353,
    "learning_rate": 1.4661485398829633e-05
  },
  {
    "step": 4640,
    "epoch": 2.061319706731837,
    "loss": 0.7857,
    "grad_norm": 0.9046327471733093,
    "learning_rate": 1.4634023122748952e-05
  },
  {
    "step": 4650,
    "epoch": 2.0657631637413907,
    "loss": 0.8031,
    "grad_norm": 1.5749472379684448,
    "learning_rate": 1.4606516268270874e-05
  },
  {
    "step": 4660,
    "epoch": 2.070206620750944,
    "loss": 0.7354,
    "grad_norm": 1.187338948249817,
    "learning_rate": 1.4578965100005965e-05
  },
  {
    "step": 4670,
    "epoch": 2.0746500777604977,
    "loss": 0.7639,
    "grad_norm": 1.3232678174972534,
    "learning_rate": 1.455136988299108e-05
  },
  {
    "step": 4680,
    "epoch": 2.079093534770051,
    "loss": 0.73,
    "grad_norm": 2.3976054191589355,
    "learning_rate": 1.4523730882686824e-05
  },
  {
    "step": 4690,
    "epoch": 2.0835369917796047,
    "loss": 0.7464,
    "grad_norm": 1.1030263900756836,
    "learning_rate": 1.4496048364974977e-05
  },
  {
    "step": 4700,
    "epoch": 2.087980448789158,
    "loss": 0.76,
    "grad_norm": 0.43147918581962585,
    "learning_rate": 1.4468322596155954e-05
  },
  {
    "step": 4710,
    "epoch": 2.0924239057987113,
    "loss": 0.8363,
    "grad_norm": 2.5155301094055176,
    "learning_rate": 1.4440553842946237e-05
  },
  {
    "step": 4720,
    "epoch": 2.096867362808265,
    "loss": 0.8114,
    "grad_norm": 1.1001540422439575,
    "learning_rate": 1.4412742372475808e-05
  },
  {
    "step": 4730,
    "epoch": 2.1013108198178183,
    "loss": 0.7935,
    "grad_norm": 2.0714316368103027,
    "learning_rate": 1.4384888452285577e-05
  },
  {
    "step": 4740,
    "epoch": 2.105754276827372,
    "loss": 0.7621,
    "grad_norm": 0.6048921346664429,
    "learning_rate": 1.4356992350324824e-05
  },
  {
    "step": 4750,
    "epoch": 2.1101977338369253,
    "loss": 0.8336,
    "grad_norm": 2.0984699726104736,
    "learning_rate": 1.4329054334948595e-05
  },
  {
    "step": 4760,
    "epoch": 2.1146411908464784,
    "loss": 0.8175,
    "grad_norm": 0.7507393956184387,
    "learning_rate": 1.4301074674915148e-05
  },
  {
    "step": 4770,
    "epoch": 2.119084647856032,
    "loss": 0.8169,
    "grad_norm": 1.4934369325637817,
    "learning_rate": 1.4273053639383342e-05
  },
  {
    "step": 4780,
    "epoch": 2.1235281048655854,
    "loss": 0.7882,
    "grad_norm": 0.9498410820960999,
    "learning_rate": 1.424499149791007e-05
  },
  {
    "step": 4790,
    "epoch": 2.127971561875139,
    "loss": 0.7532,
    "grad_norm": 0.6646844744682312,
    "learning_rate": 1.421688852044765e-05
  },
  {
    "step": 4800,
    "epoch": 2.1324150188846924,
    "loss": 0.8213,
    "grad_norm": 0.8732770085334778,
    "learning_rate": 1.4188744977341235e-05
  },
  {
    "step": 4810,
    "epoch": 2.136858475894246,
    "loss": 0.7724,
    "grad_norm": 1.0946611166000366,
    "learning_rate": 1.4160561139326216e-05
  },
  {
    "step": 4820,
    "epoch": 2.141301932903799,
    "loss": 0.8406,
    "grad_norm": 0.6685731410980225,
    "learning_rate": 1.4132337277525613e-05
  },
  {
    "step": 4830,
    "epoch": 2.1457453899133525,
    "loss": 0.795,
    "grad_norm": 0.9925941824913025,
    "learning_rate": 1.4104073663447459e-05
  },
  {
    "step": 4840,
    "epoch": 2.150188846922906,
    "loss": 0.7128,
    "grad_norm": 1.1667187213897705,
    "learning_rate": 1.4075770568982208e-05
  },
  {
    "step": 4850,
    "epoch": 2.1546323039324595,
    "loss": 0.8177,
    "grad_norm": 2.380974292755127,
    "learning_rate": 1.4047428266400092e-05
  },
  {
    "step": 4860,
    "epoch": 2.159075760942013,
    "loss": 0.8253,
    "grad_norm": 1.601285696029663,
    "learning_rate": 1.4019047028348532e-05
  },
  {
    "step": 4870,
    "epoch": 2.163519217951566,
    "loss": 0.8131,
    "grad_norm": 1.7017287015914917,
    "learning_rate": 1.3990627127849496e-05
  },
  {
    "step": 4880,
    "epoch": 2.1679626749611196,
    "loss": 0.7461,
    "grad_norm": 0.8736807107925415,
    "learning_rate": 1.3962168838296872e-05
  },
  {
    "step": 4890,
    "epoch": 2.172406131970673,
    "loss": 0.7678,
    "grad_norm": 0.7825061082839966,
    "learning_rate": 1.393367243345385e-05
  },
  {
    "step": 4900,
    "epoch": 2.1768495889802266,
    "loss": 0.8074,
    "grad_norm": 1.098171353340149,
    "learning_rate": 1.3905138187450277e-05
  },
  {
    "step": 4910,
    "epoch": 2.18129304598978,
    "loss": 0.7764,
    "grad_norm": 0.5967170596122742,
    "learning_rate": 1.3876566374780033e-05
  },
  {
    "step": 4920,
    "epoch": 2.1857365029993336,
    "loss": 0.8559,
    "grad_norm": 2.3902902603149414,
    "learning_rate": 1.3847957270298374e-05
  },
  {
    "step": 4930,
    "epoch": 2.1901799600088867,
    "loss": 0.7945,
    "grad_norm": 1.214401364326477,
    "learning_rate": 1.381931114921929e-05
  },
  {
    "step": 4940,
    "epoch": 2.19462341701844,
    "loss": 0.812,
    "grad_norm": 0.7436144948005676,
    "learning_rate": 1.379062828711288e-05
  },
  {
    "step": 4950,
    "epoch": 2.1990668740279937,
    "loss": 0.8466,
    "grad_norm": 1.216408610343933,
    "learning_rate": 1.3761908959902667e-05
  },
  {
    "step": 4960,
    "epoch": 2.2035103310375472,
    "loss": 0.7981,
    "grad_norm": 1.3933000564575195,
    "learning_rate": 1.3733153443862982e-05
  },
  {
    "step": 4970,
    "epoch": 2.2079537880471007,
    "loss": 0.7664,
    "grad_norm": 0.6405065059661865,
    "learning_rate": 1.370436201561626e-05
  },
  {
    "step": 4980,
    "epoch": 2.2123972450566542,
    "loss": 0.8055,
    "grad_norm": 1.7863857746124268,
    "learning_rate": 1.3675534952130423e-05
  },
  {
    "step": 4990,
    "epoch": 2.2168407020662073,
    "loss": 0.8418,
    "grad_norm": 2.222356081008911,
    "learning_rate": 1.3646672530716197e-05
  },
  {
    "step": 5000,
    "epoch": 2.221284159075761,
    "loss": 0.7806,
    "grad_norm": 1.094071626663208,
    "learning_rate": 1.361777502902443e-05
  },
  {
    "step": 5000,
    "epoch": 2.221284159075761,
    "eval_loss": 0.7642229199409485,
    "eval_f1": 0.5215195432586738,
    "eval_precision": 0.5796924578960215,
    "eval_recall": 0.4739572939533027,
    "eval_runtime": 39.3968,
    "eval_samples_per_second": 50.791,
    "eval_steps_per_second": 6.371
  },
  {
    "step": 5010,
    "epoch": 2.2257276160853143,
    "loss": 0.7926,
    "grad_norm": 1.9382578134536743,
    "learning_rate": 1.3588842725043451e-05
  },
  {
    "step": 5020,
    "epoch": 2.230171073094868,
    "loss": 0.8026,
    "grad_norm": 1.2564911842346191,
    "learning_rate": 1.3559875897096371e-05
  },
  {
    "step": 5030,
    "epoch": 2.2346145301044213,
    "loss": 0.7811,
    "grad_norm": 0.7045552730560303,
    "learning_rate": 1.3530874823838419e-05
  },
  {
    "step": 5040,
    "epoch": 2.239057987113975,
    "loss": 0.8013,
    "grad_norm": 1.1135742664337158,
    "learning_rate": 1.3501839784254252e-05
  },
  {
    "step": 5050,
    "epoch": 2.243501444123528,
    "loss": 0.8256,
    "grad_norm": 0.9290090203285217,
    "learning_rate": 1.3472771057655285e-05
  },
  {
    "step": 5060,
    "epoch": 2.2479449011330814,
    "loss": 0.8127,
    "grad_norm": 1.1073760986328125,
    "learning_rate": 1.3443668923676987e-05
  },
  {
    "step": 5070,
    "epoch": 2.252388358142635,
    "loss": 0.7615,
    "grad_norm": 0.9623400568962097,
    "learning_rate": 1.3414533662276209e-05
  },
  {
    "step": 5080,
    "epoch": 2.2568318151521884,
    "loss": 0.7868,
    "grad_norm": 2.2277612686157227,
    "learning_rate": 1.3385365553728467e-05
  },
  {
    "step": 5090,
    "epoch": 2.261275272161742,
    "loss": 0.7734,
    "grad_norm": 0.9029849767684937,
    "learning_rate": 1.3356164878625273e-05
  },
  {
    "step": 5100,
    "epoch": 2.2657187291712955,
    "loss": 0.7845,
    "grad_norm": 0.8941871523857117,
    "learning_rate": 1.332693191787142e-05
  },
  {
    "step": 5110,
    "epoch": 2.2701621861808485,
    "loss": 0.7942,
    "grad_norm": 1.1989586353302002,
    "learning_rate": 1.329766695268228e-05
  },
  {
    "step": 5120,
    "epoch": 2.274605643190402,
    "loss": 0.8223,
    "grad_norm": 0.8178209066390991,
    "learning_rate": 1.3268370264581098e-05
  },
  {
    "step": 5130,
    "epoch": 2.2790491001999555,
    "loss": 0.8269,
    "grad_norm": 1.2570143938064575,
    "learning_rate": 1.3239042135396299e-05
  },
  {
    "step": 5140,
    "epoch": 2.283492557209509,
    "loss": 0.7961,
    "grad_norm": 0.8309704661369324,
    "learning_rate": 1.3209682847258753e-05
  },
  {
    "step": 5150,
    "epoch": 2.2879360142190626,
    "loss": 0.8385,
    "grad_norm": 1.022703766822815,
    "learning_rate": 1.3180292682599078e-05
  },
  {
    "step": 5160,
    "epoch": 2.2923794712286156,
    "loss": 0.7686,
    "grad_norm": 0.998490035533905,
    "learning_rate": 1.3150871924144923e-05
  },
  {
    "step": 5170,
    "epoch": 2.296822928238169,
    "loss": 0.7838,
    "grad_norm": 1.4736616611480713,
    "learning_rate": 1.3121420854918234e-05
  },
  {
    "step": 5180,
    "epoch": 2.3012663852477226,
    "loss": 0.7314,
    "grad_norm": 1.1921136379241943,
    "learning_rate": 1.3091939758232547e-05
  },
  {
    "step": 5190,
    "epoch": 2.305709842257276,
    "loss": 0.7947,
    "grad_norm": 1.1746190786361694,
    "learning_rate": 1.306242891769025e-05
  },
  {
    "step": 5200,
    "epoch": 2.3101532992668297,
    "loss": 0.779,
    "grad_norm": 0.7735558152198792,
    "learning_rate": 1.3032888617179872e-05
  },
  {
    "step": 5210,
    "epoch": 2.314596756276383,
    "loss": 0.8228,
    "grad_norm": 1.3726913928985596,
    "learning_rate": 1.3003319140873329e-05
  },
  {
    "step": 5220,
    "epoch": 2.3190402132859367,
    "loss": 0.7957,
    "grad_norm": 1.9182811975479126,
    "learning_rate": 1.2973720773223208e-05
  },
  {
    "step": 5230,
    "epoch": 2.3234836702954897,
    "loss": 0.7953,
    "grad_norm": 1.6317678689956665,
    "learning_rate": 1.294409379896003e-05
  },
  {
    "step": 5240,
    "epoch": 2.3279271273050433,
    "loss": 0.752,
    "grad_norm": 0.9812506437301636,
    "learning_rate": 1.2914438503089502e-05
  },
  {
    "step": 5250,
    "epoch": 2.3323705843145968,
    "loss": 0.7707,
    "grad_norm": 1.2445616722106934,
    "learning_rate": 1.2884755170889767e-05
  },
  {
    "step": 5260,
    "epoch": 2.3368140413241503,
    "loss": 0.8197,
    "grad_norm": 1.0241163969039917,
    "learning_rate": 1.2855044087908696e-05
  },
  {
    "step": 5270,
    "epoch": 2.341257498333704,
    "loss": 0.8349,
    "grad_norm": 2.6020283699035645,
    "learning_rate": 1.2825305539961104e-05
  },
  {
    "step": 5280,
    "epoch": 2.345700955343257,
    "loss": 0.771,
    "grad_norm": 0.9780529737472534,
    "learning_rate": 1.2795539813126006e-05
  },
  {
    "step": 5290,
    "epoch": 2.3501444123528104,
    "loss": 0.825,
    "grad_norm": 0.9727659225463867,
    "learning_rate": 1.2765747193743886e-05
  },
  {
    "step": 5300,
    "epoch": 2.354587869362364,
    "loss": 0.8112,
    "grad_norm": 1.6027116775512695,
    "learning_rate": 1.2735927968413922e-05
  },
  {
    "step": 5310,
    "epoch": 2.3590313263719174,
    "loss": 0.7345,
    "grad_norm": 1.4389034509658813,
    "learning_rate": 1.270608242399124e-05
  },
  {
    "step": 5320,
    "epoch": 2.363474783381471,
    "loss": 0.8351,
    "grad_norm": 1.5791985988616943,
    "learning_rate": 1.2676210847584147e-05
  },
  {
    "step": 5330,
    "epoch": 2.3679182403910244,
    "loss": 0.8237,
    "grad_norm": 0.9710200428962708,
    "learning_rate": 1.2646313526551374e-05
  },
  {
    "step": 5340,
    "epoch": 2.372361697400578,
    "loss": 0.7703,
    "grad_norm": 1.6171238422393799,
    "learning_rate": 1.2616390748499311e-05
  },
  {
    "step": 5350,
    "epoch": 2.376805154410131,
    "loss": 0.8017,
    "grad_norm": 3.0916855335235596,
    "learning_rate": 1.258644280127924e-05
  },
  {
    "step": 5360,
    "epoch": 2.3812486114196845,
    "loss": 0.8384,
    "grad_norm": 1.445483922958374,
    "learning_rate": 1.2556469972984559e-05
  },
  {
    "step": 5370,
    "epoch": 2.385692068429238,
    "loss": 0.78,
    "grad_norm": 2.014669179916382,
    "learning_rate": 1.2526472551948028e-05
  },
  {
    "step": 5380,
    "epoch": 2.3901355254387915,
    "loss": 0.8076,
    "grad_norm": 0.9195473194122314,
    "learning_rate": 1.2496450826738978e-05
  },
  {
    "step": 5390,
    "epoch": 2.394578982448345,
    "loss": 0.8475,
    "grad_norm": 2.3924171924591064,
    "learning_rate": 1.2466405086160535e-05
  },
  {
    "step": 5400,
    "epoch": 2.399022439457898,
    "loss": 0.778,
    "grad_norm": 0.9736855030059814,
    "learning_rate": 1.2436335619246867e-05
  },
  {
    "step": 5410,
    "epoch": 2.4034658964674516,
    "loss": 0.8645,
    "grad_norm": 2.817110776901245,
    "learning_rate": 1.2406242715260369e-05
  },
  {
    "step": 5420,
    "epoch": 2.407909353477005,
    "loss": 0.7779,
    "grad_norm": 3.1284539699554443,
    "learning_rate": 1.2376126663688894e-05
  },
  {
    "step": 5430,
    "epoch": 2.4123528104865586,
    "loss": 0.8107,
    "grad_norm": 1.2081469297409058,
    "learning_rate": 1.2345987754242983e-05
  },
  {
    "step": 5440,
    "epoch": 2.416796267496112,
    "loss": 0.7596,
    "grad_norm": 0.8502224683761597,
    "learning_rate": 1.2315826276853055e-05
  },
  {
    "step": 5450,
    "epoch": 2.421239724505665,
    "loss": 0.7763,
    "grad_norm": 1.144721508026123,
    "learning_rate": 1.2285642521666636e-05
  },
  {
    "step": 5460,
    "epoch": 2.4256831815152187,
    "loss": 0.7844,
    "grad_norm": 1.297863245010376,
    "learning_rate": 1.225543677904555e-05
  },
  {
    "step": 5470,
    "epoch": 2.430126638524772,
    "loss": 0.7996,
    "grad_norm": 1.1303989887237549,
    "learning_rate": 1.2225209339563144e-05
  },
  {
    "step": 5480,
    "epoch": 2.4345700955343257,
    "loss": 0.7511,
    "grad_norm": 1.0467476844787598,
    "learning_rate": 1.2194960494001485e-05
  },
  {
    "step": 5490,
    "epoch": 2.439013552543879,
    "loss": 0.7603,
    "grad_norm": 2.2525694370269775,
    "learning_rate": 1.2164690533348557e-05
  },
  {
    "step": 5500,
    "epoch": 2.4434570095534327,
    "loss": 0.7384,
    "grad_norm": 0.6578161716461182,
    "learning_rate": 1.2134399748795473e-05
  },
  {
    "step": 5500,
    "epoch": 2.4434570095534327,
    "eval_loss": 0.760423481464386,
    "eval_f1": 0.541024258760108,
    "eval_precision": 0.5884146341463414,
    "eval_recall": 0.5006984633805628,
    "eval_runtime": 39.3698,
    "eval_samples_per_second": 50.826,
    "eval_steps_per_second": 6.375
  },
  {
    "step": 5510,
    "epoch": 2.447900466562986,
    "loss": 0.8009,
    "grad_norm": 1.6535176038742065,
    "learning_rate": 1.2104088431733661e-05
  },
  {
    "step": 5520,
    "epoch": 2.4523439235725393,
    "loss": 0.7413,
    "grad_norm": 1.2782748937606812,
    "learning_rate": 1.2073756873752072e-05
  },
  {
    "step": 5530,
    "epoch": 2.456787380582093,
    "loss": 0.8071,
    "grad_norm": 1.4495056867599487,
    "learning_rate": 1.2043405366634368e-05
  },
  {
    "step": 5540,
    "epoch": 2.4612308375916463,
    "loss": 0.7758,
    "grad_norm": 1.5685559511184692,
    "learning_rate": 1.2013034202356123e-05
  },
  {
    "step": 5550,
    "epoch": 2.4656742946012,
    "loss": 0.7906,
    "grad_norm": 0.873306930065155,
    "learning_rate": 1.1982643673082004e-05
  },
  {
    "step": 5560,
    "epoch": 2.4701177516107533,
    "loss": 0.7868,
    "grad_norm": 1.5878640413284302,
    "learning_rate": 1.1952234071162967e-05
  },
  {
    "step": 5570,
    "epoch": 2.4745612086203064,
    "loss": 0.7471,
    "grad_norm": 0.9947490692138672,
    "learning_rate": 1.1921805689133445e-05
  },
  {
    "step": 5580,
    "epoch": 2.47900466562986,
    "loss": 0.7755,
    "grad_norm": 1.3038103580474854,
    "learning_rate": 1.1891358819708531e-05
  },
  {
    "step": 5590,
    "epoch": 2.4834481226394134,
    "loss": 0.8225,
    "grad_norm": 3.000807762145996,
    "learning_rate": 1.186089375578116e-05
  },
  {
    "step": 5600,
    "epoch": 2.487891579648967,
    "loss": 0.8064,
    "grad_norm": 0.5771362781524658,
    "learning_rate": 1.1830410790419296e-05
  },
  {
    "step": 5610,
    "epoch": 2.4923350366585204,
    "loss": 0.8264,
    "grad_norm": 1.9244495630264282,
    "learning_rate": 1.1799910216863116e-05
  },
  {
    "step": 5620,
    "epoch": 2.496778493668074,
    "loss": 0.7783,
    "grad_norm": 1.1206181049346924,
    "learning_rate": 1.1769392328522178e-05
  },
  {
    "step": 5630,
    "epoch": 2.5012219506776274,
    "loss": 0.8543,
    "grad_norm": 2.8477561473846436,
    "learning_rate": 1.1738857418972609e-05
  },
  {
    "step": 5640,
    "epoch": 2.5056654076871805,
    "loss": 0.7623,
    "grad_norm": 1.279433012008667,
    "learning_rate": 1.1708305781954274e-05
  },
  {
    "step": 5650,
    "epoch": 2.510108864696734,
    "loss": 0.8302,
    "grad_norm": 1.5390843152999878,
    "learning_rate": 1.1677737711367955e-05
  },
  {
    "step": 5660,
    "epoch": 2.5145523217062875,
    "loss": 0.7862,
    "grad_norm": 1.717637300491333,
    "learning_rate": 1.1647153501272523e-05
  },
  {
    "step": 5670,
    "epoch": 2.518995778715841,
    "loss": 0.7977,
    "grad_norm": 0.7120183110237122,
    "learning_rate": 1.1616553445882104e-05
  },
  {
    "step": 5680,
    "epoch": 2.5234392357253945,
    "loss": 0.7657,
    "grad_norm": 1.2767432928085327,
    "learning_rate": 1.1585937839563255e-05
  },
  {
    "step": 5690,
    "epoch": 2.5278826927349476,
    "loss": 0.7971,
    "grad_norm": 1.349489688873291,
    "learning_rate": 1.1555306976832128e-05
  },
  {
    "step": 5700,
    "epoch": 2.532326149744501,
    "loss": 0.7198,
    "grad_norm": 1.0363550186157227,
    "learning_rate": 1.1524661152351642e-05
  },
  {
    "step": 5710,
    "epoch": 2.5367696067540546,
    "loss": 0.774,
    "grad_norm": 0.8959386944770813,
    "learning_rate": 1.1494000660928638e-05
  },
  {
    "step": 5720,
    "epoch": 2.541213063763608,
    "loss": 0.82,
    "grad_norm": 0.9550275206565857,
    "learning_rate": 1.1463325797511062e-05
  },
  {
    "step": 5730,
    "epoch": 2.5456565207731616,
    "loss": 0.7793,
    "grad_norm": 1.0162664651870728,
    "learning_rate": 1.143263685718511e-05
  },
  {
    "step": 5740,
    "epoch": 2.5500999777827147,
    "loss": 0.822,
    "grad_norm": 0.7764655947685242,
    "learning_rate": 1.1401934135172387e-05
  },
  {
    "step": 5750,
    "epoch": 2.5545434347922686,
    "loss": 0.7857,
    "grad_norm": 0.5947567820549011,
    "learning_rate": 1.1371217926827092e-05
  },
  {
    "step": 5760,
    "epoch": 2.5589868918018217,
    "loss": 0.768,
    "grad_norm": 1.098980188369751,
    "learning_rate": 1.1340488527633142e-05
  },
  {
    "step": 5770,
    "epoch": 2.563430348811375,
    "loss": 0.8704,
    "grad_norm": 0.6293540596961975,
    "learning_rate": 1.1309746233201357e-05
  },
  {
    "step": 5780,
    "epoch": 2.5678738058209287,
    "loss": 0.8103,
    "grad_norm": 1.6031489372253418,
    "learning_rate": 1.127899133926661e-05
  },
  {
    "step": 5790,
    "epoch": 2.5723172628304822,
    "loss": 0.7934,
    "grad_norm": 1.0479137897491455,
    "learning_rate": 1.1248224141684969e-05
  },
  {
    "step": 5800,
    "epoch": 2.5767607198400357,
    "loss": 0.7922,
    "grad_norm": 1.1996984481811523,
    "learning_rate": 1.1217444936430869e-05
  },
  {
    "step": 5810,
    "epoch": 2.581204176849589,
    "loss": 0.786,
    "grad_norm": 0.9038667678833008,
    "learning_rate": 1.118665401959425e-05
  },
  {
    "step": 5820,
    "epoch": 2.5856476338591423,
    "loss": 0.7299,
    "grad_norm": 1.2541162967681885,
    "learning_rate": 1.1155851687377723e-05
  },
  {
    "step": 5830,
    "epoch": 2.590091090868696,
    "loss": 0.7531,
    "grad_norm": 0.8228126764297485,
    "learning_rate": 1.1125038236093702e-05
  },
  {
    "step": 5840,
    "epoch": 2.5945345478782493,
    "loss": 0.76,
    "grad_norm": 1.701025366783142,
    "learning_rate": 1.1094213962161578e-05
  },
  {
    "step": 5850,
    "epoch": 2.598978004887803,
    "loss": 0.7943,
    "grad_norm": 1.5639843940734863,
    "learning_rate": 1.106337916210484e-05
  },
  {
    "step": 5860,
    "epoch": 2.603421461897356,
    "loss": 0.7632,
    "grad_norm": 0.6400153636932373,
    "learning_rate": 1.1032534132548245e-05
  },
  {
    "step": 5870,
    "epoch": 2.6078649189069094,
    "loss": 0.8474,
    "grad_norm": 1.7231806516647339,
    "learning_rate": 1.1001679170214955e-05
  },
  {
    "step": 5880,
    "epoch": 2.612308375916463,
    "loss": 0.7632,
    "grad_norm": 0.6696152091026306,
    "learning_rate": 1.0970814571923673e-05
  },
  {
    "step": 5890,
    "epoch": 2.6167518329260164,
    "loss": 0.826,
    "grad_norm": 1.6920530796051025,
    "learning_rate": 1.0939940634585818e-05
  },
  {
    "step": 5900,
    "epoch": 2.62119528993557,
    "loss": 0.8904,
    "grad_norm": 1.7299708127975464,
    "learning_rate": 1.090905765520263e-05
  },
  {
    "step": 5910,
    "epoch": 2.6256387469451234,
    "loss": 0.754,
    "grad_norm": 4.065642833709717,
    "learning_rate": 1.0878165930862344e-05
  },
  {
    "step": 5920,
    "epoch": 2.630082203954677,
    "loss": 0.7677,
    "grad_norm": 0.86248779296875,
    "learning_rate": 1.084726575873731e-05
  },
  {
    "step": 5930,
    "epoch": 2.63452566096423,
    "loss": 0.8069,
    "grad_norm": 1.662660837173462,
    "learning_rate": 1.0816357436081153e-05
  },
  {
    "step": 5940,
    "epoch": 2.6389691179737835,
    "loss": 0.7831,
    "grad_norm": 1.3929340839385986,
    "learning_rate": 1.0785441260225898e-05
  },
  {
    "step": 5950,
    "epoch": 2.643412574983337,
    "loss": 0.8255,
    "grad_norm": 1.9443933963775635,
    "learning_rate": 1.0754517528579117e-05
  },
  {
    "step": 5960,
    "epoch": 2.6478560319928905,
    "loss": 0.7972,
    "grad_norm": 0.815117359161377,
    "learning_rate": 1.0723586538621072e-05
  },
  {
    "step": 5970,
    "epoch": 2.652299489002444,
    "loss": 0.7687,
    "grad_norm": 1.1475988626480103,
    "learning_rate": 1.0692648587901845e-05
  },
  {
    "step": 5980,
    "epoch": 2.656742946011997,
    "loss": 0.7978,
    "grad_norm": 0.7978281378746033,
    "learning_rate": 1.066170397403848e-05
  },
  {
    "step": 5990,
    "epoch": 2.6611864030215506,
    "loss": 0.7881,
    "grad_norm": 0.5509820580482483,
    "learning_rate": 1.0630752994712117e-05
  },
  {
    "step": 6000,
    "epoch": 2.665629860031104,
    "loss": 0.7348,
    "grad_norm": 1.2762502431869507,
    "learning_rate": 1.0599795947665135e-05
  },
  {
    "step": 6000,
    "epoch": 2.665629860031104,
    "eval_loss": 0.7554762363433838,
    "eval_f1": 0.5399978639325003,
    "eval_precision": 0.5808823529411765,
    "eval_recall": 0.5044901217321892,
    "eval_runtime": 39.4347,
    "eval_samples_per_second": 50.742,
    "eval_steps_per_second": 6.365
  },
  {
    "step": 6010,
    "epoch": 2.6700733170406576,
    "loss": 0.8005,
    "grad_norm": 0.7807890772819519,
    "learning_rate": 1.0568833130698278e-05
  },
  {
    "step": 6020,
    "epoch": 2.674516774050211,
    "loss": 0.8684,
    "grad_norm": 1.9071499109268188,
    "learning_rate": 1.0537864841667798e-05
  },
  {
    "step": 6030,
    "epoch": 2.6789602310597647,
    "loss": 0.8722,
    "grad_norm": 0.940712034702301,
    "learning_rate": 1.050689137848259e-05
  },
  {
    "step": 6040,
    "epoch": 2.683403688069318,
    "loss": 0.7431,
    "grad_norm": 0.9206559658050537,
    "learning_rate": 1.0475913039101316e-05
  },
  {
    "step": 6050,
    "epoch": 2.6878471450788712,
    "loss": 0.8206,
    "grad_norm": 1.7493468523025513,
    "learning_rate": 1.0444930121529556e-05
  },
  {
    "step": 6060,
    "epoch": 2.6922906020884247,
    "loss": 0.7753,
    "grad_norm": 0.7468490600585938,
    "learning_rate": 1.041394292381692e-05
  },
  {
    "step": 6070,
    "epoch": 2.6967340590979783,
    "loss": 0.8235,
    "grad_norm": 0.8005720973014832,
    "learning_rate": 1.0386051032726339e-05
  },
  {
    "step": 6080,
    "epoch": 2.7011775161075318,
    "loss": 0.7167,
    "grad_norm": 0.9673338532447815,
    "learning_rate": 1.0355056524017893e-05
  },
  {
    "step": 6090,
    "epoch": 2.7056209731170853,
    "loss": 0.7523,
    "grad_norm": 0.3488830029964447,
    "learning_rate": 1.032405859973503e-05
  },
  {
    "step": 6100,
    "epoch": 2.7100644301266383,
    "loss": 0.7799,
    "grad_norm": 1.0650544166564941,
    "learning_rate": 1.0293057558071729e-05
  },
  {
    "step": 6110,
    "epoch": 2.714507887136192,
    "loss": 0.7436,
    "grad_norm": 0.930682897567749,
    "learning_rate": 1.0262053697251953e-05
  },
  {
    "step": 6120,
    "epoch": 2.7189513441457454,
    "loss": 0.7813,
    "grad_norm": 1.1622332334518433,
    "learning_rate": 1.0231047315526789e-05
  },
  {
    "step": 6130,
    "epoch": 2.723394801155299,
    "loss": 0.7629,
    "grad_norm": 0.6504406332969666,
    "learning_rate": 1.0200038711171576e-05
  },
  {
    "step": 6140,
    "epoch": 2.7278382581648524,
    "loss": 0.8105,
    "grad_norm": 0.9282650947570801,
    "learning_rate": 1.016902818248303e-05
  },
  {
    "step": 6150,
    "epoch": 2.7322817151744054,
    "loss": 0.8662,
    "grad_norm": 2.0335168838500977,
    "learning_rate": 1.0138016027776378e-05
  },
  {
    "step": 6160,
    "epoch": 2.7367251721839594,
    "loss": 0.7898,
    "grad_norm": 2.1984963417053223,
    "learning_rate": 1.0107002545382496e-05
  },
  {
    "step": 6170,
    "epoch": 2.7411686291935125,
    "loss": 0.7578,
    "grad_norm": 1.489155888557434,
    "learning_rate": 1.0075988033645025e-05
  },
  {
    "step": 6180,
    "epoch": 2.745612086203066,
    "loss": 0.7795,
    "grad_norm": 0.801750659942627,
    "learning_rate": 1.004497279091751e-05
  },
  {
    "step": 6190,
    "epoch": 2.7500555432126195,
    "loss": 0.7921,
    "grad_norm": 1.2708044052124023,
    "learning_rate": 1.001395711556053e-05
  },
  {
    "step": 6200,
    "epoch": 2.754499000222173,
    "loss": 0.7706,
    "grad_norm": 1.7545701265335083,
    "learning_rate": 9.982941305938825e-06
  },
  {
    "step": 6210,
    "epoch": 2.7589424572317265,
    "loss": 0.7933,
    "grad_norm": 1.090261697769165,
    "learning_rate": 9.951925660418421e-06
  },
  {
    "step": 6220,
    "epoch": 2.7633859142412796,
    "loss": 0.8399,
    "grad_norm": 1.4362167119979858,
    "learning_rate": 9.920910477363784e-06
  },
  {
    "step": 6230,
    "epoch": 2.767829371250833,
    "loss": 0.8077,
    "grad_norm": 2.515002965927124,
    "learning_rate": 9.8898960551349e-06
  },
  {
    "step": 6240,
    "epoch": 2.7722728282603866,
    "loss": 0.797,
    "grad_norm": 0.7259752750396729,
    "learning_rate": 9.858882692084467e-06
  },
  {
    "step": 6250,
    "epoch": 2.77671628526994,
    "loss": 0.7985,
    "grad_norm": 1.4704135656356812,
    "learning_rate": 9.827870686554972e-06
  },
  {
    "step": 6260,
    "epoch": 2.7811597422794936,
    "loss": 0.7691,
    "grad_norm": 1.0765224695205688,
    "learning_rate": 9.796860336875854e-06
  },
  {
    "step": 6270,
    "epoch": 2.7856031992890466,
    "loss": 0.7969,
    "grad_norm": 1.9976979494094849,
    "learning_rate": 9.765851941360625e-06
  },
  {
    "step": 6280,
    "epoch": 2.7900466562986,
    "loss": 0.7505,
    "grad_norm": 0.9241792559623718,
    "learning_rate": 9.734845798303987e-06
  },
  {
    "step": 6290,
    "epoch": 2.7944901133081537,
    "loss": 0.8093,
    "grad_norm": 1.3689391613006592,
    "learning_rate": 9.703842205978985e-06
  },
  {
    "step": 6300,
    "epoch": 2.798933570317707,
    "loss": 0.7765,
    "grad_norm": 1.9614044427871704,
    "learning_rate": 9.67284146263412e-06
  },
  {
    "step": 6310,
    "epoch": 2.8033770273272607,
    "loss": 0.7921,
    "grad_norm": 2.1011080741882324,
    "learning_rate": 9.641843866490492e-06
  },
  {
    "step": 6320,
    "epoch": 2.807820484336814,
    "loss": 0.7838,
    "grad_norm": 1.8198058605194092,
    "learning_rate": 9.610849715738916e-06
  },
  {
    "step": 6330,
    "epoch": 2.8122639413463677,
    "loss": 0.8185,
    "grad_norm": 1.5906063318252563,
    "learning_rate": 9.579859308537075e-06
  },
  {
    "step": 6340,
    "epoch": 2.8167073983559208,
    "loss": 0.8931,
    "grad_norm": 1.0855098962783813,
    "learning_rate": 9.548872943006628e-06
  },
  {
    "step": 6350,
    "epoch": 2.8211508553654743,
    "loss": 0.8156,
    "grad_norm": 2.402751922607422,
    "learning_rate": 9.517890917230364e-06
  },
  {
    "step": 6360,
    "epoch": 2.825594312375028,
    "loss": 0.8225,
    "grad_norm": 0.8399601578712463,
    "learning_rate": 9.486913529249317e-06
  },
  {
    "step": 6370,
    "epoch": 2.8300377693845813,
    "loss": 0.7755,
    "grad_norm": 1.1459978818893433,
    "learning_rate": 9.455941077059911e-06
  },
  {
    "step": 6380,
    "epoch": 2.834481226394135,
    "loss": 0.7591,
    "grad_norm": 0.6245745420455933,
    "learning_rate": 9.424973858611088e-06
  },
  {
    "step": 6390,
    "epoch": 2.838924683403688,
    "loss": 0.8155,
    "grad_norm": 0.9440842270851135,
    "learning_rate": 9.39401217180144e-06
  },
  {
    "step": 6400,
    "epoch": 2.8433681404132414,
    "loss": 0.8242,
    "grad_norm": 1.1069555282592773,
    "learning_rate": 9.363056314476348e-06
  },
  {
    "step": 6410,
    "epoch": 2.847811597422795,
    "loss": 0.7756,
    "grad_norm": 1.2894312143325806,
    "learning_rate": 9.332106584425112e-06
  },
  {
    "step": 6420,
    "epoch": 2.8522550544323484,
    "loss": 0.7938,
    "grad_norm": 1.1209882497787476,
    "learning_rate": 9.301163279378095e-06
  },
  {
    "step": 6430,
    "epoch": 2.856698511441902,
    "loss": 0.7753,
    "grad_norm": 0.8354933857917786,
    "learning_rate": 9.270226697003842e-06
  },
  {
    "step": 6440,
    "epoch": 2.861141968451455,
    "loss": 0.7769,
    "grad_norm": 1.6975148916244507,
    "learning_rate": 9.239297134906238e-06
  },
  {
    "step": 6450,
    "epoch": 2.865585425461009,
    "loss": 0.8417,
    "grad_norm": 0.9601226449012756,
    "learning_rate": 9.208374890621627e-06
  },
  {
    "step": 6460,
    "epoch": 2.870028882470562,
    "loss": 0.7963,
    "grad_norm": 0.8587535619735718,
    "learning_rate": 9.177460261615962e-06
  },
  {
    "step": 6470,
    "epoch": 2.8744723394801155,
    "loss": 0.7211,
    "grad_norm": 0.579919159412384,
    "learning_rate": 9.146553545281932e-06
  },
  {
    "step": 6480,
    "epoch": 2.878915796489669,
    "loss": 0.8159,
    "grad_norm": 1.5456370115280151,
    "learning_rate": 9.115655038936116e-06
  },
  {
    "step": 6490,
    "epoch": 2.8833592534992225,
    "loss": 0.7794,
    "grad_norm": 1.2573740482330322,
    "learning_rate": 9.084765039816114e-06
  },
  {
    "step": 6500,
    "epoch": 2.887802710508776,
    "loss": 0.8032,
    "grad_norm": 1.0881552696228027,
    "learning_rate": 9.053883845077675e-06
  },
  {
    "step": 6500,
    "epoch": 2.887802710508776,
    "eval_loss": 0.754041314125061,
    "eval_f1": 0.5478519778817524,
    "eval_precision": 0.5863874345549738,
    "eval_recall": 0.5140690480941927,
    "eval_runtime": 39.5285,
    "eval_samples_per_second": 50.622,
    "eval_steps_per_second": 6.35
  },
  {
    "step": 6510,
    "epoch": 2.892246167518329,
    "loss": 0.788,
    "grad_norm": 2.1468496322631836,
    "learning_rate": 9.02301175179187e-06
  },
  {
    "step": 6520,
    "epoch": 2.8966896245278826,
    "loss": 0.8154,
    "grad_norm": 1.4358563423156738,
    "learning_rate": 8.9921490569422e-06
  },
  {
    "step": 6530,
    "epoch": 2.901133081537436,
    "loss": 0.7448,
    "grad_norm": 1.19301176071167,
    "learning_rate": 8.961296057421767e-06
  },
  {
    "step": 6540,
    "epoch": 2.9055765385469896,
    "loss": 0.7616,
    "grad_norm": 1.9691033363342285,
    "learning_rate": 8.930453050030398e-06
  },
  {
    "step": 6550,
    "epoch": 2.910019995556543,
    "loss": 0.7633,
    "grad_norm": 1.030730962753296,
    "learning_rate": 8.899620331471804e-06
  },
  {
    "step": 6560,
    "epoch": 2.914463452566096,
    "loss": 0.8622,
    "grad_norm": 1.4509161710739136,
    "learning_rate": 8.868798198350708e-06
  },
  {
    "step": 6570,
    "epoch": 2.91890690957565,
    "loss": 0.7919,
    "grad_norm": 0.7725252509117126,
    "learning_rate": 8.837986947170022e-06
  },
  {
    "step": 6580,
    "epoch": 2.923350366585203,
    "loss": 0.7746,
    "grad_norm": 2.0747570991516113,
    "learning_rate": 8.807186874327953e-06
  },
  {
    "step": 6590,
    "epoch": 2.9277938235947567,
    "loss": 0.7594,
    "grad_norm": 1.6112619638442993,
    "learning_rate": 8.776398276115198e-06
  },
  {
    "step": 6600,
    "epoch": 2.93223728060431,
    "loss": 0.8421,
    "grad_norm": 1.7733097076416016,
    "learning_rate": 8.745621448712047e-06
  },
  {
    "step": 6610,
    "epoch": 2.9366807376138637,
    "loss": 0.8166,
    "grad_norm": 1.136293649673462,
    "learning_rate": 8.714856688185575e-06
  },
  {
    "step": 6620,
    "epoch": 2.9411241946234172,
    "loss": 0.824,
    "grad_norm": 1.5700434446334839,
    "learning_rate": 8.684104290486773e-06
  },
  {
    "step": 6630,
    "epoch": 2.9455676516329703,
    "loss": 0.7805,
    "grad_norm": 2.149454116821289,
    "learning_rate": 8.653364551447692e-06
  },
  {
    "step": 6640,
    "epoch": 2.950011108642524,
    "loss": 0.7478,
    "grad_norm": 1.3235585689544678,
    "learning_rate": 8.62263776677863e-06
  },
  {
    "step": 6650,
    "epoch": 2.9544545656520773,
    "loss": 0.7333,
    "grad_norm": 0.6681485772132874,
    "learning_rate": 8.591924232065242e-06
  },
  {
    "step": 6660,
    "epoch": 2.958898022661631,
    "loss": 0.7689,
    "grad_norm": 1.4234263896942139,
    "learning_rate": 8.561224242765744e-06
  },
  {
    "step": 6670,
    "epoch": 2.9633414796711843,
    "loss": 0.7675,
    "grad_norm": 0.7636417746543884,
    "learning_rate": 8.530538094208027e-06
  },
  {
    "step": 6680,
    "epoch": 2.9677849366807374,
    "loss": 0.755,
    "grad_norm": 1.393676996231079,
    "learning_rate": 8.499866081586857e-06
  },
  {
    "step": 6690,
    "epoch": 2.972228393690291,
    "loss": 0.7897,
    "grad_norm": 1.6727930307388306,
    "learning_rate": 8.469208499960998e-06
  },
  {
    "step": 6700,
    "epoch": 2.9766718506998444,
    "loss": 0.7843,
    "grad_norm": 1.3176764249801636,
    "learning_rate": 8.4385656442504e-06
  },
  {
    "step": 6710,
    "epoch": 2.981115307709398,
    "loss": 0.7917,
    "grad_norm": 0.7486703395843506,
    "learning_rate": 8.407937809233347e-06
  },
  {
    "step": 6720,
    "epoch": 2.9855587647189514,
    "loss": 0.7683,
    "grad_norm": 1.5522582530975342,
    "learning_rate": 8.377325289543636e-06
  },
  {
    "step": 6730,
    "epoch": 2.990002221728505,
    "loss": 0.7516,
    "grad_norm": 0.9900928139686584,
    "learning_rate": 8.346728379667729e-06
  },
  {
    "step": 6740,
    "epoch": 2.9944456787380584,
    "loss": 0.7505,
    "grad_norm": 1.509514331817627,
    "learning_rate": 8.316147373941914e-06
  },
  {
    "step": 6750,
    "epoch": 2.9988891357476115,
    "loss": 0.8084,
    "grad_norm": 1.800437569618225,
    "learning_rate": 8.285582566549505e-06
  },
  {
    "step": 6760,
    "epoch": 3.0031104199066876,
    "loss": 0.8797,
    "grad_norm": 1.5395898818969727,
    "learning_rate": 8.255034251517968e-06
  },
  {
    "step": 6770,
    "epoch": 3.0075538769162407,
    "loss": 0.7796,
    "grad_norm": 0.9556404948234558,
    "learning_rate": 8.224502722716135e-06
  },
  {
    "step": 6780,
    "epoch": 3.011997333925794,
    "loss": 0.7915,
    "grad_norm": 1.0682123899459839,
    "learning_rate": 8.19398827385135e-06
  },
  {
    "step": 6790,
    "epoch": 3.0164407909353477,
    "loss": 0.8131,
    "grad_norm": 1.8366193771362305,
    "learning_rate": 8.163491198466646e-06
  },
  {
    "step": 6800,
    "epoch": 3.020884247944901,
    "loss": 0.7968,
    "grad_norm": 0.7393509745597839,
    "learning_rate": 8.133011789937938e-06
  },
  {
    "step": 6810,
    "epoch": 3.0253277049544547,
    "loss": 0.765,
    "grad_norm": 1.1834017038345337,
    "learning_rate": 8.102550341471183e-06
  },
  {
    "step": 6820,
    "epoch": 3.029771161964008,
    "loss": 0.7956,
    "grad_norm": 1.0744273662567139,
    "learning_rate": 8.072107146099559e-06
  },
  {
    "step": 6830,
    "epoch": 3.0342146189735613,
    "loss": 0.7975,
    "grad_norm": 0.8023752570152283,
    "learning_rate": 8.041682496680664e-06
  },
  {
    "step": 6840,
    "epoch": 3.0386580759831148,
    "loss": 0.803,
    "grad_norm": 1.2877418994903564,
    "learning_rate": 8.011276685893692e-06
  },
  {
    "step": 6850,
    "epoch": 3.0431015329926683,
    "loss": 0.7472,
    "grad_norm": 0.7170600891113281,
    "learning_rate": 7.98089000623659e-06
  },
  {
    "step": 6860,
    "epoch": 3.047544990002222,
    "loss": 0.7928,
    "grad_norm": 1.2748950719833374,
    "learning_rate": 7.950522750023292e-06
  },
  {
    "step": 6870,
    "epoch": 3.0519884470117753,
    "loss": 0.7752,
    "grad_norm": 1.0450444221496582,
    "learning_rate": 7.920175209380865e-06
  },
  {
    "step": 6880,
    "epoch": 3.056431904021329,
    "loss": 0.8518,
    "grad_norm": 1.2072392702102661,
    "learning_rate": 7.88984767624673e-06
  },
  {
    "step": 6890,
    "epoch": 3.060875361030882,
    "loss": 0.7861,
    "grad_norm": 1.3982298374176025,
    "learning_rate": 7.859540442365826e-06
  },
  {
    "step": 6900,
    "epoch": 3.0653188180404354,
    "loss": 0.8168,
    "grad_norm": 0.800918698310852,
    "learning_rate": 7.829253799287829e-06
  },
  {
    "step": 6910,
    "epoch": 3.069762275049989,
    "loss": 0.8245,
    "grad_norm": 2.2917120456695557,
    "learning_rate": 7.798988038364324e-06
  },
  {
    "step": 6920,
    "epoch": 3.0742057320595424,
    "loss": 0.7788,
    "grad_norm": 0.9435319304466248,
    "learning_rate": 7.76874345074603e-06
  },
  {
    "step": 6930,
    "epoch": 3.078649189069096,
    "loss": 0.7705,
    "grad_norm": 1.739593744277954,
    "learning_rate": 7.73852032737996e-06
  },
  {
    "step": 6940,
    "epoch": 3.083092646078649,
    "loss": 0.7315,
    "grad_norm": 1.2376813888549805,
    "learning_rate": 7.70831895900667e-06
  },
  {
    "step": 6950,
    "epoch": 3.0875361030882025,
    "loss": 0.7985,
    "grad_norm": 1.2295012474060059,
    "learning_rate": 7.678139636157417e-06
  },
  {
    "step": 6960,
    "epoch": 3.091979560097756,
    "loss": 0.8368,
    "grad_norm": 1.1458396911621094,
    "learning_rate": 7.647982649151396e-06
  },
  {
    "step": 6970,
    "epoch": 3.0964230171073095,
    "loss": 0.7506,
    "grad_norm": 1.135184407234192,
    "learning_rate": 7.617848288092937e-06
  },
  {
    "step": 6980,
    "epoch": 3.100866474116863,
    "loss": 0.7812,
    "grad_norm": 0.5591369867324829,
    "learning_rate": 7.587736842868701e-06
  },
  {
    "step": 6990,
    "epoch": 3.1053099311264165,
    "loss": 0.7904,
    "grad_norm": 1.8577865362167358,
    "learning_rate": 7.5576486031449135e-06
  },
  {
    "step": 7000,
    "epoch": 3.1097533881359696,
    "loss": 0.7528,
    "grad_norm": 1.558612585067749,
    "learning_rate": 7.527583858364561e-06
  },
  {
    "step": 7000,
    "epoch": 3.1097533881359696,
    "eval_loss": 0.7512442469596863,
    "eval_f1": 0.5591897024688752,
    "eval_precision": 0.5932393104992165,
    "eval_recall": 0.5288365595689483,
    "eval_runtime": 44.8005,
    "eval_samples_per_second": 44.665,
    "eval_steps_per_second": 5.603
  },
  {
    "step": 7010,
    "epoch": 3.114196845145523,
    "loss": 0.8451,
    "grad_norm": 1.3866400718688965,
    "learning_rate": 7.497542897744623e-06
  },
  {
    "step": 7020,
    "epoch": 3.1186403021550766,
    "loss": 0.7894,
    "grad_norm": 1.4032516479492188,
    "learning_rate": 7.467526010273265e-06
  },
  {
    "step": 7030,
    "epoch": 3.12308375916463,
    "loss": 0.8366,
    "grad_norm": 1.797664999961853,
    "learning_rate": 7.437533484707089e-06
  },
  {
    "step": 7040,
    "epoch": 3.1275272161741836,
    "loss": 0.7963,
    "grad_norm": 1.896946907043457,
    "learning_rate": 7.407565609568328e-06
  },
  {
    "step": 7050,
    "epoch": 3.131970673183737,
    "loss": 0.7281,
    "grad_norm": 0.6415294408798218,
    "learning_rate": 7.3776226731420956e-06
  },
  {
    "step": 7060,
    "epoch": 3.13641413019329,
    "loss": 0.766,
    "grad_norm": 1.0628743171691895,
    "learning_rate": 7.347704963473583e-06
  },
  {
    "step": 7070,
    "epoch": 3.1408575872028437,
    "loss": 0.8149,
    "grad_norm": 1.2940534353256226,
    "learning_rate": 7.317812768365318e-06
  },
  {
    "step": 7080,
    "epoch": 3.145301044212397,
    "loss": 0.7483,
    "grad_norm": 0.7414200305938721,
    "learning_rate": 7.2879463753743855e-06
  },
  {
    "step": 7090,
    "epoch": 3.1497445012219507,
    "loss": 0.8187,
    "grad_norm": 1.5514246225357056,
    "learning_rate": 7.258106071809643e-06
  },
  {
    "step": 7100,
    "epoch": 3.154187958231504,
    "loss": 0.8538,
    "grad_norm": 1.0776712894439697,
    "learning_rate": 7.228292144728989e-06
  },
  {
    "step": 7110,
    "epoch": 3.1586314152410577,
    "loss": 0.7681,
    "grad_norm": 1.351069688796997,
    "learning_rate": 7.1985048809365776e-06
  },
  {
    "step": 7120,
    "epoch": 3.163074872250611,
    "loss": 0.7845,
    "grad_norm": 1.3450067043304443,
    "learning_rate": 7.16874456698007e-06
  },
  {
    "step": 7130,
    "epoch": 3.1675183292601643,
    "loss": 0.8175,
    "grad_norm": 0.5494404435157776,
    "learning_rate": 7.139011489147871e-06
  },
  {
    "step": 7140,
    "epoch": 3.171961786269718,
    "loss": 0.8546,
    "grad_norm": 1.551364779472351,
    "learning_rate": 7.109305933466388e-06
  },
  {
    "step": 7150,
    "epoch": 3.1764052432792713,
    "loss": 0.747,
    "grad_norm": 0.784345269203186,
    "learning_rate": 7.079628185697258e-06
  },
  {
    "step": 7160,
    "epoch": 3.180848700288825,
    "loss": 0.796,
    "grad_norm": 0.7058942914009094,
    "learning_rate": 7.049978531334627e-06
  },
  {
    "step": 7170,
    "epoch": 3.1852921572983783,
    "loss": 0.7705,
    "grad_norm": 2.1164255142211914,
    "learning_rate": 7.02035725560237e-06
  },
  {
    "step": 7180,
    "epoch": 3.1897356143079314,
    "loss": 0.8273,
    "grad_norm": 1.7497031688690186,
    "learning_rate": 6.990764643451378e-06
  },
  {
    "step": 7190,
    "epoch": 3.194179071317485,
    "loss": 0.7849,
    "grad_norm": 1.0910654067993164,
    "learning_rate": 6.961200979556804e-06
  },
  {
    "step": 7200,
    "epoch": 3.1986225283270384,
    "loss": 0.7551,
    "grad_norm": 1.0561294555664062,
    "learning_rate": 6.931666548315317e-06
  },
  {
    "step": 7210,
    "epoch": 3.203065985336592,
    "loss": 0.7706,
    "grad_norm": 0.7425615787506104,
    "learning_rate": 6.902161633842377e-06
  },
  {
    "step": 7220,
    "epoch": 3.2075094423461454,
    "loss": 0.7459,
    "grad_norm": 1.2178432941436768,
    "learning_rate": 6.8726865199695006e-06
  },
  {
    "step": 7230,
    "epoch": 3.2119528993556985,
    "loss": 0.7614,
    "grad_norm": 1.0074315071105957,
    "learning_rate": 6.8432414902415276e-06
  },
  {
    "step": 7240,
    "epoch": 3.216396356365252,
    "loss": 0.8012,
    "grad_norm": 1.49896240234375,
    "learning_rate": 6.81382682791389e-06
  },
  {
    "step": 7250,
    "epoch": 3.2208398133748055,
    "loss": 0.7798,
    "grad_norm": 1.3506014347076416,
    "learning_rate": 6.784442815949899e-06
  },
  {
    "step": 7260,
    "epoch": 3.225283270384359,
    "loss": 0.7473,
    "grad_norm": 0.5154913663864136,
    "learning_rate": 6.755089737018003e-06
  },
  {
    "step": 7270,
    "epoch": 3.2297267273939125,
    "loss": 0.7785,
    "grad_norm": 2.3101086616516113,
    "learning_rate": 6.725767873489097e-06
  },
  {
    "step": 7280,
    "epoch": 3.234170184403466,
    "loss": 0.8371,
    "grad_norm": 2.2194600105285645,
    "learning_rate": 6.696477507433777e-06
  },
  {
    "step": 7290,
    "epoch": 3.2386136414130196,
    "loss": 0.748,
    "grad_norm": 1.8606481552124023,
    "learning_rate": 6.667218920619649e-06
  },
  {
    "step": 7300,
    "epoch": 3.2430570984225726,
    "loss": 0.7955,
    "grad_norm": 0.6631976366043091,
    "learning_rate": 6.637992394508594e-06
  },
  {
    "step": 7310,
    "epoch": 3.247500555432126,
    "loss": 0.7619,
    "grad_norm": 1.7865569591522217,
    "learning_rate": 6.608798210254092e-06
  },
  {
    "step": 7320,
    "epoch": 3.2519440124416796,
    "loss": 0.7673,
    "grad_norm": 0.8853645920753479,
    "learning_rate": 6.5796366486984986e-06
  },
  {
    "step": 7330,
    "epoch": 3.256387469451233,
    "loss": 0.7941,
    "grad_norm": 1.2580593824386597,
    "learning_rate": 6.550507990370329e-06
  },
  {
    "step": 7340,
    "epoch": 3.2608309264607866,
    "loss": 0.7831,
    "grad_norm": 1.1856998205184937,
    "learning_rate": 6.5214125154816e-06
  },
  {
    "step": 7350,
    "epoch": 3.2652743834703397,
    "loss": 0.8067,
    "grad_norm": 0.6950768232345581,
    "learning_rate": 6.492350503925084e-06
  },
  {
    "step": 7360,
    "epoch": 3.2697178404798932,
    "loss": 0.8024,
    "grad_norm": 1.7489686012268066,
    "learning_rate": 6.463322235271666e-06
  },
  {
    "step": 7370,
    "epoch": 3.2741612974894467,
    "loss": 0.8212,
    "grad_norm": 1.5787116289138794,
    "learning_rate": 6.434327988767617e-06
  },
  {
    "step": 7380,
    "epoch": 3.2786047544990002,
    "loss": 0.7455,
    "grad_norm": 0.995873749256134,
    "learning_rate": 6.40536804333193e-06
  },
  {
    "step": 7390,
    "epoch": 3.2830482115085537,
    "loss": 0.8274,
    "grad_norm": 1.628366231918335,
    "learning_rate": 6.376442677553618e-06
  },
  {
    "step": 7400,
    "epoch": 3.2874916685181073,
    "loss": 0.7869,
    "grad_norm": 1.4911491870880127,
    "learning_rate": 6.3475521696890575e-06
  },
  {
    "step": 7410,
    "epoch": 3.2919351255276608,
    "loss": 0.8051,
    "grad_norm": 1.1304938793182373,
    "learning_rate": 6.3186967976592825e-06
  },
  {
    "step": 7420,
    "epoch": 3.296378582537214,
    "loss": 0.7602,
    "grad_norm": 0.8499280214309692,
    "learning_rate": 6.289876839047343e-06
  },
  {
    "step": 7430,
    "epoch": 3.3008220395467673,
    "loss": 0.7416,
    "grad_norm": 0.8378446698188782,
    "learning_rate": 6.261092571095615e-06
  },
  {
    "step": 7440,
    "epoch": 3.305265496556321,
    "loss": 0.818,
    "grad_norm": 1.1124746799468994,
    "learning_rate": 6.232344270703126e-06
  },
  {
    "step": 7450,
    "epoch": 3.3097089535658744,
    "loss": 0.8151,
    "grad_norm": 1.8994619846343994,
    "learning_rate": 6.203632214422916e-06
  },
  {
    "step": 7460,
    "epoch": 3.314152410575428,
    "loss": 0.7728,
    "grad_norm": 1.3612719774246216,
    "learning_rate": 6.174956678459359e-06
  },
  {
    "step": 7470,
    "epoch": 3.318595867584981,
    "loss": 0.7953,
    "grad_norm": 0.8779230713844299,
    "learning_rate": 6.146317938665512e-06
  },
  {
    "step": 7480,
    "epoch": 3.3230393245945344,
    "loss": 0.7647,
    "grad_norm": 0.4391576945781708,
    "learning_rate": 6.1177162705404534e-06
  },
  {
    "step": 7490,
    "epoch": 3.327482781604088,
    "loss": 0.7177,
    "grad_norm": 0.635015606880188,
    "learning_rate": 6.089151949226652e-06
  },
  {
    "step": 7500,
    "epoch": 3.3319262386136415,
    "loss": 0.7999,
    "grad_norm": 1.585372805595398,
    "learning_rate": 6.06062524950729e-06
  },
  {
    "step": 7500,
    "epoch": 3.3319262386136415,
    "eval_loss": 0.7494401931762695,
    "eval_f1": 0.5589565583254444,
    "eval_precision": 0.5909697508896797,
    "eval_recall": 0.5302334863300738,
    "eval_runtime": 49.9262,
    "eval_samples_per_second": 40.079,
    "eval_steps_per_second": 5.027
  },
  {
    "step": 7510,
    "epoch": 3.336369695623195,
    "loss": 0.823,
    "grad_norm": 0.9813833236694336,
    "learning_rate": 6.032136445803657e-06
  },
  {
    "step": 7520,
    "epoch": 3.340813152632748,
    "loss": 0.7977,
    "grad_norm": 1.4523289203643799,
    "learning_rate": 6.003685812172474e-06
  },
  {
    "step": 7530,
    "epoch": 3.3452566096423015,
    "loss": 0.7472,
    "grad_norm": 1.370060920715332,
    "learning_rate": 5.975273622303285e-06
  },
  {
    "step": 7540,
    "epoch": 3.349700066651855,
    "loss": 0.8061,
    "grad_norm": 0.6581919193267822,
    "learning_rate": 5.946900149515805e-06
  },
  {
    "step": 7550,
    "epoch": 3.3541435236614086,
    "loss": 0.8033,
    "grad_norm": 0.8099231123924255,
    "learning_rate": 5.918565666757298e-06
  },
  {
    "step": 7560,
    "epoch": 3.358586980670962,
    "loss": 0.7719,
    "grad_norm": 1.272118091583252,
    "learning_rate": 5.8902704465999635e-06
  },
  {
    "step": 7570,
    "epoch": 3.3630304376805156,
    "loss": 0.7632,
    "grad_norm": 2.2008557319641113,
    "learning_rate": 5.862014761238282e-06
  },
  {
    "step": 7580,
    "epoch": 3.367473894690069,
    "loss": 0.7712,
    "grad_norm": 0.8548064231872559,
    "learning_rate": 5.833798882486436e-06
  },
  {
    "step": 7590,
    "epoch": 3.371917351699622,
    "loss": 0.763,
    "grad_norm": 0.8627415895462036,
    "learning_rate": 5.805623081775665e-06
  },
  {
    "step": 7600,
    "epoch": 3.3763608087091757,
    "loss": 0.7365,
    "grad_norm": 0.4322062134742737,
    "learning_rate": 5.77748763015167e-06
  },
  {
    "step": 7610,
    "epoch": 3.380804265718729,
    "loss": 0.7429,
    "grad_norm": 1.287968397140503,
    "learning_rate": 5.749392798272e-06
  },
  {
    "step": 7620,
    "epoch": 3.3852477227282827,
    "loss": 0.7907,
    "grad_norm": 1.364248514175415,
    "learning_rate": 5.721338856403452e-06
  },
  {
    "step": 7630,
    "epoch": 3.389691179737836,
    "loss": 0.7981,
    "grad_norm": 0.46815770864486694,
    "learning_rate": 5.693326074419467e-06
  },
  {
    "step": 7640,
    "epoch": 3.3941346367473892,
    "loss": 0.7645,
    "grad_norm": 2.0712170600891113,
    "learning_rate": 5.665354721797536e-06
  },
  {
    "step": 7650,
    "epoch": 3.3985780937569428,
    "loss": 0.8603,
    "grad_norm": 2.279014825820923,
    "learning_rate": 5.637425067616604e-06
  },
  {
    "step": 7660,
    "epoch": 3.4030215507664963,
    "loss": 0.7549,
    "grad_norm": 2.0506553649902344,
    "learning_rate": 5.6095373805545e-06
  },
  {
    "step": 7670,
    "epoch": 3.4074650077760498,
    "loss": 0.7984,
    "grad_norm": 1.4815142154693604,
    "learning_rate": 5.58169192888532e-06
  },
  {
    "step": 7680,
    "epoch": 3.4119084647856033,
    "loss": 0.7331,
    "grad_norm": 0.758782684803009,
    "learning_rate": 5.553888980476872e-06
  },
  {
    "step": 7690,
    "epoch": 3.416351921795157,
    "loss": 0.7352,
    "grad_norm": 1.5839382410049438,
    "learning_rate": 5.52612880278809e-06
  },
  {
    "step": 7700,
    "epoch": 3.4207953788047103,
    "loss": 0.8491,
    "grad_norm": 1.2720489501953125,
    "learning_rate": 5.49841166286646e-06
  },
  {
    "step": 7710,
    "epoch": 3.4252388358142634,
    "loss": 0.7843,
    "grad_norm": 1.4234868288040161,
    "learning_rate": 5.470737827345458e-06
  },
  {
    "step": 7720,
    "epoch": 3.429682292823817,
    "loss": 0.7437,
    "grad_norm": 1.3479875326156616,
    "learning_rate": 5.4431075624419764e-06
  },
  {
    "step": 7730,
    "epoch": 3.4341257498333704,
    "loss": 0.7603,
    "grad_norm": 1.6440485715866089,
    "learning_rate": 5.415521133953763e-06
  },
  {
    "step": 7740,
    "epoch": 3.438569206842924,
    "loss": 0.7915,
    "grad_norm": 1.09531569480896,
    "learning_rate": 5.387978807256873e-06
  },
  {
    "step": 7750,
    "epoch": 3.4430126638524774,
    "loss": 0.804,
    "grad_norm": 0.7871894240379333,
    "learning_rate": 5.360480847303118e-06
  },
  {
    "step": 7760,
    "epoch": 3.4474561208620305,
    "loss": 0.7534,
    "grad_norm": 0.8050768971443176,
    "learning_rate": 5.333027518617491e-06
  },
  {
    "step": 7770,
    "epoch": 3.451899577871584,
    "loss": 0.8037,
    "grad_norm": 1.7090951204299927,
    "learning_rate": 5.305619085295659e-06
  },
  {
    "step": 7780,
    "epoch": 3.4563430348811375,
    "loss": 0.7503,
    "grad_norm": 0.9747321605682373,
    "learning_rate": 5.278255811001398e-06
  },
  {
    "step": 7790,
    "epoch": 3.460786491890691,
    "loss": 0.7696,
    "grad_norm": 1.0778230428695679,
    "learning_rate": 5.2509379589640605e-06
  },
  {
    "step": 7800,
    "epoch": 3.4652299489002445,
    "loss": 0.7779,
    "grad_norm": 1.0853233337402344,
    "learning_rate": 5.223665791976048e-06
  },
  {
    "step": 7810,
    "epoch": 3.469673405909798,
    "loss": 0.8097,
    "grad_norm": 1.6482264995574951,
    "learning_rate": 5.196439572390281e-06
  },
  {
    "step": 7820,
    "epoch": 3.474116862919351,
    "loss": 0.7578,
    "grad_norm": 1.6381134986877441,
    "learning_rate": 5.169259562117674e-06
  },
  {
    "step": 7830,
    "epoch": 3.4785603199289046,
    "loss": 0.7676,
    "grad_norm": 1.9153711795806885,
    "learning_rate": 5.142126022624614e-06
  },
  {
    "step": 7840,
    "epoch": 3.483003776938458,
    "loss": 0.7929,
    "grad_norm": 1.6200412511825562,
    "learning_rate": 5.115039214930463e-06
  },
  {
    "step": 7850,
    "epoch": 3.4874472339480116,
    "loss": 0.7581,
    "grad_norm": 1.3941384553909302,
    "learning_rate": 5.087999399605006e-06
  },
  {
    "step": 7860,
    "epoch": 3.491890690957565,
    "loss": 0.7547,
    "grad_norm": 1.1449427604675293,
    "learning_rate": 5.061006836765999e-06
  },
  {
    "step": 7870,
    "epoch": 3.4963341479671186,
    "loss": 0.754,
    "grad_norm": 0.7056856155395508,
    "learning_rate": 5.0340617860766115e-06
  },
  {
    "step": 7880,
    "epoch": 3.5007776049766717,
    "loss": 0.8324,
    "grad_norm": 2.1032767295837402,
    "learning_rate": 5.00716450674298e-06
  },
  {
    "step": 7890,
    "epoch": 3.505221061986225,
    "loss": 0.7584,
    "grad_norm": 1.0578272342681885,
    "learning_rate": 4.980315257511673e-06
  },
  {
    "step": 7900,
    "epoch": 3.5096645189957787,
    "loss": 0.7945,
    "grad_norm": 1.56815767288208,
    "learning_rate": 4.953514296667227e-06
  },
  {
    "step": 7910,
    "epoch": 3.514107976005332,
    "loss": 0.7735,
    "grad_norm": 1.0449072122573853,
    "learning_rate": 4.926761882029648e-06
  },
  {
    "step": 7920,
    "epoch": 3.5185514330148857,
    "loss": 0.7604,
    "grad_norm": 1.2882930040359497,
    "learning_rate": 4.900058270951938e-06
  },
  {
    "step": 7930,
    "epoch": 3.5229948900244388,
    "loss": 0.7607,
    "grad_norm": 1.1015311479568481,
    "learning_rate": 4.873403720317632e-06
  },
  {
    "step": 7940,
    "epoch": 3.5274383470339923,
    "loss": 0.7646,
    "grad_norm": 1.853299617767334,
    "learning_rate": 4.846798486538286e-06
  },
  {
    "step": 7950,
    "epoch": 3.531881804043546,
    "loss": 0.7606,
    "grad_norm": 1.6107311248779297,
    "learning_rate": 4.820242825551066e-06
  },
  {
    "step": 7960,
    "epoch": 3.5363252610530993,
    "loss": 0.7768,
    "grad_norm": 0.9353667497634888,
    "learning_rate": 4.793736992816231e-06
  },
  {
    "step": 7970,
    "epoch": 3.540768718062653,
    "loss": 0.6935,
    "grad_norm": 1.5349351167678833,
    "learning_rate": 4.767281243314726e-06
  },
  {
    "step": 7980,
    "epoch": 3.5452121750722063,
    "loss": 0.7707,
    "grad_norm": 1.526357889175415,
    "learning_rate": 4.7408758315456915e-06
  },
  {
    "step": 7990,
    "epoch": 3.54965563208176,
    "loss": 0.7814,
    "grad_norm": 2.0047380924224854,
    "learning_rate": 4.71452101152403e-06
  },
  {
    "step": 8000,
    "epoch": 3.554099089091313,
    "loss": 0.7375,
    "grad_norm": 2.2732627391815186,
    "learning_rate": 4.688217036777965e-06
  },
  {
    "step": 8000,
    "epoch": 3.554099089091313,
    "eval_loss": 0.7493689060211182,
    "eval_f1": 0.5593095463635406,
    "eval_precision": 0.5917594654788418,
    "eval_recall": 0.5302334863300738,
    "eval_runtime": 46.9787,
    "eval_samples_per_second": 42.594,
    "eval_steps_per_second": 5.343
  },
  {
    "step": 8010,
    "epoch": 3.5585425461008664,
    "loss": 0.8079,
    "grad_norm": 1.3663058280944824,
    "learning_rate": 4.661964160346591e-06
  },
  {
    "step": 8020,
    "epoch": 3.56298600311042,
    "loss": 0.7428,
    "grad_norm": 1.2913779020309448,
    "learning_rate": 4.635762634777462e-06
  },
  {
    "step": 8030,
    "epoch": 3.5674294601199734,
    "loss": 0.8492,
    "grad_norm": 1.7795536518096924,
    "learning_rate": 4.609612712124125e-06
  },
  {
    "step": 8040,
    "epoch": 3.571872917129527,
    "loss": 0.7402,
    "grad_norm": 0.7307801842689514,
    "learning_rate": 4.5835146439437405e-06
  },
  {
    "step": 8050,
    "epoch": 3.57631637413908,
    "loss": 0.8142,
    "grad_norm": 1.5249594449996948,
    "learning_rate": 4.557468681294615e-06
  },
  {
    "step": 8060,
    "epoch": 3.5807598311486335,
    "loss": 0.7925,
    "grad_norm": 1.4568579196929932,
    "learning_rate": 4.531475074733832e-06
  },
  {
    "step": 8070,
    "epoch": 3.585203288158187,
    "loss": 0.7607,
    "grad_norm": 1.7890231609344482,
    "learning_rate": 4.505534074314807e-06
  },
  {
    "step": 8080,
    "epoch": 3.5896467451677405,
    "loss": 0.7968,
    "grad_norm": 1.5807009935379028,
    "learning_rate": 4.482232358450273e-06
  },
  {
    "step": 8090,
    "epoch": 3.594090202177294,
    "loss": 0.6957,
    "grad_norm": 0.7496850490570068,
    "learning_rate": 4.4563919967833644e-06
  },
  {
    "step": 8100,
    "epoch": 3.5985336591868475,
    "loss": 0.7826,
    "grad_norm": 0.6281710267066956,
    "learning_rate": 4.430604963542758e-06
  },
  {
    "step": 8110,
    "epoch": 3.602977116196401,
    "loss": 0.7721,
    "grad_norm": 0.6128894090652466,
    "learning_rate": 4.40487150679468e-06
  },
  {
    "step": 8120,
    "epoch": 3.607420573205954,
    "loss": 0.7916,
    "grad_norm": 0.7539968490600586,
    "learning_rate": 4.379191874089956e-06
  },
  {
    "step": 8130,
    "epoch": 3.6118640302155076,
    "loss": 0.7675,
    "grad_norm": 1.1912078857421875,
    "learning_rate": 4.353566312461635e-06
  },
  {
    "step": 8140,
    "epoch": 3.616307487225061,
    "loss": 0.7896,
    "grad_norm": 2.2865495681762695,
    "learning_rate": 4.327995068422622e-06
  },
  {
    "step": 8150,
    "epoch": 3.6207509442346146,
    "loss": 0.7837,
    "grad_norm": 0.7980242371559143,
    "learning_rate": 4.302478387963288e-06
  },
  {
    "step": 8160,
    "epoch": 3.625194401244168,
    "loss": 0.7756,
    "grad_norm": 1.123199701309204,
    "learning_rate": 4.277016516549114e-06
  },
  {
    "step": 8170,
    "epoch": 3.629637858253721,
    "loss": 0.811,
    "grad_norm": 3.0170114040374756,
    "learning_rate": 4.2516096991183295e-06
  },
  {
    "step": 8180,
    "epoch": 3.6340813152632747,
    "loss": 0.7462,
    "grad_norm": 1.065130352973938,
    "learning_rate": 4.2262581800795584e-06
  },
  {
    "step": 8190,
    "epoch": 3.6385247722728282,
    "loss": 0.7609,
    "grad_norm": 1.4199256896972656,
    "learning_rate": 4.200962203309461e-06
  },
  {
    "step": 8200,
    "epoch": 3.6429682292823817,
    "loss": 0.7375,
    "grad_norm": 0.8393847346305847,
    "learning_rate": 4.1757220121503936e-06
  },
  {
    "step": 8210,
    "epoch": 3.6474116862919352,
    "loss": 0.8041,
    "grad_norm": 1.7302709817886353,
    "learning_rate": 4.150537849408067e-06
  },
  {
    "step": 8220,
    "epoch": 3.6518551433014883,
    "loss": 0.7522,
    "grad_norm": 1.5408554077148438,
    "learning_rate": 4.125409957349204e-06
  },
  {
    "step": 8230,
    "epoch": 3.6562986003110423,
    "loss": 0.7393,
    "grad_norm": 1.05510675907135,
    "learning_rate": 4.100338577699227e-06
  },
  {
    "step": 8240,
    "epoch": 3.6607420573205953,
    "loss": 0.8583,
    "grad_norm": 1.4142236709594727,
    "learning_rate": 4.075323951639901e-06
  },
  {
    "step": 8250,
    "epoch": 3.665185514330149,
    "loss": 0.7665,
    "grad_norm": 1.0086708068847656,
    "learning_rate": 4.050366319807052e-06
  },
  {
    "step": 8260,
    "epoch": 3.6696289713397023,
    "loss": 0.8042,
    "grad_norm": 1.214280366897583,
    "learning_rate": 4.025465922288221e-06
  },
  {
    "step": 8270,
    "epoch": 3.674072428349256,
    "loss": 0.8782,
    "grad_norm": 0.8637697696685791,
    "learning_rate": 4.000622998620367e-06
  },
  {
    "step": 8280,
    "epoch": 3.6785158853588094,
    "loss": 0.8129,
    "grad_norm": 1.7191458940505981,
    "learning_rate": 3.975837787787568e-06
  },
  {
    "step": 8290,
    "epoch": 3.6829593423683624,
    "loss": 0.7514,
    "grad_norm": 1.897610068321228,
    "learning_rate": 3.951110528218707e-06
  },
  {
    "step": 8300,
    "epoch": 3.687402799377916,
    "loss": 0.7425,
    "grad_norm": 0.8468685746192932,
    "learning_rate": 3.926441457785194e-06
  },
  {
    "step": 8310,
    "epoch": 3.6918462563874694,
    "loss": 0.7658,
    "grad_norm": 1.0299628973007202,
    "learning_rate": 3.901830813798666e-06
  },
  {
    "step": 8320,
    "epoch": 3.696289713397023,
    "loss": 0.7381,
    "grad_norm": 1.123077154159546,
    "learning_rate": 3.877278833008719e-06
  },
  {
    "step": 8330,
    "epoch": 3.7007331704065765,
    "loss": 0.7986,
    "grad_norm": 1.5681532621383667,
    "learning_rate": 3.8527857516006025e-06
  },
  {
    "step": 8340,
    "epoch": 3.7051766274161295,
    "loss": 0.8154,
    "grad_norm": 1.905180811882019,
    "learning_rate": 3.828351805192989e-06
  },
  {
    "step": 8350,
    "epoch": 3.709620084425683,
    "loss": 0.7447,
    "grad_norm": 0.831885576248169,
    "learning_rate": 3.803977228835656e-06
  },
  {
    "step": 8360,
    "epoch": 3.7140635414352365,
    "loss": 0.8047,
    "grad_norm": 0.8712524771690369,
    "learning_rate": 3.7796622570072783e-06
  },
  {
    "step": 8370,
    "epoch": 3.71850699844479,
    "loss": 0.804,
    "grad_norm": 1.8248875141143799,
    "learning_rate": 3.755407123613133e-06
  },
  {
    "step": 8380,
    "epoch": 3.7229504554543436,
    "loss": 0.822,
    "grad_norm": 1.3370755910873413,
    "learning_rate": 3.731212061982866e-06
  },
  {
    "step": 8390,
    "epoch": 3.727393912463897,
    "loss": 0.7433,
    "grad_norm": 1.0405102968215942,
    "learning_rate": 3.707077304868245e-06
  },
  {
    "step": 8400,
    "epoch": 3.7318373694734506,
    "loss": 0.7238,
    "grad_norm": 0.8155269026756287,
    "learning_rate": 3.683003084440917e-06
  },
  {
    "step": 8410,
    "epoch": 3.7362808264830036,
    "loss": 0.8277,
    "grad_norm": 1.6934432983398438,
    "learning_rate": 3.65898963229019e-06
  },
  {
    "step": 8420,
    "epoch": 3.740724283492557,
    "loss": 0.7839,
    "grad_norm": 1.0586931705474854,
    "learning_rate": 3.6350371794207706e-06
  },
  {
    "step": 8430,
    "epoch": 3.7451677405021107,
    "loss": 0.7585,
    "grad_norm": 1.3751540184020996,
    "learning_rate": 3.6111459562505903e-06
  },
  {
    "step": 8440,
    "epoch": 3.749611197511664,
    "loss": 0.7485,
    "grad_norm": 0.9884650111198425,
    "learning_rate": 3.5873161926085375e-06
  },
  {
    "step": 8450,
    "epoch": 3.7540546545212177,
    "loss": 0.8207,
    "grad_norm": 1.386318325996399,
    "learning_rate": 3.563548117732294e-06
  },
  {
    "step": 8460,
    "epoch": 3.7584981115307707,
    "loss": 0.738,
    "grad_norm": 2.2869906425476074,
    "learning_rate": 3.539841960266094e-06
  },
  {
    "step": 8470,
    "epoch": 3.7629415685403242,
    "loss": 0.7947,
    "grad_norm": 2.2140824794769287,
    "learning_rate": 3.516197948258544e-06
  },
  {
    "step": 8480,
    "epoch": 3.7673850255498778,
    "loss": 0.8044,
    "grad_norm": 1.4991161823272705,
    "learning_rate": 3.4926163091604204e-06
  },
  {
    "step": 8490,
    "epoch": 3.7718284825594313,
    "loss": 0.7877,
    "grad_norm": 0.9925488829612732,
    "learning_rate": 3.4690972698224822e-06
  },
  {
    "step": 8500,
    "epoch": 3.7762719395689848,
    "loss": 0.7897,
    "grad_norm": 0.8836246132850647,
    "learning_rate": 3.4456410564933064e-06
  },
  {
    "step": 8500,
    "epoch": 3.7762719395689848,
    "eval_loss": 0.7478403449058533,
    "eval_f1": 0.563659095644926,
    "eval_precision": 0.5897100501417049,
    "eval_recall": 0.5398124126920775,
    "eval_runtime": 46.392,
    "eval_samples_per_second": 43.132,
    "eval_steps_per_second": 5.41
  },
  {
    "step": 8510,
    "epoch": 3.780715396578538,
    "loss": 0.8149,
    "grad_norm": 1.7303340435028076,
    "learning_rate": 3.422247894817069e-06
  },
  {
    "step": 8520,
    "epoch": 3.785158853588092,
    "loss": 0.7466,
    "grad_norm": 1.5465068817138672,
    "learning_rate": 3.398918009831431e-06
  },
  {
    "step": 8530,
    "epoch": 3.789602310597645,
    "loss": 0.7538,
    "grad_norm": 1.4873219728469849,
    "learning_rate": 3.375651625965315e-06
  },
  {
    "step": 8540,
    "epoch": 3.7940457676071984,
    "loss": 0.8008,
    "grad_norm": 1.1115975379943848,
    "learning_rate": 3.352448967036801e-06
  },
  {
    "step": 8550,
    "epoch": 3.798489224616752,
    "loss": 0.784,
    "grad_norm": 0.9400584101676941,
    "learning_rate": 3.3293102562509326e-06
  },
  {
    "step": 8560,
    "epoch": 3.8029326816263054,
    "loss": 0.7314,
    "grad_norm": 0.7364060878753662,
    "learning_rate": 3.306235716197588e-06
  },
  {
    "step": 8570,
    "epoch": 3.807376138635859,
    "loss": 0.7399,
    "grad_norm": 1.455994725227356,
    "learning_rate": 3.283225568849336e-06
  },
  {
    "step": 8580,
    "epoch": 3.811819595645412,
    "loss": 0.7403,
    "grad_norm": 0.7753149271011353,
    "learning_rate": 3.260280035559301e-06
  },
  {
    "step": 8590,
    "epoch": 3.8162630526549655,
    "loss": 0.7366,
    "grad_norm": 0.6856860518455505,
    "learning_rate": 3.2373993370590316e-06
  },
  {
    "step": 8600,
    "epoch": 3.820706509664519,
    "loss": 0.7774,
    "grad_norm": 1.3470345735549927,
    "learning_rate": 3.2145836934563747e-06
  },
  {
    "step": 8610,
    "epoch": 3.8251499666740725,
    "loss": 0.807,
    "grad_norm": 0.8858383893966675,
    "learning_rate": 3.1918333242333756e-06
  },
  {
    "step": 8620,
    "epoch": 3.829593423683626,
    "loss": 0.8119,
    "grad_norm": 1.5609960556030273,
    "learning_rate": 3.1691484482441304e-06
  },
  {
    "step": 8630,
    "epoch": 3.834036880693179,
    "loss": 0.7567,
    "grad_norm": 1.226230263710022,
    "learning_rate": 3.146529283712726e-06
  },
  {
    "step": 8640,
    "epoch": 3.838480337702733,
    "loss": 0.7954,
    "grad_norm": 1.1691410541534424,
    "learning_rate": 3.1239760482311045e-06
  },
  {
    "step": 8650,
    "epoch": 3.842923794712286,
    "loss": 0.7852,
    "grad_norm": 0.9821280241012573,
    "learning_rate": 3.1014889587569843e-06
  },
  {
    "step": 8660,
    "epoch": 3.8473672517218396,
    "loss": 0.7629,
    "grad_norm": 1.9098963737487793,
    "learning_rate": 3.079068231611777e-06
  },
  {
    "step": 8670,
    "epoch": 3.851810708731393,
    "loss": 0.8105,
    "grad_norm": 1.3585388660430908,
    "learning_rate": 3.0567140824784956e-06
  },
  {
    "step": 8680,
    "epoch": 3.8562541657409466,
    "loss": 0.7811,
    "grad_norm": 1.3683425188064575,
    "learning_rate": 3.034426726399693e-06
  },
  {
    "step": 8690,
    "epoch": 3.8606976227505,
    "loss": 0.7644,
    "grad_norm": 1.1486592292785645,
    "learning_rate": 3.0122063777753798e-06
  },
  {
    "step": 8700,
    "epoch": 3.865141079760053,
    "loss": 0.7676,
    "grad_norm": 1.0331203937530518,
    "learning_rate": 2.990053250360969e-06
  },
  {
    "step": 8710,
    "epoch": 3.8695845367696067,
    "loss": 0.7604,
    "grad_norm": 0.8935498595237732,
    "learning_rate": 2.9679675572652176e-06
  },
  {
    "step": 8720,
    "epoch": 3.87402799377916,
    "loss": 0.7648,
    "grad_norm": 1.3581117391586304,
    "learning_rate": 2.945949510948187e-06
  },
  {
    "step": 8730,
    "epoch": 3.8784714507887137,
    "loss": 0.7763,
    "grad_norm": 0.5662229657173157,
    "learning_rate": 2.9239993232191787e-06
  },
  {
    "step": 8740,
    "epoch": 3.882914907798267,
    "loss": 0.8789,
    "grad_norm": 1.8983715772628784,
    "learning_rate": 2.9021172052347113e-06
  },
  {
    "step": 8750,
    "epoch": 3.8873583648078203,
    "loss": 0.7393,
    "grad_norm": 1.2826732397079468,
    "learning_rate": 2.8803033674964865e-06
  },
  {
    "step": 8760,
    "epoch": 3.8918018218173738,
    "loss": 0.8195,
    "grad_norm": 1.2739746570587158,
    "learning_rate": 2.858558019849362e-06
  },
  {
    "step": 8770,
    "epoch": 3.8962452788269273,
    "loss": 0.72,
    "grad_norm": 1.874495267868042,
    "learning_rate": 2.8368813714793374e-06
  },
  {
    "step": 8780,
    "epoch": 3.900688735836481,
    "loss": 0.808,
    "grad_norm": 1.5838830471038818,
    "learning_rate": 2.8152736309115347e-06
  },
  {
    "step": 8790,
    "epoch": 3.9051321928460343,
    "loss": 0.7701,
    "grad_norm": 0.8135088086128235,
    "learning_rate": 2.793735006008199e-06
  },
  {
    "step": 8800,
    "epoch": 3.909575649855588,
    "loss": 0.818,
    "grad_norm": 1.1127560138702393,
    "learning_rate": 2.7722657039666945e-06
  },
  {
    "step": 8810,
    "epoch": 3.9140191068651413,
    "loss": 0.7482,
    "grad_norm": 1.8567432165145874,
    "learning_rate": 2.750865931317511e-06
  },
  {
    "step": 8820,
    "epoch": 3.9184625638746944,
    "loss": 0.8294,
    "grad_norm": 3.6862964630126953,
    "learning_rate": 2.7295358939222892e-06
  },
  {
    "step": 8830,
    "epoch": 3.922906020884248,
    "loss": 0.7833,
    "grad_norm": 0.8778626322746277,
    "learning_rate": 2.7082757969718177e-06
  },
  {
    "step": 8840,
    "epoch": 3.9273494778938014,
    "loss": 0.7911,
    "grad_norm": 0.9347036480903625,
    "learning_rate": 2.6870858449840786e-06
  },
  {
    "step": 8850,
    "epoch": 3.931792934903355,
    "loss": 0.7561,
    "grad_norm": 1.2259355783462524,
    "learning_rate": 2.6659662418022713e-06
  },
  {
    "step": 8860,
    "epoch": 3.9362363919129084,
    "loss": 0.7733,
    "grad_norm": 1.2941279411315918,
    "learning_rate": 2.644917190592855e-06
  },
  {
    "step": 8870,
    "epoch": 3.9406798489224615,
    "loss": 0.7764,
    "grad_norm": 1.7227957248687744,
    "learning_rate": 2.6239388938435884e-06
  },
  {
    "step": 8880,
    "epoch": 3.945123305932015,
    "loss": 0.7741,
    "grad_norm": 1.9108420610427856,
    "learning_rate": 2.603031553361588e-06
  },
  {
    "step": 8890,
    "epoch": 3.9495667629415685,
    "loss": 0.7571,
    "grad_norm": 1.9524400234222412,
    "learning_rate": 2.5821953702713944e-06
  },
  {
    "step": 8900,
    "epoch": 3.954010219951122,
    "loss": 0.7939,
    "grad_norm": 1.8639906644821167,
    "learning_rate": 2.5614305450130074e-06
  },
  {
    "step": 8910,
    "epoch": 3.9584536769606755,
    "loss": 0.7445,
    "grad_norm": 0.842272937297821,
    "learning_rate": 2.540737277340003e-06
  },
  {
    "step": 8920,
    "epoch": 3.9628971339702286,
    "loss": 0.7554,
    "grad_norm": 0.6849313378334045,
    "learning_rate": 2.5201157663175637e-06
  },
  {
    "step": 8930,
    "epoch": 3.9673405909797825,
    "loss": 0.7462,
    "grad_norm": 0.8204491138458252,
    "learning_rate": 2.4995662103206077e-06
  },
  {
    "step": 8940,
    "epoch": 3.9717840479893356,
    "loss": 0.8272,
    "grad_norm": 2.095407485961914,
    "learning_rate": 2.47908880703184e-06
  },
  {
    "step": 8950,
    "epoch": 3.976227504998889,
    "loss": 0.8222,
    "grad_norm": 1.6824647188186646,
    "learning_rate": 2.45868375343989e-06
  },
  {
    "step": 8960,
    "epoch": 3.9806709620084426,
    "loss": 0.7604,
    "grad_norm": 1.2482573986053467,
    "learning_rate": 2.438351245837384e-06
  },
  {
    "step": 8970,
    "epoch": 3.985114419017996,
    "loss": 0.8059,
    "grad_norm": 0.7301066517829895,
    "learning_rate": 2.4180914798190714e-06
  },
  {
    "step": 8980,
    "epoch": 3.9895578760275496,
    "loss": 0.7369,
    "grad_norm": 1.3657716512680054,
    "learning_rate": 2.3979046502799542e-06
  },
  {
    "step": 8990,
    "epoch": 3.9940013330371027,
    "loss": 0.7674,
    "grad_norm": 0.8351903557777405,
    "learning_rate": 2.3777909514133777e-06
  },
  {
    "step": 9000,
    "epoch": 3.998444790046656,
    "loss": 0.789,
    "grad_norm": 0.9218916893005371,
    "learning_rate": 2.357750576709208e-06
  },
  {
    "step": 9000,
    "epoch": 3.998444790046656,
    "eval_loss": 0.7467641830444336,
    "eval_f1": 0.5624414123528799,
    "eval_precision": 0.5882352941176471,
    "eval_recall": 0.5388146078627021,
    "eval_runtime": 40.2179,
    "eval_samples_per_second": 49.754,
    "eval_steps_per_second": 6.241
  },
  {
    "step": 9010,
    "epoch": 4.002666074205732,
    "loss": 0.796,
    "grad_norm": 0.7290943264961243,
    "learning_rate": 2.337783718951926e-06
  },
  {
    "step": 9020,
    "epoch": 4.007109531215286,
    "loss": 0.8081,
    "grad_norm": 1.9131826162338257,
    "learning_rate": 2.3178905702188125e-06
  },
  {
    "step": 9030,
    "epoch": 4.011552988224839,
    "loss": 0.7351,
    "grad_norm": 1.0590451955795288,
    "learning_rate": 2.2980713218780624e-06
  },
  {
    "step": 9040,
    "epoch": 4.015996445234392,
    "loss": 0.7844,
    "grad_norm": 1.069265604019165,
    "learning_rate": 2.278326164586985e-06
  },
  {
    "step": 9050,
    "epoch": 4.020439902243946,
    "loss": 0.7932,
    "grad_norm": 0.7018721699714661,
    "learning_rate": 2.2586552882901313e-06
  },
  {
    "step": 9060,
    "epoch": 4.024883359253499,
    "loss": 0.7433,
    "grad_norm": 1.2894303798675537,
    "learning_rate": 2.2390588822174876e-06
  },
  {
    "step": 9070,
    "epoch": 4.029326816263053,
    "loss": 0.8283,
    "grad_norm": 1.6031947135925293,
    "learning_rate": 2.219537134882662e-06
  },
  {
    "step": 9080,
    "epoch": 4.033770273272606,
    "loss": 0.7722,
    "grad_norm": 0.49683231115341187,
    "learning_rate": 2.2000902340810406e-06
  },
  {
    "step": 9090,
    "epoch": 4.03821373028216,
    "loss": 0.8161,
    "grad_norm": 0.9079614877700806,
    "learning_rate": 2.1807183668880192e-06
  },
  {
    "step": 9100,
    "epoch": 4.042657187291713,
    "loss": 0.7861,
    "grad_norm": 1.518398404121399,
    "learning_rate": 2.1614217196571695e-06
  },
  {
    "step": 9110,
    "epoch": 4.047100644301266,
    "loss": 0.7422,
    "grad_norm": 1.4744292497634888,
    "learning_rate": 2.1422004780184757e-06
  },
  {
    "step": 9120,
    "epoch": 4.05154410131082,
    "loss": 0.7508,
    "grad_norm": 1.0823373794555664,
    "learning_rate": 2.123054826876525e-06
  },
  {
    "step": 9130,
    "epoch": 4.055987558320373,
    "loss": 0.7718,
    "grad_norm": 1.297670841217041,
    "learning_rate": 2.103984950408743e-06
  },
  {
    "step": 9140,
    "epoch": 4.060431015329927,
    "loss": 0.8333,
    "grad_norm": 1.449044942855835,
    "learning_rate": 2.084991032063617e-06
  },
  {
    "step": 9150,
    "epoch": 4.06487447233948,
    "loss": 0.7386,
    "grad_norm": 0.6508429646492004,
    "learning_rate": 2.0660732545589314e-06
  },
  {
    "step": 9160,
    "epoch": 4.069317929349033,
    "loss": 0.7222,
    "grad_norm": 1.7009235620498657,
    "learning_rate": 2.047231799880011e-06
  },
  {
    "step": 9170,
    "epoch": 4.073761386358587,
    "loss": 0.7651,
    "grad_norm": 0.8697500824928284,
    "learning_rate": 2.028466849277968e-06
  },
  {
    "step": 9180,
    "epoch": 4.07820484336814,
    "loss": 0.8286,
    "grad_norm": 1.8803919553756714,
    "learning_rate": 2.0097785832679696e-06
  },
  {
    "step": 9190,
    "epoch": 4.082648300377694,
    "loss": 0.7359,
    "grad_norm": 1.921130895614624,
    "learning_rate": 1.9911671816274748e-06
  },
  {
    "step": 9200,
    "epoch": 4.087091757387247,
    "loss": 0.7763,
    "grad_norm": 1.0151352882385254,
    "learning_rate": 1.97263282339454e-06
  },
  {
    "step": 9210,
    "epoch": 4.091535214396801,
    "loss": 0.7388,
    "grad_norm": 0.8969811201095581,
    "learning_rate": 1.95417568686607e-06
  },
  {
    "step": 9220,
    "epoch": 4.095978671406354,
    "loss": 0.738,
    "grad_norm": 0.4235721826553345,
    "learning_rate": 1.935795949596112e-06
  },
  {
    "step": 9230,
    "epoch": 4.100422128415907,
    "loss": 0.7478,
    "grad_norm": 2.752561569213867,
    "learning_rate": 1.91749378839415e-06
  },
  {
    "step": 9240,
    "epoch": 4.104865585425461,
    "loss": 0.8263,
    "grad_norm": 2.1676084995269775,
    "learning_rate": 1.8992693793233997e-06
  },
  {
    "step": 9250,
    "epoch": 4.109309042435014,
    "loss": 0.7539,
    "grad_norm": 0.8112429976463318,
    "learning_rate": 1.8811228976991169e-06
  },
  {
    "step": 9260,
    "epoch": 4.113752499444568,
    "loss": 0.7508,
    "grad_norm": 1.0880764722824097,
    "learning_rate": 1.863054518086912e-06
  },
  {
    "step": 9270,
    "epoch": 4.118195956454121,
    "loss": 0.796,
    "grad_norm": 1.4745509624481201,
    "learning_rate": 1.8450644143010664e-06
  },
  {
    "step": 9280,
    "epoch": 4.122639413463674,
    "loss": 0.7684,
    "grad_norm": 1.1519984006881714,
    "learning_rate": 1.827152759402866e-06
  },
  {
    "step": 9290,
    "epoch": 4.127082870473228,
    "loss": 0.7991,
    "grad_norm": 0.8904809355735779,
    "learning_rate": 1.8093197256989304e-06
  },
  {
    "step": 9300,
    "epoch": 4.131526327482781,
    "loss": 0.7393,
    "grad_norm": 1.061627984046936,
    "learning_rate": 1.7915654847395647e-06
  },
  {
    "step": 9310,
    "epoch": 4.135969784492335,
    "loss": 0.8166,
    "grad_norm": 3.039804220199585,
    "learning_rate": 1.7738902073170982e-06
  },
  {
    "step": 9320,
    "epoch": 4.140413241501888,
    "loss": 0.8045,
    "grad_norm": 1.128230094909668,
    "learning_rate": 1.7562940634642467e-06
  },
  {
    "step": 9330,
    "epoch": 4.1448566985114415,
    "loss": 0.7898,
    "grad_norm": 0.5488578081130981,
    "learning_rate": 1.738777222452479e-06
  },
  {
    "step": 9340,
    "epoch": 4.149300155520995,
    "loss": 0.7609,
    "grad_norm": 1.2944419384002686,
    "learning_rate": 1.7213398527903824e-06
  },
  {
    "step": 9350,
    "epoch": 4.1537436125305485,
    "loss": 0.7317,
    "grad_norm": 0.18818998336791992,
    "learning_rate": 1.7039821222220498e-06
  },
  {
    "step": 9360,
    "epoch": 4.158187069540102,
    "loss": 0.7569,
    "grad_norm": 1.393058180809021,
    "learning_rate": 1.6867041977254572e-06
  },
  {
    "step": 9370,
    "epoch": 4.1626305265496555,
    "loss": 0.7632,
    "grad_norm": 1.4210642576217651,
    "learning_rate": 1.6695062455108646e-06
  },
  {
    "step": 9380,
    "epoch": 4.167073983559209,
    "loss": 0.8014,
    "grad_norm": 1.8995429277420044,
    "learning_rate": 1.6523884310192117e-06
  },
  {
    "step": 9390,
    "epoch": 4.1715174405687625,
    "loss": 0.769,
    "grad_norm": 0.9047762751579285,
    "learning_rate": 1.6353509189205362e-06
  },
  {
    "step": 9400,
    "epoch": 4.175960897578316,
    "loss": 0.7785,
    "grad_norm": 1.4420130252838135,
    "learning_rate": 1.6183938731123695e-06
  },
  {
    "step": 9410,
    "epoch": 4.1804043545878695,
    "loss": 0.7628,
    "grad_norm": 0.7271989583969116,
    "learning_rate": 1.6015174567181868e-06
  },
  {
    "step": 9420,
    "epoch": 4.184847811597423,
    "loss": 0.8244,
    "grad_norm": 1.1589549779891968,
    "learning_rate": 1.5847218320858149e-06
  },
  {
    "step": 9430,
    "epoch": 4.1892912686069765,
    "loss": 0.7906,
    "grad_norm": 1.9966657161712646,
    "learning_rate": 1.5680071607858827e-06
  },
  {
    "step": 9440,
    "epoch": 4.19373472561653,
    "loss": 0.7572,
    "grad_norm": 0.9766512513160706,
    "learning_rate": 1.5513736036102645e-06
  },
  {
    "step": 9450,
    "epoch": 4.198178182626083,
    "loss": 0.8416,
    "grad_norm": 1.370651364326477,
    "learning_rate": 1.5348213205705308e-06
  },
  {
    "step": 9460,
    "epoch": 4.202621639635637,
    "loss": 0.7411,
    "grad_norm": 1.0285649299621582,
    "learning_rate": 1.5183504708964125e-06
  },
  {
    "step": 9470,
    "epoch": 4.20706509664519,
    "loss": 0.7317,
    "grad_norm": 1.0726845264434814,
    "learning_rate": 1.5019612130342642e-06
  },
  {
    "step": 9480,
    "epoch": 4.211508553654744,
    "loss": 0.7669,
    "grad_norm": 0.48017314076423645,
    "learning_rate": 1.4856537046455522e-06
  },
  {
    "step": 9490,
    "epoch": 4.215952010664297,
    "loss": 0.8273,
    "grad_norm": 1.0535740852355957,
    "learning_rate": 1.4694281026053126e-06
  },
  {
    "step": 9500,
    "epoch": 4.220395467673851,
    "loss": 0.8006,
    "grad_norm": 2.4323673248291016,
    "learning_rate": 1.4532845630006776e-06
  },
  {
    "step": 9500,
    "epoch": 4.220395467673851,
    "eval_loss": 0.7466592788696289,
    "eval_f1": 0.5627083333333333,
    "eval_precision": 0.588581390281107,
    "eval_recall": 0.5390141688285771,
    "eval_runtime": 40.3375,
    "eval_samples_per_second": 49.606,
    "eval_steps_per_second": 6.223
  },
  {
    "step": 9510,
    "epoch": 4.224838924683404,
    "loss": 0.7937,
    "grad_norm": 0.8044329881668091,
    "learning_rate": 1.4372232411293374e-06
  },
  {
    "step": 9520,
    "epoch": 4.229282381692957,
    "loss": 0.7688,
    "grad_norm": 1.1570411920547485,
    "learning_rate": 1.4212442914980762e-06
  },
  {
    "step": 9530,
    "epoch": 4.233725838702511,
    "loss": 0.7293,
    "grad_norm": 0.8098050951957703,
    "learning_rate": 1.4053478678212683e-06
  },
  {
    "step": 9540,
    "epoch": 4.238169295712064,
    "loss": 0.7748,
    "grad_norm": 1.0891461372375488,
    "learning_rate": 1.3895341230194036e-06
  },
  {
    "step": 9550,
    "epoch": 4.242612752721618,
    "loss": 0.7735,
    "grad_norm": 1.1400752067565918,
    "learning_rate": 1.37380320921762e-06
  },
  {
    "step": 9560,
    "epoch": 4.247056209731171,
    "loss": 0.7177,
    "grad_norm": 0.501218318939209,
    "learning_rate": 1.358155277744233e-06
  },
  {
    "step": 9570,
    "epoch": 4.251499666740724,
    "loss": 0.7681,
    "grad_norm": 1.2963942289352417,
    "learning_rate": 1.3425904791292932e-06
  },
  {
    "step": 9580,
    "epoch": 4.255943123750278,
    "loss": 0.7638,
    "grad_norm": 1.0196821689605713,
    "learning_rate": 1.3271089631031152e-06
  },
  {
    "step": 9590,
    "epoch": 4.260386580759831,
    "loss": 0.8556,
    "grad_norm": 2.4290549755096436,
    "learning_rate": 1.3117108785948695e-06
  },
  {
    "step": 9600,
    "epoch": 4.264830037769385,
    "loss": 0.8001,
    "grad_norm": 1.8399661779403687,
    "learning_rate": 1.2963963737311102e-06
  },
  {
    "step": 9610,
    "epoch": 4.269273494778938,
    "loss": 0.7509,
    "grad_norm": 0.8032892942428589,
    "learning_rate": 1.2811655958343926e-06
  },
  {
    "step": 9620,
    "epoch": 4.273716951788492,
    "loss": 0.7831,
    "grad_norm": 0.4377553462982178,
    "learning_rate": 1.266018691421822e-06
  },
  {
    "step": 9630,
    "epoch": 4.278160408798045,
    "loss": 0.8452,
    "grad_norm": 1.3652595281600952,
    "learning_rate": 1.2509558062036608e-06
  },
  {
    "step": 9640,
    "epoch": 4.282603865807598,
    "loss": 0.8306,
    "grad_norm": 0.5381376147270203,
    "learning_rate": 1.235977085081922e-06
  },
  {
    "step": 9650,
    "epoch": 4.287047322817152,
    "loss": 0.8486,
    "grad_norm": 1.7432595491409302,
    "learning_rate": 1.2210826721489767e-06
  },
  {
    "step": 9660,
    "epoch": 4.291490779826705,
    "loss": 0.7867,
    "grad_norm": 1.62400484085083,
    "learning_rate": 1.2062727106861726e-06
  },
  {
    "step": 9670,
    "epoch": 4.295934236836259,
    "loss": 0.803,
    "grad_norm": 1.1724406480789185,
    "learning_rate": 1.1915473431624413e-06
  },
  {
    "step": 9680,
    "epoch": 4.300377693845812,
    "loss": 0.7811,
    "grad_norm": 1.0841164588928223,
    "learning_rate": 1.176906711232949e-06
  },
  {
    "step": 9690,
    "epoch": 4.304821150855365,
    "loss": 0.7972,
    "grad_norm": 2.0604820251464844,
    "learning_rate": 1.1623509557377066e-06
  },
  {
    "step": 9700,
    "epoch": 4.309264607864919,
    "loss": 0.8362,
    "grad_norm": 1.693947434425354,
    "learning_rate": 1.1478802167002456e-06
  },
  {
    "step": 9710,
    "epoch": 4.313708064874472,
    "loss": 0.769,
    "grad_norm": 1.0993766784667969,
    "learning_rate": 1.1334946333262487e-06
  },
  {
    "step": 9720,
    "epoch": 4.318151521884026,
    "loss": 0.8015,
    "grad_norm": 0.6882737874984741,
    "learning_rate": 1.119194344002218e-06
  },
  {
    "step": 9730,
    "epoch": 4.322594978893579,
    "loss": 0.72,
    "grad_norm": 0.9085715413093567,
    "learning_rate": 1.104979486294142e-06
  },
  {
    "step": 9740,
    "epoch": 4.327038435903132,
    "loss": 0.7966,
    "grad_norm": 1.208778738975525,
    "learning_rate": 1.0908501969461781e-06
  },
  {
    "step": 9750,
    "epoch": 4.331481892912686,
    "loss": 0.7758,
    "grad_norm": 1.5887199640274048,
    "learning_rate": 1.0768066118793286e-06
  },
  {
    "step": 9760,
    "epoch": 4.335925349922239,
    "loss": 0.7501,
    "grad_norm": 0.7097989916801453,
    "learning_rate": 1.0628488661901371e-06
  },
  {
    "step": 9770,
    "epoch": 4.340368806931793,
    "loss": 0.8078,
    "grad_norm": 1.1378061771392822,
    "learning_rate": 1.0489770941493981e-06
  },
  {
    "step": 9780,
    "epoch": 4.344812263941346,
    "loss": 0.7722,
    "grad_norm": 0.985170841217041,
    "learning_rate": 1.0351914292008425e-06
  },
  {
    "step": 9790,
    "epoch": 4.3492557209509,
    "loss": 0.7959,
    "grad_norm": 0.9207460284233093,
    "learning_rate": 1.0214920039598774e-06
  },
  {
    "step": 9800,
    "epoch": 4.353699177960453,
    "loss": 0.8036,
    "grad_norm": 2.0870680809020996,
    "learning_rate": 1.0078789502122989e-06
  },
  {
    "step": 9810,
    "epoch": 4.358142634970006,
    "loss": 0.8058,
    "grad_norm": 1.2715833187103271,
    "learning_rate": 9.943523989130243e-07
  },
  {
    "step": 9820,
    "epoch": 4.36258609197956,
    "loss": 0.7834,
    "grad_norm": 1.3222291469573975,
    "learning_rate": 9.809124801848346e-07
  },
  {
    "step": 9830,
    "epoch": 4.367029548989113,
    "loss": 0.7447,
    "grad_norm": 1.519372582435608,
    "learning_rate": 9.675593233171255e-07
  },
  {
    "step": 9840,
    "epoch": 4.371473005998667,
    "loss": 0.7797,
    "grad_norm": 1.0227224826812744,
    "learning_rate": 9.542930567646547e-07
  },
  {
    "step": 9850,
    "epoch": 4.37591646300822,
    "loss": 0.7593,
    "grad_norm": 0.974267303943634,
    "learning_rate": 9.411138081463189e-07
  },
  {
    "step": 9860,
    "epoch": 4.380359920017773,
    "loss": 0.7983,
    "grad_norm": 1.4793143272399902,
    "learning_rate": 9.28021704243911e-07
  },
  {
    "step": 9870,
    "epoch": 4.384803377027327,
    "loss": 0.8042,
    "grad_norm": 2.605281114578247,
    "learning_rate": 9.1501687100092e-07
  },
  {
    "step": 9880,
    "epoch": 4.38924683403688,
    "loss": 0.7601,
    "grad_norm": 0.9107168912887573,
    "learning_rate": 9.020994335212985e-07
  },
  {
    "step": 9890,
    "epoch": 4.393690291046434,
    "loss": 0.775,
    "grad_norm": 0.7845937609672546,
    "learning_rate": 8.892695160682719e-07
  },
  {
    "step": 9900,
    "epoch": 4.3981337480559874,
    "loss": 0.7331,
    "grad_norm": 0.9954953193664551,
    "learning_rate": 8.76527242063141e-07
  },
  {
    "step": 9910,
    "epoch": 4.402577205065541,
    "loss": 0.7597,
    "grad_norm": 1.127271294593811,
    "learning_rate": 8.638727340840935e-07
  },
  {
    "step": 9920,
    "epoch": 4.4070206620750945,
    "loss": 0.7674,
    "grad_norm": 0.6001325249671936,
    "learning_rate": 8.513061138650236e-07
  },
  {
    "step": 9930,
    "epoch": 4.4114641190846475,
    "loss": 0.7908,
    "grad_norm": 0.6433090567588806,
    "learning_rate": 8.388275022943649e-07
  },
  {
    "step": 9940,
    "epoch": 4.4159075760942015,
    "loss": 0.75,
    "grad_norm": 0.4783078730106354,
    "learning_rate": 8.264370194139226e-07
  },
  {
    "step": 9950,
    "epoch": 4.4203510331037545,
    "loss": 0.8074,
    "grad_norm": 1.092908263206482,
    "learning_rate": 8.141347844177194e-07
  },
  {
    "step": 9960,
    "epoch": 4.4247944901133085,
    "loss": 0.8139,
    "grad_norm": 0.5951809287071228,
    "learning_rate": 8.019209156508611e-07
  },
  {
    "step": 9970,
    "epoch": 4.429237947122862,
    "loss": 0.7275,
    "grad_norm": 0.9290403723716736,
    "learning_rate": 7.897955306083704e-07
  },
  {
    "step": 9980,
    "epoch": 4.433681404132415,
    "loss": 0.7853,
    "grad_norm": 1.5145633220672607,
    "learning_rate": 7.777587459340919e-07
  },
  {
    "step": 9990,
    "epoch": 4.438124861141969,
    "loss": 0.7629,
    "grad_norm": 0.825247049331665,
    "learning_rate": 7.658106774195351e-07
  },
  {
    "step": 10000,
    "epoch": 4.442568318151522,
    "loss": 0.7371,
    "grad_norm": 1.0180529356002808,
    "learning_rate": 7.539514400027925e-07
  },
  {
    "step": 10000,
    "epoch": 4.442568318151522,
    "eval_loss": 0.7461133599281311,
    "eval_f1": 0.5647792207792207,
    "eval_precision": 0.5890767230169051,
    "eval_recall": 0.5424067052484534,
    "eval_runtime": 40.4245,
    "eval_samples_per_second": 49.5,
    "eval_steps_per_second": 6.209
  },
  {
    "step": 10010,
    "epoch": 4.447011775161076,
    "loss": 0.7949,
    "grad_norm": 1.165565848350525,
    "learning_rate": 7.421811477674079e-07
  },
  {
    "step": 10020,
    "epoch": 4.451455232170629,
    "loss": 0.7285,
    "grad_norm": 1.2398021221160889,
    "learning_rate": 7.30499913941296e-07
  },
  {
    "step": 10030,
    "epoch": 4.455898689180183,
    "loss": 0.7741,
    "grad_norm": 1.95479416847229,
    "learning_rate": 7.189078508956438e-07
  },
  {
    "step": 10040,
    "epoch": 4.460342146189736,
    "loss": 0.7946,
    "grad_norm": 2.672090530395508,
    "learning_rate": 7.074050701438318e-07
  },
  {
    "step": 10050,
    "epoch": 4.464785603199289,
    "loss": 0.7559,
    "grad_norm": 0.841224730014801,
    "learning_rate": 6.959916823403701e-07
  },
  {
    "step": 10060,
    "epoch": 4.469229060208843,
    "loss": 0.7721,
    "grad_norm": 2.67598557472229,
    "learning_rate": 6.846677972798121e-07
  },
  {
    "step": 10070,
    "epoch": 4.473672517218396,
    "loss": 0.7631,
    "grad_norm": 2.647387981414795,
    "learning_rate": 6.734335238957302e-07
  },
  {
    "step": 10080,
    "epoch": 4.47811597422795,
    "loss": 0.7412,
    "grad_norm": 1.0460129976272583,
    "learning_rate": 6.622889702596302e-07
  },
  {
    "step": 10090,
    "epoch": 4.482559431237503,
    "loss": 0.7241,
    "grad_norm": 1.519946813583374,
    "learning_rate": 6.512342435799479e-07
  },
  {
    "step": 10100,
    "epoch": 4.487002888247056,
    "loss": 0.7546,
    "grad_norm": 1.1607098579406738,
    "learning_rate": 6.402694502009943e-07
  },
  {
    "step": 10110,
    "epoch": 4.49144634525661,
    "loss": 0.8359,
    "grad_norm": 0.5885798335075378,
    "learning_rate": 6.293946956019392e-07
  },
  {
    "step": 10120,
    "epoch": 4.495889802266163,
    "loss": 0.8036,
    "grad_norm": 0.6261988282203674,
    "learning_rate": 6.186100843957976e-07
  },
  {
    "step": 10130,
    "epoch": 4.500333259275717,
    "loss": 0.7596,
    "grad_norm": 1.5513865947723389,
    "learning_rate": 6.079157203284225e-07
  },
  {
    "step": 10140,
    "epoch": 4.50477671628527,
    "loss": 0.7344,
    "grad_norm": 1.2887917757034302,
    "learning_rate": 5.973117062775114e-07
  },
  {
    "step": 10150,
    "epoch": 4.509220173294823,
    "loss": 0.7672,
    "grad_norm": 1.2086169719696045,
    "learning_rate": 5.867981442516013e-07
  },
  {
    "step": 10160,
    "epoch": 4.513663630304377,
    "loss": 0.7536,
    "grad_norm": 1.5364986658096313,
    "learning_rate": 5.763751353891145e-07
  },
  {
    "step": 10170,
    "epoch": 4.51810708731393,
    "loss": 0.801,
    "grad_norm": 0.8687456846237183,
    "learning_rate": 5.660427799573531e-07
  },
  {
    "step": 10180,
    "epoch": 4.522550544323484,
    "loss": 0.7849,
    "grad_norm": 0.760168731212616,
    "learning_rate": 5.558011773515615e-07
  },
  {
    "step": 10190,
    "epoch": 4.526994001333037,
    "loss": 0.7172,
    "grad_norm": 0.9658805727958679,
    "learning_rate": 5.456504260939576e-07
  },
  {
    "step": 10200,
    "epoch": 4.531437458342591,
    "loss": 0.7505,
    "grad_norm": 0.7692299485206604,
    "learning_rate": 5.365925085891599e-07
  },
  {
    "step": 10210,
    "epoch": 4.535880915352144,
    "loss": 0.8386,
    "grad_norm": 1.5569058656692505,
    "learning_rate": 5.266146431909291e-07
  },
  {
    "step": 10220,
    "epoch": 4.540324372361697,
    "loss": 0.7587,
    "grad_norm": 1.2960214614868164,
    "learning_rate": 5.167279099096423e-07
  },
  {
    "step": 10230,
    "epoch": 4.544767829371251,
    "loss": 0.7764,
    "grad_norm": 1.8316950798034668,
    "learning_rate": 5.069324038537438e-07
  },
  {
    "step": 10240,
    "epoch": 4.549211286380804,
    "loss": 0.7228,
    "grad_norm": 0.7235320210456848,
    "learning_rate": 4.972282192540868e-07
  },
  {
    "step": 10250,
    "epoch": 4.553654743390358,
    "loss": 0.834,
    "grad_norm": 1.0089590549468994,
    "learning_rate": 4.876154494630369e-07
  },
  {
    "step": 10260,
    "epoch": 4.558098200399911,
    "loss": 0.7881,
    "grad_norm": 1.4943411350250244,
    "learning_rate": 4.78094186953556e-07
  },
  {
    "step": 10270,
    "epoch": 4.562541657409465,
    "loss": 0.7741,
    "grad_norm": 0.7584941983222961,
    "learning_rate": 4.68664523318334e-07
  },
  {
    "step": 10280,
    "epoch": 4.566985114419018,
    "loss": 0.7777,
    "grad_norm": 1.9645411968231201,
    "learning_rate": 4.593265492688914e-07
  },
  {
    "step": 10290,
    "epoch": 4.571428571428571,
    "loss": 0.6986,
    "grad_norm": 0.6829963326454163,
    "learning_rate": 4.5008035463471655e-07
  },
  {
    "step": 10300,
    "epoch": 4.575872028438125,
    "loss": 0.7773,
    "grad_norm": 0.7165039777755737,
    "learning_rate": 4.4092602836239395e-07
  },
  {
    "step": 10310,
    "epoch": 4.580315485447678,
    "loss": 0.8265,
    "grad_norm": 2.1551074981689453,
    "learning_rate": 4.318636585147562e-07
  },
  {
    "step": 10320,
    "epoch": 4.584758942457231,
    "loss": 0.7859,
    "grad_norm": 2.5968899726867676,
    "learning_rate": 4.2289333227003126e-07
  },
  {
    "step": 10330,
    "epoch": 4.589202399466785,
    "loss": 0.7515,
    "grad_norm": 1.035109043121338,
    "learning_rate": 4.1401513592100426e-07
  },
  {
    "step": 10340,
    "epoch": 4.593645856476338,
    "loss": 0.806,
    "grad_norm": 1.1865990161895752,
    "learning_rate": 4.0522915487419045e-07
  },
  {
    "step": 10350,
    "epoch": 4.598089313485892,
    "loss": 0.827,
    "grad_norm": 2.3814220428466797,
    "learning_rate": 3.965354736490112e-07
  },
  {
    "step": 10360,
    "epoch": 4.602532770495445,
    "loss": 0.7482,
    "grad_norm": 1.2554240226745605,
    "learning_rate": 3.87934175876985e-07
  },
  {
    "step": 10370,
    "epoch": 4.606976227504999,
    "loss": 0.7871,
    "grad_norm": 1.384987711906433,
    "learning_rate": 3.794253443009133e-07
  },
  {
    "step": 10380,
    "epoch": 4.611419684514552,
    "loss": 0.7141,
    "grad_norm": 0.66274493932724,
    "learning_rate": 3.710090607740957e-07
  },
  {
    "step": 10390,
    "epoch": 4.615863141524105,
    "loss": 0.7341,
    "grad_norm": 1.0879137516021729,
    "learning_rate": 3.626854062595353e-07
  },
  {
    "step": 10400,
    "epoch": 4.620306598533659,
    "loss": 0.7816,
    "grad_norm": 0.5562586784362793,
    "learning_rate": 3.544544608291622e-07
  },
  {
    "step": 10410,
    "epoch": 4.624750055543212,
    "loss": 0.798,
    "grad_norm": 0.9388855695724487,
    "learning_rate": 3.463163036630657e-07
  },
  {
    "step": 10420,
    "epoch": 4.629193512552766,
    "loss": 0.8027,
    "grad_norm": 2.4256064891815186,
    "learning_rate": 3.3827101304872657e-07
  },
  {
    "step": 10430,
    "epoch": 4.633636969562319,
    "loss": 0.7689,
    "grad_norm": 1.6654815673828125,
    "learning_rate": 3.3031866638027045e-07
  },
  {
    "step": 10440,
    "epoch": 4.638080426571873,
    "loss": 0.7518,
    "grad_norm": 0.5574358105659485,
    "learning_rate": 3.2245934015771915e-07
  },
  {
    "step": 10450,
    "epoch": 4.642523883581426,
    "loss": 0.7651,
    "grad_norm": 1.2874733209609985,
    "learning_rate": 3.146931099862538e-07
  },
  {
    "step": 10460,
    "epoch": 4.6469673405909795,
    "loss": 0.7632,
    "grad_norm": 1.125507116317749,
    "learning_rate": 3.07020050575495e-07
  },
  {
    "step": 10470,
    "epoch": 4.651410797600533,
    "loss": 0.8083,
    "grad_norm": 0.7383701801300049,
    "learning_rate": 2.9944023573877376e-07
  },
  {
    "step": 10480,
    "epoch": 4.6558542546100865,
    "loss": 0.7839,
    "grad_norm": 1.3932985067367554,
    "learning_rate": 2.919537383924298e-07
  },
  {
    "step": 10490,
    "epoch": 4.6602977116196405,
    "loss": 0.775,
    "grad_norm": 1.843689203262329,
    "learning_rate": 2.8456063055510406e-07
  },
  {
    "step": 10500,
    "epoch": 4.6647411686291935,
    "loss": 0.7989,
    "grad_norm": 1.286429762840271,
    "learning_rate": 2.7726098334705073e-07
  },
  {
    "step": 10500,
    "epoch": 4.6647411686291935,
    "eval_loss": 0.74594646692276,
    "eval_f1": 0.5666839647119876,
    "eval_precision": 0.5903979238754326,
    "eval_recall": 0.5448014368389543,
    "eval_runtime": 43.7186,
    "eval_samples_per_second": 45.77,
    "eval_steps_per_second": 5.741
  },
  {
    "step": 10510,
    "epoch": 4.669184625638747,
    "loss": 0.7911,
    "grad_norm": 2.871382236480713,
    "learning_rate": 2.7005486698945093e-07
  },
  {
    "step": 10520,
    "epoch": 4.6736280826483005,
    "loss": 0.7543,
    "grad_norm": 1.3730000257492065,
    "learning_rate": 2.629423508037343e-07
  },
  {
    "step": 10530,
    "epoch": 4.678071539657854,
    "loss": 0.7817,
    "grad_norm": 1.180567979812622,
    "learning_rate": 2.5592350321092087e-07
  },
  {
    "step": 10540,
    "epoch": 4.682514996667408,
    "loss": 0.7111,
    "grad_norm": 0.7310850024223328,
    "learning_rate": 2.489983917309502e-07
  },
  {
    "step": 10550,
    "epoch": 4.686958453676961,
    "loss": 0.8081,
    "grad_norm": 2.1215157508850098,
    "learning_rate": 2.421670829820466e-07
  },
  {
    "step": 10560,
    "epoch": 4.691401910686514,
    "loss": 0.8235,
    "grad_norm": 0.886034369468689,
    "learning_rate": 2.3542964268006063e-07
  },
  {
    "step": 10570,
    "epoch": 4.695845367696068,
    "loss": 0.7472,
    "grad_norm": 1.8985843658447266,
    "learning_rate": 2.2878613563785624e-07
  },
  {
    "step": 10580,
    "epoch": 4.700288824705621,
    "loss": 0.7528,
    "grad_norm": 1.371227502822876,
    "learning_rate": 2.222366257646713e-07
  },
  {
    "step": 10590,
    "epoch": 4.704732281715175,
    "loss": 0.7941,
    "grad_norm": 0.653429388999939,
    "learning_rate": 2.1578117606551373e-07
  },
  {
    "step": 10600,
    "epoch": 4.709175738724728,
    "loss": 0.8065,
    "grad_norm": 1.648848295211792,
    "learning_rate": 2.0941984864054742e-07
  },
  {
    "step": 10610,
    "epoch": 4.713619195734282,
    "loss": 0.8303,
    "grad_norm": 1.6355613470077515,
    "learning_rate": 2.0315270468449943e-07
  },
  {
    "step": 10620,
    "epoch": 4.718062652743835,
    "loss": 0.7773,
    "grad_norm": 1.9526910781860352,
    "learning_rate": 1.9697980448607267e-07
  },
  {
    "step": 10630,
    "epoch": 4.722506109753388,
    "loss": 0.8239,
    "grad_norm": 1.2565397024154663,
    "learning_rate": 1.9090120742735862e-07
  },
  {
    "step": 10640,
    "epoch": 4.726949566762942,
    "loss": 0.7735,
    "grad_norm": 0.5641451478004456,
    "learning_rate": 1.8491697198327774e-07
  },
  {
    "step": 10650,
    "epoch": 4.731393023772495,
    "loss": 0.7847,
    "grad_norm": 1.0658252239227295,
    "learning_rate": 1.7902715572100105e-07
  },
  {
    "step": 10660,
    "epoch": 4.735836480782049,
    "loss": 0.742,
    "grad_norm": 0.792782187461853,
    "learning_rate": 1.7323181529941613e-07
  },
  {
    "step": 10670,
    "epoch": 4.740279937791602,
    "loss": 0.8271,
    "grad_norm": 1.8251627683639526,
    "learning_rate": 1.675310064685609e-07
  },
  {
    "step": 10680,
    "epoch": 4.744723394801156,
    "loss": 0.8377,
    "grad_norm": 3.3871703147888184,
    "learning_rate": 1.6192478406910627e-07
  },
  {
    "step": 10690,
    "epoch": 4.749166851810709,
    "loss": 0.7894,
    "grad_norm": 1.5386112928390503,
    "learning_rate": 1.5641320203181655e-07
  },
  {
    "step": 10700,
    "epoch": 4.753610308820262,
    "loss": 0.7687,
    "grad_norm": 1.1761717796325684,
    "learning_rate": 1.5099631337703314e-07
  },
  {
    "step": 10710,
    "epoch": 4.758053765829816,
    "loss": 0.7424,
    "grad_norm": 1.0259326696395874,
    "learning_rate": 1.456741702141684e-07
  },
  {
    "step": 10720,
    "epoch": 4.762497222839369,
    "loss": 0.8026,
    "grad_norm": 1.029469609260559,
    "learning_rate": 1.4044682374119823e-07
  },
  {
    "step": 10730,
    "epoch": 4.766940679848922,
    "loss": 0.8372,
    "grad_norm": 1.4474080801010132,
    "learning_rate": 1.353143242441779e-07
  },
  {
    "step": 10740,
    "epoch": 4.771384136858476,
    "loss": 0.8288,
    "grad_norm": 1.467281460762024,
    "learning_rate": 1.3027672109674595e-07
  },
  {
    "step": 10750,
    "epoch": 4.775827593868029,
    "loss": 0.7274,
    "grad_norm": 0.7262673377990723,
    "learning_rate": 1.2533406275966443e-07
  },
  {
    "step": 10760,
    "epoch": 4.780271050877583,
    "loss": 0.7317,
    "grad_norm": 0.937760055065155,
    "learning_rate": 1.2048639678034048e-07
  },
  {
    "step": 10770,
    "epoch": 4.784714507887136,
    "loss": 0.7559,
    "grad_norm": 1.7316807508468628,
    "learning_rate": 1.1573376979237217e-07
  },
  {
    "step": 10780,
    "epoch": 4.78915796489669,
    "loss": 0.7957,
    "grad_norm": 1.1988543272018433,
    "learning_rate": 1.1107622751510449e-07
  },
  {
    "step": 10790,
    "epoch": 4.793601421906243,
    "loss": 0.7259,
    "grad_norm": 1.076019048690796,
    "learning_rate": 1.0651381475318523e-07
  },
  {
    "step": 10800,
    "epoch": 4.798044878915796,
    "loss": 0.7524,
    "grad_norm": 0.6185210943222046,
    "learning_rate": 1.0204657539613195e-07
  },
  {
    "step": 10810,
    "epoch": 4.80248833592535,
    "loss": 0.7258,
    "grad_norm": 2.0369133949279785,
    "learning_rate": 9.767455241791568e-08
  },
  {
    "step": 10820,
    "epoch": 4.806931792934903,
    "loss": 0.7927,
    "grad_norm": 0.9251198768615723,
    "learning_rate": 9.339778787654574e-08
  },
  {
    "step": 10830,
    "epoch": 4.811375249944457,
    "loss": 0.7935,
    "grad_norm": 1.0677516460418701,
    "learning_rate": 8.921632291365778e-08
  },
  {
    "step": 10840,
    "epoch": 4.81581870695401,
    "loss": 0.8077,
    "grad_norm": 1.3691545724868774,
    "learning_rate": 8.513019775413078e-08
  },
  {
    "step": 10850,
    "epoch": 4.820262163963564,
    "loss": 0.7907,
    "grad_norm": 1.2686306238174438,
    "learning_rate": 8.113945170569071e-08
  },
  {
    "step": 10860,
    "epoch": 4.824705620973117,
    "loss": 0.7593,
    "grad_norm": 1.2160072326660156,
    "learning_rate": 7.724412315853414e-08
  },
  {
    "step": 10870,
    "epoch": 4.82914907798267,
    "loss": 0.755,
    "grad_norm": 0.7295784950256348,
    "learning_rate": 7.344424958496188e-08
  },
  {
    "step": 10880,
    "epoch": 4.833592534992224,
    "loss": 0.7559,
    "grad_norm": 1.2018831968307495,
    "learning_rate": 6.973986753901485e-08
  },
  {
    "step": 10890,
    "epoch": 4.838035992001777,
    "loss": 0.7916,
    "grad_norm": 2.5301406383514404,
    "learning_rate": 6.613101265612431e-08
  },
  {
    "step": 10900,
    "epoch": 4.84247944901133,
    "loss": 0.7775,
    "grad_norm": 1.2424479722976685,
    "learning_rate": 6.261771965277107e-08
  },
  {
    "step": 10910,
    "epoch": 4.846922906020884,
    "loss": 0.7517,
    "grad_norm": 0.7587198615074158,
    "learning_rate": 5.9200022326146854e-08
  },
  {
    "step": 10920,
    "epoch": 4.851366363030437,
    "loss": 0.8176,
    "grad_norm": 1.9644185304641724,
    "learning_rate": 5.587795355383119e-08
  },
  {
    "step": 10930,
    "epoch": 4.855809820039991,
    "loss": 0.7778,
    "grad_norm": 1.8714953660964966,
    "learning_rate": 5.265154529347838e-08
  },
  {
    "step": 10940,
    "epoch": 4.860253277049544,
    "loss": 0.7564,
    "grad_norm": 1.05763578414917,
    "learning_rate": 4.9520828582505506e-08
  },
  {
    "step": 10950,
    "epoch": 4.864696734059098,
    "loss": 0.7965,
    "grad_norm": 0.2798347473144531,
    "learning_rate": 4.648583353779601e-08
  },
  {
    "step": 10960,
    "epoch": 4.869140191068651,
    "loss": 0.7904,
    "grad_norm": 0.6108733415603638,
    "learning_rate": 4.3546589355409894e-08
  },
  {
    "step": 10970,
    "epoch": 4.873583648078204,
    "loss": 0.7504,
    "grad_norm": 1.1991145610809326,
    "learning_rate": 4.070312431030066e-08
  },
  {
    "step": 10980,
    "epoch": 4.878027105087758,
    "loss": 0.8127,
    "grad_norm": 1.0068094730377197,
    "learning_rate": 3.7955465756047696e-08
  },
  {
    "step": 10990,
    "epoch": 4.8824705620973115,
    "loss": 0.7272,
    "grad_norm": 1.2342169284820557,
    "learning_rate": 3.5303640124589865e-08
  },
  {
    "step": 11000,
    "epoch": 4.886914019106865,
    "loss": 0.8405,
    "grad_norm": 1.251111626625061,
    "learning_rate": 3.2747672925971254e-08
  },
  {
    "step": 11000,
    "epoch": 4.886914019106865,
    "eval_loss": 0.7459147572517395,
    "eval_f1": 0.566002490660025,
    "eval_precision": 0.5896216216216216,
    "eval_recall": 0.5442027539413291,
    "eval_runtime": 46.9683,
    "eval_samples_per_second": 42.603,
    "eval_steps_per_second": 5.344
  },
  {
    "step": 11010,
    "epoch": 4.8913574761164185,
    "loss": 0.7946,
    "grad_norm": 0.9115720391273499,
    "learning_rate": 3.02875887480969e-08
  },
  {
    "step": 11020,
    "epoch": 4.895800933125972,
    "loss": 0.7589,
    "grad_norm": 1.1702830791473389,
    "learning_rate": 2.7923411256496337e-08
  },
  {
    "step": 11030,
    "epoch": 4.9002443901355255,
    "loss": 0.8368,
    "grad_norm": 1.9224134683609009,
    "learning_rate": 2.565516319409711e-08
  },
  {
    "step": 11040,
    "epoch": 4.9046878471450785,
    "loss": 0.78,
    "grad_norm": 1.4074735641479492,
    "learning_rate": 2.3482866380999393e-08
  },
  {
    "step": 11050,
    "epoch": 4.9091313041546325,
    "loss": 0.7467,
    "grad_norm": 0.8464234471321106,
    "learning_rate": 2.140654171427614e-08
  },
  {
    "step": 11060,
    "epoch": 4.913574761164186,
    "loss": 0.7846,
    "grad_norm": 1.889526605606079,
    "learning_rate": 1.9426209167765498e-08
  },
  {
    "step": 11070,
    "epoch": 4.9180182181737395,
    "loss": 0.7638,
    "grad_norm": 1.9924206733703613,
    "learning_rate": 1.7541887791878707e-08
  },
  {
    "step": 11080,
    "epoch": 4.922461675183293,
    "loss": 0.7616,
    "grad_norm": 1.0952285528182983,
    "learning_rate": 1.575359571342028e-08
  },
  {
    "step": 11090,
    "epoch": 4.926905132192846,
    "loss": 0.7347,
    "grad_norm": 1.2496522665023804,
    "learning_rate": 1.4061350135410323e-08
  },
  {
    "step": 11100,
    "epoch": 4.9313485892024,
    "loss": 0.77,
    "grad_norm": 1.2234565019607544,
    "learning_rate": 1.246516733692027e-08
  },
  {
    "step": 11110,
    "epoch": 4.935792046211953,
    "loss": 0.7502,
    "grad_norm": 1.1847671270370483,
    "learning_rate": 1.0965062672917415e-08
  },
  {
    "step": 11120,
    "epoch": 4.940235503221507,
    "loss": 0.7781,
    "grad_norm": 1.149803876876831,
    "learning_rate": 9.56105057411616e-09
  },
  {
    "step": 11130,
    "epoch": 4.94467896023106,
    "loss": 0.7748,
    "grad_norm": 0.6127244830131531,
    "learning_rate": 8.25314454683812e-09
  },
  {
    "step": 11140,
    "epoch": 4.949122417240613,
    "loss": 0.7659,
    "grad_norm": 0.7563129663467407,
    "learning_rate": 7.041357172884455e-09
  },
  {
    "step": 11150,
    "epoch": 4.953565874250167,
    "loss": 0.7916,
    "grad_norm": 0.7431365251541138,
    "learning_rate": 5.925700109411514e-09
  },
  {
    "step": 11160,
    "epoch": 4.95800933125972,
    "loss": 0.806,
    "grad_norm": 2.388517379760742,
    "learning_rate": 4.9061840888242615e-09
  },
  {
    "step": 11170,
    "epoch": 4.962452788269274,
    "loss": 0.7371,
    "grad_norm": 1.0480095148086548,
    "learning_rate": 3.982818918665255e-09
  },
  {
    "step": 11180,
    "epoch": 4.966896245278827,
    "loss": 0.7168,
    "grad_norm": 1.0540295839309692,
    "learning_rate": 3.155613481530262e-09
  },
  {
    "step": 11190,
    "epoch": 4.971339702288381,
    "loss": 0.755,
    "grad_norm": 0.6037331223487854,
    "learning_rate": 2.424575734971679e-09
  },
  {
    "step": 11200,
    "epoch": 4.975783159297934,
    "loss": 0.8024,
    "grad_norm": 1.5910576581954956,
    "learning_rate": 1.7897127114308021e-09
  },
  {
    "step": 11210,
    "epoch": 4.980226616307487,
    "loss": 0.7632,
    "grad_norm": 1.757655382156372,
    "learning_rate": 1.2510305181645532e-09
  },
  {
    "step": 11220,
    "epoch": 4.984670073317041,
    "loss": 0.8324,
    "grad_norm": 1.2606221437454224,
    "learning_rate": 8.085343371933008e-10
  },
  {
    "step": 11230,
    "epoch": 4.989113530326594,
    "loss": 0.803,
    "grad_norm": 1.4251958131790161,
    "learning_rate": 4.622284252409071e-10
  },
  {
    "step": 11240,
    "epoch": 4.993556987336148,
    "loss": 0.8213,
    "grad_norm": 1.7803603410720825,
    "learning_rate": 2.1211611370475226e-10
  },
  {
    "step": 11250,
    "epoch": 4.998000444345701,
    "loss": 0.8528,
    "grad_norm": 1.0582774877548218,
    "learning_rate": 5.819980861465624e-11
  },
  {
    "step": 11255,
    "epoch": 5.0,
    "train_runtime": 3402.1647,
    "train_samples_per_second": 26.458,
    "train_steps_per_second": 3.308,
    "total_flos": 6.343807987991808e+16,
    "train_loss": 0.8662972532871404
  }
]