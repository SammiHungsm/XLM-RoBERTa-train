[
  {
    "step": 10,
    "epoch": 0.005616399887672002,
    "loss": 2.907,
    "grad_norm": 16.82427215576172,
    "learning_rate": 1.7957351290684628e-07
  },
  {
    "step": 20,
    "epoch": 0.011232799775344004,
    "loss": 2.9304,
    "grad_norm": 20.585643768310547,
    "learning_rate": 4.040404040404041e-07
  },
  {
    "step": 30,
    "epoch": 0.016849199663016005,
    "loss": 2.9073,
    "grad_norm": 17.07275390625,
    "learning_rate": 6.285072951739619e-07
  },
  {
    "step": 40,
    "epoch": 0.02246559955068801,
    "loss": 2.8948,
    "grad_norm": 18.18145751953125,
    "learning_rate": 8.529741863075197e-07
  },
  {
    "step": 50,
    "epoch": 0.02808199943836001,
    "loss": 2.8753,
    "grad_norm": 15.383073806762695,
    "learning_rate": 1.0774410774410775e-06
  },
  {
    "step": 60,
    "epoch": 0.03369839932603201,
    "loss": 2.8534,
    "grad_norm": 16.360580444335938,
    "learning_rate": 1.3019079685746353e-06
  },
  {
    "step": 70,
    "epoch": 0.03931479921370402,
    "loss": 2.8763,
    "grad_norm": 13.510520935058594,
    "learning_rate": 1.526374859708193e-06
  },
  {
    "step": 80,
    "epoch": 0.04493119910137602,
    "loss": 2.8394,
    "grad_norm": 19.730789184570312,
    "learning_rate": 1.7508417508417511e-06
  },
  {
    "step": 90,
    "epoch": 0.05054759898904802,
    "loss": 2.844,
    "grad_norm": 15.244067192077637,
    "learning_rate": 1.9753086419753087e-06
  },
  {
    "step": 100,
    "epoch": 0.05616399887672002,
    "loss": 2.8232,
    "grad_norm": 14.714807510375977,
    "learning_rate": 2.1997755331088668e-06
  },
  {
    "step": 100,
    "epoch": 0.05616399887672002,
    "eval_loss": 2.7635953426361084,
    "eval_f1": 0.016805126987894613,
    "eval_precision": 0.009799579227106633,
    "eval_recall": 0.058941058941058944,
    "eval_runtime": 32.3509,
    "eval_samples_per_second": 48.932,
    "eval_steps_per_second": 6.12
  },
  {
    "step": 110,
    "epoch": 0.06178039876439202,
    "loss": 2.8192,
    "grad_norm": 15.28126335144043,
    "learning_rate": 2.4242424242424244e-06
  },
  {
    "step": 120,
    "epoch": 0.06739679865206402,
    "loss": 2.8012,
    "grad_norm": 13.035250663757324,
    "learning_rate": 2.6487093153759824e-06
  },
  {
    "step": 130,
    "epoch": 0.07301319853973604,
    "loss": 2.7713,
    "grad_norm": 15.91627025604248,
    "learning_rate": 2.8731762065095405e-06
  },
  {
    "step": 140,
    "epoch": 0.07862959842740803,
    "loss": 2.7395,
    "grad_norm": 19.67255401611328,
    "learning_rate": 3.0976430976430976e-06
  },
  {
    "step": 150,
    "epoch": 0.08424599831508003,
    "loss": 2.6891,
    "grad_norm": 14.944266319274902,
    "learning_rate": 3.3221099887766557e-06
  },
  {
    "step": 160,
    "epoch": 0.08986239820275203,
    "loss": 2.6691,
    "grad_norm": 16.595273971557617,
    "learning_rate": 3.5465768799102133e-06
  },
  {
    "step": 170,
    "epoch": 0.09547879809042403,
    "loss": 2.6435,
    "grad_norm": 16.035844802856445,
    "learning_rate": 3.7710437710437713e-06
  },
  {
    "step": 180,
    "epoch": 0.10109519797809605,
    "loss": 2.6208,
    "grad_norm": 16.977439880371094,
    "learning_rate": 3.995510662177329e-06
  },
  {
    "step": 190,
    "epoch": 0.10671159786576805,
    "loss": 2.6044,
    "grad_norm": 12.087971687316895,
    "learning_rate": 4.219977553310887e-06
  },
  {
    "step": 200,
    "epoch": 0.11232799775344005,
    "loss": 2.5739,
    "grad_norm": 15.356311798095703,
    "learning_rate": 4.444444444444444e-06
  },
  {
    "step": 200,
    "epoch": 0.11232799775344005,
    "eval_loss": 2.474782943725586,
    "eval_f1": 0.01888276947285602,
    "eval_precision": 0.011358258400378608,
    "eval_recall": 0.055944055944055944,
    "eval_runtime": 32.029,
    "eval_samples_per_second": 49.424,
    "eval_steps_per_second": 6.182
  },
  {
    "step": 210,
    "epoch": 0.11794439764111204,
    "loss": 2.5067,
    "grad_norm": 13.356477737426758,
    "learning_rate": 4.668911335578002e-06
  },
  {
    "step": 220,
    "epoch": 0.12356079752878404,
    "loss": 2.5127,
    "grad_norm": 15.169858932495117,
    "learning_rate": 4.89337822671156e-06
  },
  {
    "step": 230,
    "epoch": 0.12917719741645606,
    "loss": 2.4068,
    "grad_norm": 18.356348037719727,
    "learning_rate": 5.117845117845118e-06
  },
  {
    "step": 240,
    "epoch": 0.13479359730412804,
    "loss": 2.4075,
    "grad_norm": 14.92326831817627,
    "learning_rate": 5.342312008978676e-06
  },
  {
    "step": 250,
    "epoch": 0.14040999719180006,
    "loss": 2.3639,
    "grad_norm": 15.976872444152832,
    "learning_rate": 5.566778900112234e-06
  },
  {
    "step": 260,
    "epoch": 0.14602639707947207,
    "loss": 2.3574,
    "grad_norm": 15.083197593688965,
    "learning_rate": 5.791245791245792e-06
  },
  {
    "step": 270,
    "epoch": 0.15164279696714406,
    "loss": 2.3018,
    "grad_norm": 12.841556549072266,
    "learning_rate": 6.0157126823793495e-06
  },
  {
    "step": 280,
    "epoch": 0.15725919685481607,
    "loss": 2.1984,
    "grad_norm": 14.832571983337402,
    "learning_rate": 6.2401795735129076e-06
  },
  {
    "step": 290,
    "epoch": 0.16287559674248805,
    "loss": 2.2091,
    "grad_norm": 17.412235260009766,
    "learning_rate": 6.464646464646466e-06
  },
  {
    "step": 300,
    "epoch": 0.16849199663016007,
    "loss": 2.1321,
    "grad_norm": 13.311129570007324,
    "learning_rate": 6.689113355780023e-06
  },
  {
    "step": 300,
    "epoch": 0.16849199663016007,
    "eval_loss": 2.035207509994507,
    "eval_f1": 0.015886720773614228,
    "eval_precision": 0.01214040643969385,
    "eval_recall": 0.022977022977022976,
    "eval_runtime": 31.4942,
    "eval_samples_per_second": 50.263,
    "eval_steps_per_second": 6.287
  },
  {
    "step": 310,
    "epoch": 0.17410839651783208,
    "loss": 2.0966,
    "grad_norm": 14.904549598693848,
    "learning_rate": 6.913580246913581e-06
  },
  {
    "step": 320,
    "epoch": 0.17972479640550407,
    "loss": 2.0132,
    "grad_norm": 14.088085174560547,
    "learning_rate": 7.138047138047138e-06
  },
  {
    "step": 330,
    "epoch": 0.18534119629317608,
    "loss": 1.9854,
    "grad_norm": 13.960908889770508,
    "learning_rate": 7.362514029180696e-06
  },
  {
    "step": 340,
    "epoch": 0.19095759618084807,
    "loss": 1.9232,
    "grad_norm": 16.289161682128906,
    "learning_rate": 7.586980920314254e-06
  },
  {
    "step": 350,
    "epoch": 0.19657399606852008,
    "loss": 1.8821,
    "grad_norm": 10.935620307922363,
    "learning_rate": 7.811447811447812e-06
  },
  {
    "step": 360,
    "epoch": 0.2021903959561921,
    "loss": 1.8229,
    "grad_norm": 9.831161499023438,
    "learning_rate": 8.03591470258137e-06
  },
  {
    "step": 370,
    "epoch": 0.20780679584386408,
    "loss": 1.8407,
    "grad_norm": 10.787456512451172,
    "learning_rate": 8.260381593714928e-06
  },
  {
    "step": 380,
    "epoch": 0.2134231957315361,
    "loss": 1.8056,
    "grad_norm": 9.619414329528809,
    "learning_rate": 8.484848484848486e-06
  },
  {
    "step": 390,
    "epoch": 0.21903959561920808,
    "loss": 1.7263,
    "grad_norm": 8.582759857177734,
    "learning_rate": 8.709315375982044e-06
  },
  {
    "step": 400,
    "epoch": 0.2246559955068801,
    "loss": 1.7239,
    "grad_norm": 10.5972261428833,
    "learning_rate": 8.933782267115602e-06
  },
  {
    "step": 400,
    "epoch": 0.2246559955068801,
    "eval_loss": 1.546882152557373,
    "eval_f1": 0.11386796632698273,
    "eval_precision": 0.10230891719745223,
    "eval_recall": 0.12837162837162838,
    "eval_runtime": 33.1834,
    "eval_samples_per_second": 47.705,
    "eval_steps_per_second": 5.967
  },
  {
    "step": 410,
    "epoch": 0.2302723953945521,
    "loss": 1.6077,
    "grad_norm": 8.082918167114258,
    "learning_rate": 9.15824915824916e-06
  },
  {
    "step": 420,
    "epoch": 0.2358887952822241,
    "loss": 1.5897,
    "grad_norm": 7.914057731628418,
    "learning_rate": 9.382716049382717e-06
  },
  {
    "step": 430,
    "epoch": 0.2415051951698961,
    "loss": 1.5729,
    "grad_norm": 7.180578708648682,
    "learning_rate": 9.607182940516275e-06
  },
  {
    "step": 440,
    "epoch": 0.2471215950575681,
    "loss": 1.5084,
    "grad_norm": 7.30241060256958,
    "learning_rate": 9.831649831649833e-06
  },
  {
    "step": 450,
    "epoch": 0.2527379949452401,
    "loss": 1.4031,
    "grad_norm": 7.148262977600098,
    "learning_rate": 1.005611672278339e-05
  },
  {
    "step": 460,
    "epoch": 0.2583543948329121,
    "loss": 1.4447,
    "grad_norm": 5.452728271484375,
    "learning_rate": 1.0280583613916947e-05
  },
  {
    "step": 470,
    "epoch": 0.2639707947205841,
    "loss": 1.4605,
    "grad_norm": 5.467025279998779,
    "learning_rate": 1.0505050505050507e-05
  },
  {
    "step": 480,
    "epoch": 0.2695871946082561,
    "loss": 1.3036,
    "grad_norm": 7.188103199005127,
    "learning_rate": 1.0729517396184063e-05
  },
  {
    "step": 490,
    "epoch": 0.2752035944959281,
    "loss": 1.3137,
    "grad_norm": 5.483095645904541,
    "learning_rate": 1.0953984287317621e-05
  },
  {
    "step": 500,
    "epoch": 0.2808199943836001,
    "loss": 1.269,
    "grad_norm": 5.049767971038818,
    "learning_rate": 1.117845117845118e-05
  },
  {
    "step": 500,
    "epoch": 0.2808199943836001,
    "eval_loss": 1.1794848442077637,
    "eval_f1": 0.20943567045568856,
    "eval_precision": 0.26454891994917407,
    "eval_recall": 0.17332667332667331,
    "eval_runtime": 31.8619,
    "eval_samples_per_second": 49.683,
    "eval_steps_per_second": 6.214
  },
  {
    "step": 510,
    "epoch": 0.2864363942712721,
    "loss": 1.2633,
    "grad_norm": 4.609584808349609,
    "learning_rate": 1.1402918069584736e-05
  },
  {
    "step": 520,
    "epoch": 0.29205279415894414,
    "loss": 1.2624,
    "grad_norm": 4.892251968383789,
    "learning_rate": 1.1627384960718295e-05
  },
  {
    "step": 530,
    "epoch": 0.2976691940466161,
    "loss": 1.1708,
    "grad_norm": 4.179773330688477,
    "learning_rate": 1.1851851851851852e-05
  },
  {
    "step": 540,
    "epoch": 0.3032855939342881,
    "loss": 1.1387,
    "grad_norm": 3.0919189453125,
    "learning_rate": 1.2076318742985411e-05
  },
  {
    "step": 550,
    "epoch": 0.3089019938219601,
    "loss": 1.1466,
    "grad_norm": 4.053440570831299,
    "learning_rate": 1.2300785634118968e-05
  },
  {
    "step": 560,
    "epoch": 0.31451839370963214,
    "loss": 1.2453,
    "grad_norm": 2.3514773845672607,
    "learning_rate": 1.2525252525252527e-05
  },
  {
    "step": 570,
    "epoch": 0.3201347935973041,
    "loss": 1.113,
    "grad_norm": 2.038965940475464,
    "learning_rate": 1.2749719416386084e-05
  },
  {
    "step": 580,
    "epoch": 0.3257511934849761,
    "loss": 1.0769,
    "grad_norm": 3.8008460998535156,
    "learning_rate": 1.2974186307519643e-05
  },
  {
    "step": 590,
    "epoch": 0.33136759337264815,
    "loss": 1.0288,
    "grad_norm": 3.2139077186584473,
    "learning_rate": 1.31986531986532e-05
  },
  {
    "step": 600,
    "epoch": 0.33698399326032014,
    "loss": 1.0297,
    "grad_norm": 2.064340591430664,
    "learning_rate": 1.3423120089786758e-05
  },
  {
    "step": 600,
    "epoch": 0.33698399326032014,
    "eval_loss": 0.9941308498382568,
    "eval_f1": 0.25121894590202,
    "eval_precision": 0.4148773006134969,
    "eval_recall": 0.18015318015318016,
    "eval_runtime": 32.479,
    "eval_samples_per_second": 48.739,
    "eval_steps_per_second": 6.096
  },
  {
    "step": 610,
    "epoch": 0.3426003931479921,
    "loss": 1.0377,
    "grad_norm": 2.1491072177886963,
    "learning_rate": 1.3647586980920316e-05
  },
  {
    "step": 620,
    "epoch": 0.34821679303566416,
    "loss": 0.981,
    "grad_norm": 2.4503211975097656,
    "learning_rate": 1.3872053872053872e-05
  },
  {
    "step": 630,
    "epoch": 0.35383319292333615,
    "loss": 1.0716,
    "grad_norm": 2.3654019832611084,
    "learning_rate": 1.4096520763187432e-05
  },
  {
    "step": 640,
    "epoch": 0.35944959281100813,
    "loss": 0.9574,
    "grad_norm": 2.3876776695251465,
    "learning_rate": 1.4320987654320988e-05
  },
  {
    "step": 650,
    "epoch": 0.3650659926986801,
    "loss": 0.9994,
    "grad_norm": 2.083024024963379,
    "learning_rate": 1.4545454545454546e-05
  },
  {
    "step": 660,
    "epoch": 0.37068239258635216,
    "loss": 1.0801,
    "grad_norm": 1.8008471727371216,
    "learning_rate": 1.4769921436588104e-05
  },
  {
    "step": 670,
    "epoch": 0.37629879247402415,
    "loss": 0.978,
    "grad_norm": 2.062830924987793,
    "learning_rate": 1.4994388327721662e-05
  },
  {
    "step": 680,
    "epoch": 0.38191519236169613,
    "loss": 0.9796,
    "grad_norm": 2.3510303497314453,
    "learning_rate": 1.521885521885522e-05
  },
  {
    "step": 690,
    "epoch": 0.3875315922493682,
    "loss": 0.9636,
    "grad_norm": 1.0449464321136475,
    "learning_rate": 1.544332210998878e-05
  },
  {
    "step": 700,
    "epoch": 0.39314799213704016,
    "loss": 0.9328,
    "grad_norm": 0.9664485454559326,
    "learning_rate": 1.5667789001122335e-05
  },
  {
    "step": 700,
    "epoch": 0.39314799213704016,
    "eval_loss": 0.9237260222434998,
    "eval_f1": 0.30689579202467504,
    "eval_precision": 0.4534505208333333,
    "eval_recall": 0.23193473193473194,
    "eval_runtime": 33.2683,
    "eval_samples_per_second": 47.583,
    "eval_steps_per_second": 5.952
  },
  {
    "step": 710,
    "epoch": 0.39876439202471214,
    "loss": 0.9247,
    "grad_norm": 2.6505792140960693,
    "learning_rate": 1.5892255892255895e-05
  },
  {
    "step": 720,
    "epoch": 0.4043807919123842,
    "loss": 0.9316,
    "grad_norm": 1.770545244216919,
    "learning_rate": 1.611672278338945e-05
  },
  {
    "step": 730,
    "epoch": 0.40999719180005617,
    "loss": 0.9113,
    "grad_norm": 1.5645471811294556,
    "learning_rate": 1.6341189674523007e-05
  },
  {
    "step": 740,
    "epoch": 0.41561359168772816,
    "loss": 0.9488,
    "grad_norm": 2.496703624725342,
    "learning_rate": 1.6565656565656567e-05
  },
  {
    "step": 750,
    "epoch": 0.42122999157540014,
    "loss": 0.9292,
    "grad_norm": 1.374117136001587,
    "learning_rate": 1.6790123456790123e-05
  },
  {
    "step": 760,
    "epoch": 0.4268463914630722,
    "loss": 0.9444,
    "grad_norm": 2.00091290473938,
    "learning_rate": 1.7014590347923683e-05
  },
  {
    "step": 770,
    "epoch": 0.43246279135074417,
    "loss": 0.8564,
    "grad_norm": 1.4470953941345215,
    "learning_rate": 1.723905723905724e-05
  },
  {
    "step": 780,
    "epoch": 0.43807919123841615,
    "loss": 1.013,
    "grad_norm": 1.5796005725860596,
    "learning_rate": 1.74635241301908e-05
  },
  {
    "step": 790,
    "epoch": 0.4436955911260882,
    "loss": 0.9346,
    "grad_norm": 2.1378276348114014,
    "learning_rate": 1.7687991021324355e-05
  },
  {
    "step": 800,
    "epoch": 0.4493119910137602,
    "loss": 0.9301,
    "grad_norm": 1.1509360074996948,
    "learning_rate": 1.7912457912457915e-05
  },
  {
    "step": 800,
    "epoch": 0.4493119910137602,
    "eval_loss": 0.8869494795799255,
    "eval_f1": 0.3356810055260592,
    "eval_precision": 0.4806081290722929,
    "eval_recall": 0.2579087579087579,
    "eval_runtime": 33.0066,
    "eval_samples_per_second": 47.96,
    "eval_steps_per_second": 5.999
  },
  {
    "step": 810,
    "epoch": 0.45492839090143217,
    "loss": 0.943,
    "grad_norm": 1.7478530406951904,
    "learning_rate": 1.813692480359147e-05
  },
  {
    "step": 820,
    "epoch": 0.4605447907891042,
    "loss": 0.9805,
    "grad_norm": 1.0283361673355103,
    "learning_rate": 1.836139169472503e-05
  },
  {
    "step": 830,
    "epoch": 0.4661611906767762,
    "loss": 0.9673,
    "grad_norm": 2.4710755348205566,
    "learning_rate": 1.8585858585858588e-05
  },
  {
    "step": 840,
    "epoch": 0.4717775905644482,
    "loss": 0.9331,
    "grad_norm": 1.0959293842315674,
    "learning_rate": 1.8810325476992147e-05
  },
  {
    "step": 850,
    "epoch": 0.47739399045212016,
    "loss": 0.9624,
    "grad_norm": 1.3071656227111816,
    "learning_rate": 1.9034792368125704e-05
  },
  {
    "step": 860,
    "epoch": 0.4830103903397922,
    "loss": 0.8957,
    "grad_norm": 0.82945716381073,
    "learning_rate": 1.925925925925926e-05
  },
  {
    "step": 870,
    "epoch": 0.4886267902274642,
    "loss": 0.9247,
    "grad_norm": 1.2709736824035645,
    "learning_rate": 1.948372615039282e-05
  },
  {
    "step": 880,
    "epoch": 0.4942431901151362,
    "loss": 0.9255,
    "grad_norm": 1.3207814693450928,
    "learning_rate": 1.9708193041526376e-05
  },
  {
    "step": 890,
    "epoch": 0.4998595900028082,
    "loss": 0.8949,
    "grad_norm": 0.8580546379089355,
    "learning_rate": 1.9932659932659936e-05
  },
  {
    "step": 900,
    "epoch": 0.5054759898904801,
    "loss": 0.9036,
    "grad_norm": 1.0138353109359741,
    "learning_rate": 1.9999962349835244e-05
  },
  {
    "step": 900,
    "epoch": 0.5054759898904801,
    "eval_loss": 0.863377034664154,
    "eval_f1": 0.3617526440751133,
    "eval_precision": 0.5141104294478528,
    "eval_recall": 0.27905427905427904,
    "eval_runtime": 33.1995,
    "eval_samples_per_second": 47.681,
    "eval_steps_per_second": 5.964
  },
  {
    "step": 910,
    "epoch": 0.5110923897781522,
    "loss": 0.9538,
    "grad_norm": 1.1687016487121582,
    "learning_rate": 1.9999777941547487e-05
  },
  {
    "step": 920,
    "epoch": 0.5167087896658242,
    "loss": 0.8947,
    "grad_norm": 1.4792757034301758,
    "learning_rate": 1.9999439862630687e-05
  },
  {
    "step": 930,
    "epoch": 0.5223251895534962,
    "loss": 0.941,
    "grad_norm": 1.721785306930542,
    "learning_rate": 1.9998948118280234e-05
  },
  {
    "step": 940,
    "epoch": 0.5279415894411682,
    "loss": 0.8771,
    "grad_norm": 1.6779707670211792,
    "learning_rate": 1.999830271605297e-05
  },
  {
    "step": 950,
    "epoch": 0.5335579893288402,
    "loss": 0.8839,
    "grad_norm": 1.8349393606185913,
    "learning_rate": 1.9997503665867045e-05
  },
  {
    "step": 960,
    "epoch": 0.5391743892165122,
    "loss": 0.8614,
    "grad_norm": 1.944554328918457,
    "learning_rate": 1.9996550980001786e-05
  },
  {
    "step": 970,
    "epoch": 0.5447907891041842,
    "loss": 0.8238,
    "grad_norm": 1.182215929031372,
    "learning_rate": 1.9995444673097505e-05
  },
  {
    "step": 980,
    "epoch": 0.5504071889918563,
    "loss": 0.8641,
    "grad_norm": 1.5220246315002441,
    "learning_rate": 1.9994184762155264e-05
  },
  {
    "step": 990,
    "epoch": 0.5560235888795282,
    "loss": 0.8602,
    "grad_norm": 1.5204582214355469,
    "learning_rate": 1.9992771266536627e-05
  },
  {
    "step": 1000,
    "epoch": 0.5616399887672002,
    "loss": 0.9118,
    "grad_norm": 0.6611503958702087,
    "learning_rate": 1.9991204207963353e-05
  },
  {
    "step": 1000,
    "epoch": 0.5616399887672002,
    "eval_loss": 0.8487628102302551,
    "eval_f1": 0.37171980047711994,
    "eval_precision": 0.5329601990049752,
    "eval_recall": 0.2853812853812854,
    "eval_runtime": 33.177,
    "eval_samples_per_second": 47.714,
    "eval_steps_per_second": 5.968
  },
  {
    "step": 1010,
    "epoch": 0.5672563886548723,
    "loss": 0.9033,
    "grad_norm": 1.459494709968567,
    "learning_rate": 1.998948361051706e-05
  },
  {
    "step": 1020,
    "epoch": 0.5728727885425442,
    "loss": 0.8819,
    "grad_norm": 1.047475814819336,
    "learning_rate": 1.9987609500638867e-05
  },
  {
    "step": 1030,
    "epoch": 0.5784891884302162,
    "loss": 0.8875,
    "grad_norm": 1.2118016481399536,
    "learning_rate": 1.9985581907128978e-05
  },
  {
    "step": 1040,
    "epoch": 0.5841055883178883,
    "loss": 0.9135,
    "grad_norm": 1.3675752878189087,
    "learning_rate": 1.998340086114624e-05
  },
  {
    "step": 1050,
    "epoch": 0.5897219882055602,
    "loss": 0.8589,
    "grad_norm": 1.4225969314575195,
    "learning_rate": 1.9981066396207672e-05
  },
  {
    "step": 1060,
    "epoch": 0.5953383880932323,
    "loss": 0.8811,
    "grad_norm": 1.3306994438171387,
    "learning_rate": 1.9978578548187938e-05
  },
  {
    "step": 1070,
    "epoch": 0.6009547879809043,
    "loss": 0.8761,
    "grad_norm": 1.0259331464767456,
    "learning_rate": 1.9975937355318803e-05
  },
  {
    "step": 1080,
    "epoch": 0.6065711878685762,
    "loss": 0.9462,
    "grad_norm": 1.3299283981323242,
    "learning_rate": 1.9973142858188546e-05
  },
  {
    "step": 1090,
    "epoch": 0.6121875877562483,
    "loss": 0.87,
    "grad_norm": 1.1467177867889404,
    "learning_rate": 1.9970195099741335e-05
  },
  {
    "step": 1100,
    "epoch": 0.6178039876439202,
    "loss": 0.8917,
    "grad_norm": 1.0757439136505127,
    "learning_rate": 1.9967094125276563e-05
  },
  {
    "step": 1100,
    "epoch": 0.6178039876439202,
    "eval_loss": 0.8305155038833618,
    "eval_f1": 0.38078716252846145,
    "eval_precision": 0.5458501709667392,
    "eval_recall": 0.29237429237429235,
    "eval_runtime": 33.4041,
    "eval_samples_per_second": 47.389,
    "eval_steps_per_second": 5.927
  },
  {
    "step": 1110,
    "epoch": 0.6234203875315922,
    "loss": 0.8914,
    "grad_norm": 0.8674415946006775,
    "learning_rate": 1.9963839982448162e-05
  },
  {
    "step": 1120,
    "epoch": 0.6290367874192643,
    "loss": 0.8833,
    "grad_norm": 1.0405981540679932,
    "learning_rate": 1.9960432721263852e-05
  },
  {
    "step": 1130,
    "epoch": 0.6346531873069362,
    "loss": 0.8683,
    "grad_norm": 1.3384917974472046,
    "learning_rate": 1.99568723940844e-05
  },
  {
    "step": 1140,
    "epoch": 0.6402695871946082,
    "loss": 0.8243,
    "grad_norm": 1.3211920261383057,
    "learning_rate": 1.9953159055622792e-05
  },
  {
    "step": 1150,
    "epoch": 0.6458859870822803,
    "loss": 0.8408,
    "grad_norm": 0.8399317264556885,
    "learning_rate": 1.99492927629434e-05
  },
  {
    "step": 1160,
    "epoch": 0.6515023869699522,
    "loss": 0.9352,
    "grad_norm": 1.2178400754928589,
    "learning_rate": 1.9945273575461103e-05
  },
  {
    "step": 1170,
    "epoch": 0.6571187868576243,
    "loss": 0.8412,
    "grad_norm": 1.2954875230789185,
    "learning_rate": 1.9941101554940385e-05
  },
  {
    "step": 1180,
    "epoch": 0.6627351867452963,
    "loss": 0.8867,
    "grad_norm": 0.9594799280166626,
    "learning_rate": 1.9936776765494367e-05
  },
  {
    "step": 1190,
    "epoch": 0.6683515866329682,
    "loss": 0.8672,
    "grad_norm": 0.7757662534713745,
    "learning_rate": 1.993229927358384e-05
  },
  {
    "step": 1200,
    "epoch": 0.6739679865206403,
    "loss": 0.7988,
    "grad_norm": 1.0002107620239258,
    "learning_rate": 1.9927669148016227e-05
  },
  {
    "step": 1200,
    "epoch": 0.6739679865206403,
    "eval_loss": 0.8182234168052673,
    "eval_f1": 0.38808234019501625,
    "eval_precision": 0.5555210918114144,
    "eval_recall": 0.2982017982017982,
    "eval_runtime": 33.5874,
    "eval_samples_per_second": 47.131,
    "eval_steps_per_second": 5.895
  },
  {
    "step": 1210,
    "epoch": 0.6795843864083123,
    "loss": 0.8481,
    "grad_norm": 1.081398844718933,
    "learning_rate": 1.992288645994454e-05
  },
  {
    "step": 1220,
    "epoch": 0.6852007862959842,
    "loss": 0.8628,
    "grad_norm": 0.9694477319717407,
    "learning_rate": 1.9917951282866284e-05
  },
  {
    "step": 1230,
    "epoch": 0.6908171861836563,
    "loss": 0.8518,
    "grad_norm": 1.7750834226608276,
    "learning_rate": 1.9912863692622313e-05
  },
  {
    "step": 1240,
    "epoch": 0.6964335860713283,
    "loss": 0.8728,
    "grad_norm": 1.383165955543518,
    "learning_rate": 1.990762376739569e-05
  },
  {
    "step": 1250,
    "epoch": 0.7020499859590003,
    "loss": 0.8748,
    "grad_norm": 1.102941870689392,
    "learning_rate": 1.9902231587710455e-05
  },
  {
    "step": 1260,
    "epoch": 0.7076663858466723,
    "loss": 0.8581,
    "grad_norm": 1.3401439189910889,
    "learning_rate": 1.9896687236430423e-05
  },
  {
    "step": 1270,
    "epoch": 0.7132827857343443,
    "loss": 0.8874,
    "grad_norm": 1.3530607223510742,
    "learning_rate": 1.9890990798757872e-05
  },
  {
    "step": 1280,
    "epoch": 0.7188991856220163,
    "loss": 0.8116,
    "grad_norm": 1.205466389656067,
    "learning_rate": 1.9885142362232266e-05
  },
  {
    "step": 1290,
    "epoch": 0.7245155855096883,
    "loss": 0.901,
    "grad_norm": 1.3174999952316284,
    "learning_rate": 1.9879142016728893e-05
  },
  {
    "step": 1300,
    "epoch": 0.7301319853973602,
    "loss": 0.8205,
    "grad_norm": 2.163839817047119,
    "learning_rate": 1.9872989854457483e-05
  },
  {
    "step": 1300,
    "epoch": 0.7301319853973602,
    "eval_loss": 0.8077791333198547,
    "eval_f1": 0.39734667246628974,
    "eval_precision": 0.5727272727272728,
    "eval_recall": 0.3041958041958042,
    "eval_runtime": 33.4081,
    "eval_samples_per_second": 47.384,
    "eval_steps_per_second": 5.927
  },
  {
    "step": 1310,
    "epoch": 0.7357483852850323,
    "loss": 0.8689,
    "grad_norm": 1.287768006324768,
    "learning_rate": 1.9866685969960802e-05
  },
  {
    "step": 1320,
    "epoch": 0.7413647851727043,
    "loss": 0.8969,
    "grad_norm": 1.4560903310775757,
    "learning_rate": 1.98602304601132e-05
  },
  {
    "step": 1330,
    "epoch": 0.7469811850603763,
    "loss": 0.8485,
    "grad_norm": 0.7419649958610535,
    "learning_rate": 1.985362342411909e-05
  },
  {
    "step": 1340,
    "epoch": 0.7525975849480483,
    "loss": 0.8339,
    "grad_norm": 0.6975486874580383,
    "learning_rate": 1.9846864963511473e-05
  },
  {
    "step": 1350,
    "epoch": 0.7582139848357203,
    "loss": 0.8558,
    "grad_norm": 0.8885458111763,
    "learning_rate": 1.9839955182150346e-05
  },
  {
    "step": 1360,
    "epoch": 0.7638303847233923,
    "loss": 0.859,
    "grad_norm": 1.8434605598449707,
    "learning_rate": 1.983289418622111e-05
  },
  {
    "step": 1370,
    "epoch": 0.7694467846110643,
    "loss": 0.7942,
    "grad_norm": 1.1354786157608032,
    "learning_rate": 1.982568208423294e-05
  },
  {
    "step": 1380,
    "epoch": 0.7750631844987363,
    "loss": 0.8455,
    "grad_norm": 2.403338670730591,
    "learning_rate": 1.9818318987017128e-05
  },
  {
    "step": 1390,
    "epoch": 0.7806795843864083,
    "loss": 0.8674,
    "grad_norm": 1.9598405361175537,
    "learning_rate": 1.9810805007725358e-05
  },
  {
    "step": 1400,
    "epoch": 0.7862959842740803,
    "loss": 0.8191,
    "grad_norm": 0.9200155735015869,
    "learning_rate": 1.980314026182799e-05
  },
  {
    "step": 1400,
    "epoch": 0.7862959842740803,
    "eval_loss": 0.797298014163971,
    "eval_f1": 0.399523345249702,
    "eval_precision": 0.5717829457364341,
    "eval_recall": 0.307026307026307,
    "eval_runtime": 33.3142,
    "eval_samples_per_second": 47.517,
    "eval_steps_per_second": 5.943
  },
  {
    "step": 1410,
    "epoch": 0.7919123841617524,
    "loss": 0.7886,
    "grad_norm": 1.5357400178909302,
    "learning_rate": 1.9795324867112276e-05
  },
  {
    "step": 1420,
    "epoch": 0.7975287840494243,
    "loss": 0.8325,
    "grad_norm": 1.2638494968414307,
    "learning_rate": 1.978735894368054e-05
  },
  {
    "step": 1430,
    "epoch": 0.8031451839370963,
    "loss": 0.8139,
    "grad_norm": 0.6181604266166687,
    "learning_rate": 1.9779242613948345e-05
  },
  {
    "step": 1440,
    "epoch": 0.8087615838247684,
    "loss": 0.8531,
    "grad_norm": 1.2319788932800293,
    "learning_rate": 1.9770976002642616e-05
  },
  {
    "step": 1450,
    "epoch": 0.8143779837124403,
    "loss": 0.8784,
    "grad_norm": 1.1011896133422852,
    "learning_rate": 1.9762559236799706e-05
  },
  {
    "step": 1460,
    "epoch": 0.8199943836001123,
    "loss": 0.8317,
    "grad_norm": 0.8341197371482849,
    "learning_rate": 1.9753992445763454e-05
  },
  {
    "step": 1470,
    "epoch": 0.8256107834877844,
    "loss": 0.8527,
    "grad_norm": 1.1832283735275269,
    "learning_rate": 1.974527576118321e-05
  },
  {
    "step": 1480,
    "epoch": 0.8312271833754563,
    "loss": 0.8285,
    "grad_norm": 1.4527159929275513,
    "learning_rate": 1.973640931701178e-05
  },
  {
    "step": 1490,
    "epoch": 0.8368435832631284,
    "loss": 0.8282,
    "grad_norm": 1.6423858404159546,
    "learning_rate": 1.9727393249503405e-05
  },
  {
    "step": 1500,
    "epoch": 0.8424599831508003,
    "loss": 0.8771,
    "grad_norm": 1.7456027269363403,
    "learning_rate": 1.9718227697211624e-05
  },
  {
    "step": 1500,
    "epoch": 0.8424599831508003,
    "eval_loss": 0.7895147800445557,
    "eval_f1": 0.41996374106857204,
    "eval_precision": 0.5840996736873332,
    "eval_recall": 0.32783882783882784,
    "eval_runtime": 33.3004,
    "eval_samples_per_second": 47.537,
    "eval_steps_per_second": 5.946
  },
  {
    "step": 1510,
    "epoch": 0.8480763830384723,
    "loss": 0.8215,
    "grad_norm": 1.1671676635742188,
    "learning_rate": 1.9708912800987196e-05
  },
  {
    "step": 1520,
    "epoch": 0.8536927829261444,
    "loss": 0.8547,
    "grad_norm": 0.7092034816741943,
    "learning_rate": 1.9699448703975887e-05
  },
  {
    "step": 1530,
    "epoch": 0.8593091828138163,
    "loss": 0.8658,
    "grad_norm": 1.1815035343170166,
    "learning_rate": 1.9689835551616304e-05
  },
  {
    "step": 1540,
    "epoch": 0.8649255827014883,
    "loss": 0.8243,
    "grad_norm": 2.7120583057403564,
    "learning_rate": 1.968007349163765e-05
  },
  {
    "step": 1550,
    "epoch": 0.8705419825891604,
    "loss": 0.7778,
    "grad_norm": 0.8780385255813599,
    "learning_rate": 1.9670162674057435e-05
  },
  {
    "step": 1560,
    "epoch": 0.8761583824768323,
    "loss": 0.8377,
    "grad_norm": 1.4378383159637451,
    "learning_rate": 1.9660103251179204e-05
  },
  {
    "step": 1570,
    "epoch": 0.8817747823645044,
    "loss": 0.8023,
    "grad_norm": 0.8613219857215881,
    "learning_rate": 1.964989537759018e-05
  },
  {
    "step": 1580,
    "epoch": 0.8873911822521764,
    "loss": 0.8314,
    "grad_norm": 0.7656804919242859,
    "learning_rate": 1.9639539210158873e-05
  },
  {
    "step": 1590,
    "epoch": 0.8930075821398483,
    "loss": 0.8557,
    "grad_norm": 0.8539524078369141,
    "learning_rate": 1.9629034908032697e-05
  },
  {
    "step": 1600,
    "epoch": 0.8986239820275204,
    "loss": 0.784,
    "grad_norm": 1.158239722251892,
    "learning_rate": 1.9618382632635504e-05
  },
  {
    "step": 1600,
    "epoch": 0.8986239820275204,
    "eval_loss": 0.7802740335464478,
    "eval_f1": 0.44566829061639485,
    "eval_precision": 0.6123399301513388,
    "eval_recall": 0.35031635031635033,
    "eval_runtime": 33.4022,
    "eval_samples_per_second": 47.392,
    "eval_steps_per_second": 5.928
  },
  {
    "step": 1610,
    "epoch": 0.9042403819151924,
    "loss": 0.8753,
    "grad_norm": 1.2695255279541016,
    "learning_rate": 1.9607582547665123e-05
  },
  {
    "step": 1620,
    "epoch": 0.9098567818028643,
    "loss": 0.8027,
    "grad_norm": 1.3211547136306763,
    "learning_rate": 1.9596634819090815e-05
  },
  {
    "step": 1630,
    "epoch": 0.9154731816905364,
    "loss": 0.7964,
    "grad_norm": 1.0549886226654053,
    "learning_rate": 1.958553961515076e-05
  },
  {
    "step": 1640,
    "epoch": 0.9210895815782084,
    "loss": 0.8235,
    "grad_norm": 2.947053909301758,
    "learning_rate": 1.9574297106349434e-05
  },
  {
    "step": 1650,
    "epoch": 0.9267059814658803,
    "loss": 0.8247,
    "grad_norm": 1.3739347457885742,
    "learning_rate": 1.9562907465455017e-05
  },
  {
    "step": 1660,
    "epoch": 0.9323223813535524,
    "loss": 0.852,
    "grad_norm": 0.9684990048408508,
    "learning_rate": 1.955137086749672e-05
  },
  {
    "step": 1670,
    "epoch": 0.9379387812412244,
    "loss": 0.7995,
    "grad_norm": 1.290972352027893,
    "learning_rate": 1.9539687489762107e-05
  },
  {
    "step": 1680,
    "epoch": 0.9435551811288964,
    "loss": 0.8123,
    "grad_norm": 1.0797514915466309,
    "learning_rate": 1.952785751179437e-05
  },
  {
    "step": 1690,
    "epoch": 0.9491715810165684,
    "loss": 0.8585,
    "grad_norm": 1.0207133293151855,
    "learning_rate": 1.9515881115389556e-05
  },
  {
    "step": 1700,
    "epoch": 0.9547879809042403,
    "loss": 0.7861,
    "grad_norm": 1.0395573377609253,
    "learning_rate": 1.9503758484593793e-05
  },
  {
    "step": 1700,
    "epoch": 0.9547879809042403,
    "eval_loss": 0.7734044790267944,
    "eval_f1": 0.48710721369662796,
    "eval_precision": 0.6529527008116429,
    "eval_recall": 0.38844488844488845,
    "eval_runtime": 33.4832,
    "eval_samples_per_second": 47.277,
    "eval_steps_per_second": 5.913
  },
  {
    "step": 1710,
    "epoch": 0.9604043807919124,
    "loss": 0.8387,
    "grad_norm": 1.7201379537582397,
    "learning_rate": 1.9491489805700444e-05
  },
  {
    "step": 1720,
    "epoch": 0.9660207806795844,
    "loss": 0.9075,
    "grad_norm": 1.2669552564620972,
    "learning_rate": 1.947907526724726e-05
  },
  {
    "step": 1730,
    "epoch": 0.9716371805672563,
    "loss": 0.8601,
    "grad_norm": 1.80142343044281,
    "learning_rate": 1.946651506001347e-05
  },
  {
    "step": 1740,
    "epoch": 0.9772535804549284,
    "loss": 0.7826,
    "grad_norm": 0.9889060854911804,
    "learning_rate": 1.945380937701685e-05
  },
  {
    "step": 1750,
    "epoch": 0.9828699803426004,
    "loss": 0.8284,
    "grad_norm": 1.6292978525161743,
    "learning_rate": 1.9440958413510772e-05
  },
  {
    "step": 1760,
    "epoch": 0.9884863802302724,
    "loss": 0.805,
    "grad_norm": 1.0020064115524292,
    "learning_rate": 1.9427962366981182e-05
  },
  {
    "step": 1770,
    "epoch": 0.9941027801179444,
    "loss": 0.8419,
    "grad_norm": 0.9487621784210205,
    "learning_rate": 1.9414821437143577e-05
  },
  {
    "step": 1780,
    "epoch": 0.9997191800056164,
    "loss": 0.8129,
    "grad_norm": 1.0862246751785278,
    "learning_rate": 1.9401535825939946e-05
  },
  {
    "step": 1790,
    "epoch": 1.0050547598989048,
    "loss": 0.8383,
    "grad_norm": 1.4176539182662964,
    "learning_rate": 1.9388105737535635e-05
  },
  {
    "step": 1800,
    "epoch": 1.0106711597865767,
    "loss": 0.8051,
    "grad_norm": 0.95936119556427,
    "learning_rate": 1.937453137831625e-05
  },
  {
    "step": 1800,
    "epoch": 1.0106711597865767,
    "eval_loss": 0.7662495970726013,
    "eval_f1": 0.5193075898801598,
    "eval_precision": 0.6747404844290658,
    "eval_recall": 0.42207792207792205,
    "eval_runtime": 33.7452,
    "eval_samples_per_second": 46.91,
    "eval_steps_per_second": 5.868
  },
  {
    "step": 1810,
    "epoch": 1.0162875596742489,
    "loss": 0.7791,
    "grad_norm": 0.9305016398429871,
    "learning_rate": 1.9360812956884446e-05
  },
  {
    "step": 1820,
    "epoch": 1.0219039595619208,
    "loss": 0.7625,
    "grad_norm": 0.9399157166481018,
    "learning_rate": 1.9346950684056757e-05
  },
  {
    "step": 1830,
    "epoch": 1.0275203594495927,
    "loss": 0.8372,
    "grad_norm": 0.6953113675117493,
    "learning_rate": 1.9332944772860328e-05
  },
  {
    "step": 1840,
    "epoch": 1.033136759337265,
    "loss": 0.8182,
    "grad_norm": 1.0425175428390503,
    "learning_rate": 1.9318795438529657e-05
  },
  {
    "step": 1850,
    "epoch": 1.0387531592249368,
    "loss": 0.8023,
    "grad_norm": 0.7867867350578308,
    "learning_rate": 1.9304502898503284e-05
  },
  {
    "step": 1860,
    "epoch": 1.0443695591126088,
    "loss": 0.7936,
    "grad_norm": 0.9076505899429321,
    "learning_rate": 1.9290067372420448e-05
  },
  {
    "step": 1870,
    "epoch": 1.049985959000281,
    "loss": 0.8385,
    "grad_norm": 2.3498239517211914,
    "learning_rate": 1.927548908211771e-05
  },
  {
    "step": 1880,
    "epoch": 1.0556023588879528,
    "loss": 0.8039,
    "grad_norm": 1.3053067922592163,
    "learning_rate": 1.9260768251625553e-05
  },
  {
    "step": 1890,
    "epoch": 1.0612187587756248,
    "loss": 0.8138,
    "grad_norm": 1.349885106086731,
    "learning_rate": 1.924590510716493e-05
  },
  {
    "step": 1900,
    "epoch": 1.066835158663297,
    "loss": 0.7969,
    "grad_norm": 1.5049034357070923,
    "learning_rate": 1.9230899877143782e-05
  },
  {
    "step": 1900,
    "epoch": 1.066835158663297,
    "eval_loss": 0.7614187598228455,
    "eval_f1": 0.5205954323001631,
    "eval_precision": 0.6714886901630721,
    "eval_recall": 0.42507492507492506,
    "eval_runtime": 34.908,
    "eval_samples_per_second": 45.348,
    "eval_steps_per_second": 5.672
  },
  {
    "step": 1910,
    "epoch": 1.0724515585509689,
    "loss": 0.8221,
    "grad_norm": 1.2789427042007446,
    "learning_rate": 1.921575279215355e-05
  },
  {
    "step": 1920,
    "epoch": 1.0780679584386408,
    "loss": 0.8078,
    "grad_norm": 1.1077625751495361,
    "learning_rate": 1.9200464084965606e-05
  },
  {
    "step": 1930,
    "epoch": 1.083684358326313,
    "loss": 0.7727,
    "grad_norm": 1.1123114824295044,
    "learning_rate": 1.918503399052769e-05
  },
  {
    "step": 1940,
    "epoch": 1.0893007582139849,
    "loss": 0.8276,
    "grad_norm": 2.16205096244812,
    "learning_rate": 1.9169462745960307e-05
  },
  {
    "step": 1950,
    "epoch": 1.0949171581016568,
    "loss": 0.8197,
    "grad_norm": 1.0067245960235596,
    "learning_rate": 1.915375059055306e-05
  },
  {
    "step": 1960,
    "epoch": 1.100533557989329,
    "loss": 0.7933,
    "grad_norm": 0.9948036670684814,
    "learning_rate": 1.913789776576099e-05
  },
  {
    "step": 1970,
    "epoch": 1.1061499578770009,
    "loss": 0.7816,
    "grad_norm": 1.102312684059143,
    "learning_rate": 1.912190451520087e-05
  },
  {
    "step": 1980,
    "epoch": 1.1117663577646728,
    "loss": 0.7986,
    "grad_norm": 1.2682181596755981,
    "learning_rate": 1.910577108464744e-05
  },
  {
    "step": 1990,
    "epoch": 1.117382757652345,
    "loss": 0.7605,
    "grad_norm": 1.7207132577896118,
    "learning_rate": 1.9089497722029647e-05
  },
  {
    "step": 2000,
    "epoch": 1.122999157540017,
    "loss": 0.8491,
    "grad_norm": 1.837671160697937,
    "learning_rate": 1.907308467742683e-05
  },
  {
    "step": 2000,
    "epoch": 1.122999157540017,
    "eval_loss": 0.7563960552215576,
    "eval_f1": 0.5447963800904978,
    "eval_precision": 0.6877380045696877,
    "eval_recall": 0.45104895104895104,
    "eval_runtime": 34.1542,
    "eval_samples_per_second": 46.349,
    "eval_steps_per_second": 5.797
  },
  {
    "step": 2010,
    "epoch": 1.1286155574276888,
    "loss": 0.7886,
    "grad_norm": 1.6227823495864868,
    "learning_rate": 1.9056532203064884e-05
  },
  {
    "step": 2020,
    "epoch": 1.134231957315361,
    "loss": 0.8069,
    "grad_norm": 1.3766639232635498,
    "learning_rate": 1.9039840553312367e-05
  },
  {
    "step": 2030,
    "epoch": 1.139848357203033,
    "loss": 0.8186,
    "grad_norm": 1.4840816259384155,
    "learning_rate": 1.902300998467661e-05
  },
  {
    "step": 2040,
    "epoch": 1.1454647570907048,
    "loss": 0.7909,
    "grad_norm": 1.2129329442977905,
    "learning_rate": 1.900604075579976e-05
  },
  {
    "step": 2050,
    "epoch": 1.151081156978377,
    "loss": 0.839,
    "grad_norm": 1.669398546218872,
    "learning_rate": 1.8988933127454817e-05
  },
  {
    "step": 2060,
    "epoch": 1.156697556866049,
    "loss": 0.752,
    "grad_norm": 1.2948285341262817,
    "learning_rate": 1.8971687362541626e-05
  },
  {
    "step": 2070,
    "epoch": 1.1623139567537208,
    "loss": 0.7462,
    "grad_norm": 0.8615446090698242,
    "learning_rate": 1.8954303726082813e-05
  },
  {
    "step": 2080,
    "epoch": 1.1679303566413928,
    "loss": 0.7601,
    "grad_norm": 1.1111905574798584,
    "learning_rate": 1.893678248521976e-05
  },
  {
    "step": 2090,
    "epoch": 1.173546756529065,
    "loss": 0.7396,
    "grad_norm": 0.558890700340271,
    "learning_rate": 1.8919123909208445e-05
  },
  {
    "step": 2100,
    "epoch": 1.1791631564167369,
    "loss": 0.7955,
    "grad_norm": 0.7744840383529663,
    "learning_rate": 1.8901328269415347e-05
  },
  {
    "step": 2100,
    "epoch": 1.1791631564167369,
    "eval_loss": 0.7521873116493225,
    "eval_f1": 0.5572268154198625,
    "eval_precision": 0.6935283907760972,
    "eval_recall": 0.4657009657009657,
    "eval_runtime": 43.0966,
    "eval_samples_per_second": 36.731,
    "eval_steps_per_second": 4.594
  },
  {
    "step": 2110,
    "epoch": 1.1847795563044088,
    "loss": 0.8097,
    "grad_norm": 1.1477190256118774,
    "learning_rate": 1.8883395839313254e-05
  },
  {
    "step": 2120,
    "epoch": 1.190395956192081,
    "loss": 0.7965,
    "grad_norm": 0.9454537630081177,
    "learning_rate": 1.8865326894477067e-05
  },
  {
    "step": 2130,
    "epoch": 1.1960123560797529,
    "loss": 0.7837,
    "grad_norm": 0.9037796854972839,
    "learning_rate": 1.8847121712579564e-05
  },
  {
    "step": 2140,
    "epoch": 1.2016287559674248,
    "loss": 0.7784,
    "grad_norm": 0.5609717965126038,
    "learning_rate": 1.8828780573387133e-05
  },
  {
    "step": 2150,
    "epoch": 1.207245155855097,
    "loss": 0.8064,
    "grad_norm": 0.8214455246925354,
    "learning_rate": 1.881030375875547e-05
  },
  {
    "step": 2160,
    "epoch": 1.2128615557427689,
    "loss": 0.8084,
    "grad_norm": 1.7612379789352417,
    "learning_rate": 1.879169155262526e-05
  },
  {
    "step": 2170,
    "epoch": 1.2184779556304408,
    "loss": 0.8008,
    "grad_norm": 1.0911580324172974,
    "learning_rate": 1.8772944241017792e-05
  },
  {
    "step": 2180,
    "epoch": 1.224094355518113,
    "loss": 0.7572,
    "grad_norm": 2.171919345855713,
    "learning_rate": 1.8754062112030577e-05
  },
  {
    "step": 2190,
    "epoch": 1.229710755405785,
    "loss": 0.8004,
    "grad_norm": 0.9379348158836365,
    "learning_rate": 1.873504545583293e-05
  },
  {
    "step": 2200,
    "epoch": 1.2353271552934568,
    "loss": 0.7584,
    "grad_norm": 1.140642523765564,
    "learning_rate": 1.8715894564661482e-05
  },
  {
    "step": 2200,
    "epoch": 1.2353271552934568,
    "eval_loss": 0.7467513680458069,
    "eval_f1": 0.5860456051451959,
    "eval_precision": 0.7065319548872181,
    "eval_recall": 0.5006660006660006,
    "eval_runtime": 40.6311,
    "eval_samples_per_second": 38.96,
    "eval_steps_per_second": 4.873
  },
  {
    "step": 2210,
    "epoch": 1.240943555181129,
    "loss": 0.7826,
    "grad_norm": 1.4741840362548828,
    "learning_rate": 1.8696609732815726e-05
  },
  {
    "step": 2220,
    "epoch": 1.246559955068801,
    "loss": 0.7777,
    "grad_norm": 1.0437153577804565,
    "learning_rate": 1.8677191256653463e-05
  },
  {
    "step": 2230,
    "epoch": 1.2521763549564728,
    "loss": 0.7894,
    "grad_norm": 0.9182005524635315,
    "learning_rate": 1.865763943458627e-05
  },
  {
    "step": 2240,
    "epoch": 1.2577927548441448,
    "loss": 0.7612,
    "grad_norm": 1.566547155380249,
    "learning_rate": 1.8637954567074888e-05
  },
  {
    "step": 2250,
    "epoch": 1.263409154731817,
    "loss": 0.7842,
    "grad_norm": 1.3261513710021973,
    "learning_rate": 1.8618136956624644e-05
  },
  {
    "step": 2260,
    "epoch": 1.2690255546194888,
    "loss": 0.7811,
    "grad_norm": 1.4210695028305054,
    "learning_rate": 1.8598186907780757e-05
  },
  {
    "step": 2270,
    "epoch": 1.2746419545071608,
    "loss": 0.778,
    "grad_norm": 0.31936949491500854,
    "learning_rate": 1.8578104727123696e-05
  },
  {
    "step": 2280,
    "epoch": 1.280258354394833,
    "loss": 0.7797,
    "grad_norm": 0.6016597151756287,
    "learning_rate": 1.8557890723264446e-05
  },
  {
    "step": 2290,
    "epoch": 1.2858747542825049,
    "loss": 0.7594,
    "grad_norm": 0.9123831391334534,
    "learning_rate": 1.853754520683977e-05
  },
  {
    "step": 2300,
    "epoch": 1.2914911541701768,
    "loss": 0.7925,
    "grad_norm": 2.2433176040649414,
    "learning_rate": 1.851706849050745e-05
  },
  {
    "step": 2300,
    "epoch": 1.2914911541701768,
    "eval_loss": 0.7427327036857605,
    "eval_f1": 0.5979860573199071,
    "eval_precision": 0.7144840351689032,
    "eval_recall": 0.5141525141525142,
    "eval_runtime": 43.8585,
    "eval_samples_per_second": 36.093,
    "eval_steps_per_second": 4.515
  },
  {
    "step": 2310,
    "epoch": 1.297107554057849,
    "loss": 0.7578,
    "grad_norm": 2.1743149757385254,
    "learning_rate": 1.8496460888941453e-05
  },
  {
    "step": 2320,
    "epoch": 1.3027239539455209,
    "loss": 0.8121,
    "grad_norm": 0.9408822059631348,
    "learning_rate": 1.8475722718827128e-05
  },
  {
    "step": 2330,
    "epoch": 1.3083403538331928,
    "loss": 0.7987,
    "grad_norm": 0.8972659707069397,
    "learning_rate": 1.845485429885631e-05
  },
  {
    "step": 2340,
    "epoch": 1.313956753720865,
    "loss": 0.7631,
    "grad_norm": 1.83608877658844,
    "learning_rate": 1.8433855949722445e-05
  },
  {
    "step": 2350,
    "epoch": 1.3195731536085369,
    "loss": 0.7973,
    "grad_norm": 0.9718398451805115,
    "learning_rate": 1.8412727994115656e-05
  },
  {
    "step": 2360,
    "epoch": 1.3251895534962088,
    "loss": 0.7829,
    "grad_norm": 1.0947502851486206,
    "learning_rate": 1.8391470756717767e-05
  },
  {
    "step": 2370,
    "epoch": 1.330805953383881,
    "loss": 0.7997,
    "grad_norm": 1.459470272064209,
    "learning_rate": 1.8370084564197342e-05
  },
  {
    "step": 2380,
    "epoch": 1.336422353271553,
    "loss": 0.7663,
    "grad_norm": 1.0313990116119385,
    "learning_rate": 1.834856974520464e-05
  },
  {
    "step": 2390,
    "epoch": 1.3420387531592248,
    "loss": 0.7627,
    "grad_norm": 1.16054368019104,
    "learning_rate": 1.8326926630366585e-05
  },
  {
    "step": 2400,
    "epoch": 1.347655153046897,
    "loss": 0.7677,
    "grad_norm": 1.0216503143310547,
    "learning_rate": 1.830515555228167e-05
  },
  {
    "step": 2400,
    "epoch": 1.347655153046897,
    "eval_loss": 0.7381018996238708,
    "eval_f1": 0.6311252693713107,
    "eval_precision": 0.7216627383758303,
    "eval_recall": 0.5607725607725608,
    "eval_runtime": 44.1525,
    "eval_samples_per_second": 35.853,
    "eval_steps_per_second": 4.484
  },
  {
    "step": 2410,
    "epoch": 1.353271552934569,
    "loss": 0.7639,
    "grad_norm": 1.0859249830245972,
    "learning_rate": 1.8283256845514842e-05
  },
  {
    "step": 2420,
    "epoch": 1.3588879528222408,
    "loss": 0.8086,
    "grad_norm": 0.6845592260360718,
    "learning_rate": 1.8261230846592388e-05
  },
  {
    "step": 2430,
    "epoch": 1.364504352709913,
    "loss": 0.7515,
    "grad_norm": 0.931901752948761,
    "learning_rate": 1.823907789399673e-05
  },
  {
    "step": 2440,
    "epoch": 1.370120752597585,
    "loss": 0.7959,
    "grad_norm": 0.9429175853729248,
    "learning_rate": 1.8216798328161248e-05
  },
  {
    "step": 2450,
    "epoch": 1.3757371524852569,
    "loss": 0.72,
    "grad_norm": 1.0316904783248901,
    "learning_rate": 1.819439249146503e-05
  },
  {
    "step": 2460,
    "epoch": 1.381353552372929,
    "loss": 0.7892,
    "grad_norm": 0.7211927771568298,
    "learning_rate": 1.8171860728227627e-05
  },
  {
    "step": 2470,
    "epoch": 1.386969952260601,
    "loss": 0.8235,
    "grad_norm": 1.437133550643921,
    "learning_rate": 1.8149203384703747e-05
  },
  {
    "step": 2480,
    "epoch": 1.3925863521482729,
    "loss": 0.7362,
    "grad_norm": 0.8684564828872681,
    "learning_rate": 1.812642080907795e-05
  },
  {
    "step": 2490,
    "epoch": 1.398202752035945,
    "loss": 0.7377,
    "grad_norm": 1.0574511289596558,
    "learning_rate": 1.8103513351459282e-05
  },
  {
    "step": 2500,
    "epoch": 1.403819151923617,
    "loss": 0.7828,
    "grad_norm": 2.3019866943359375,
    "learning_rate": 1.80804813638759e-05
  },
  {
    "step": 2500,
    "epoch": 1.403819151923617,
    "eval_loss": 0.7360199093818665,
    "eval_f1": 0.636533432947329,
    "eval_precision": 0.7247979583156103,
    "eval_recall": 0.5674325674325674,
    "eval_runtime": 43.8421,
    "eval_samples_per_second": 36.107,
    "eval_steps_per_second": 4.516
  },
  {
    "step": 2510,
    "epoch": 1.4094355518112889,
    "loss": 0.772,
    "grad_norm": 0.9369231462478638,
    "learning_rate": 1.8057325200269664e-05
  },
  {
    "step": 2520,
    "epoch": 1.415051951698961,
    "loss": 0.7952,
    "grad_norm": 1.1074310541152954,
    "learning_rate": 1.8034045216490705e-05
  },
  {
    "step": 2530,
    "epoch": 1.420668351586633,
    "loss": 0.7685,
    "grad_norm": 1.1830434799194336,
    "learning_rate": 1.8010641770291937e-05
  },
  {
    "step": 2540,
    "epoch": 1.426284751474305,
    "loss": 0.7857,
    "grad_norm": 2.17767333984375,
    "learning_rate": 1.798711522132358e-05
  },
  {
    "step": 2550,
    "epoch": 1.431901151361977,
    "loss": 0.7904,
    "grad_norm": 0.7818789482116699,
    "learning_rate": 1.7963465931127614e-05
  },
  {
    "step": 2560,
    "epoch": 1.437517551249649,
    "loss": 0.7692,
    "grad_norm": 0.6091966032981873,
    "learning_rate": 1.7939694263132246e-05
  },
  {
    "step": 2570,
    "epoch": 1.443133951137321,
    "loss": 0.7671,
    "grad_norm": 1.0138243436813354,
    "learning_rate": 1.7915800582646302e-05
  },
  {
    "step": 2580,
    "epoch": 1.448750351024993,
    "loss": 0.7946,
    "grad_norm": 0.9656558036804199,
    "learning_rate": 1.789178525685363e-05
  },
  {
    "step": 2590,
    "epoch": 1.454366750912665,
    "loss": 0.7516,
    "grad_norm": 0.82594895362854,
    "learning_rate": 1.7867648654807442e-05
  },
  {
    "step": 2600,
    "epoch": 1.459983150800337,
    "loss": 0.7663,
    "grad_norm": 1.221764326095581,
    "learning_rate": 1.784339114742466e-05
  },
  {
    "step": 2600,
    "epoch": 1.459983150800337,
    "eval_loss": 0.7324452996253967,
    "eval_f1": 0.6441587272222736,
    "eval_precision": 0.7246618106139439,
    "eval_recall": 0.5797535797535798,
    "eval_runtime": 43.1654,
    "eval_samples_per_second": 36.673,
    "eval_steps_per_second": 4.587
  },
  {
    "step": 2610,
    "epoch": 1.465599550688009,
    "loss": 0.7938,
    "grad_norm": 1.3736677169799805,
    "learning_rate": 1.7819013107480203e-05
  },
  {
    "step": 2620,
    "epoch": 1.471215950575681,
    "loss": 0.7465,
    "grad_norm": 0.5348352193832397,
    "learning_rate": 1.7794514909601264e-05
  },
  {
    "step": 2630,
    "epoch": 1.476832350463353,
    "loss": 0.8084,
    "grad_norm": 0.9910772442817688,
    "learning_rate": 1.776989693026155e-05
  },
  {
    "step": 2640,
    "epoch": 1.482448750351025,
    "loss": 0.7681,
    "grad_norm": 1.0934213399887085,
    "learning_rate": 1.7745159547775497e-05
  },
  {
    "step": 2650,
    "epoch": 1.488065150238697,
    "loss": 0.7522,
    "grad_norm": 0.9505475759506226,
    "learning_rate": 1.7720303142292467e-05
  },
  {
    "step": 2660,
    "epoch": 1.493681550126369,
    "loss": 0.7837,
    "grad_norm": 1.0371906757354736,
    "learning_rate": 1.7695328095790878e-05
  },
  {
    "step": 2670,
    "epoch": 1.499297950014041,
    "loss": 0.7879,
    "grad_norm": 1.483466386795044,
    "learning_rate": 1.767023479207237e-05
  },
  {
    "step": 2680,
    "epoch": 1.504914349901713,
    "loss": 0.7639,
    "grad_norm": 0.8991625308990479,
    "learning_rate": 1.764502361675588e-05
  },
  {
    "step": 2690,
    "epoch": 1.510530749789385,
    "loss": 0.7887,
    "grad_norm": 1.3243045806884766,
    "learning_rate": 1.7619694957271728e-05
  },
  {
    "step": 2700,
    "epoch": 1.516147149677057,
    "loss": 0.7376,
    "grad_norm": 1.0845459699630737,
    "learning_rate": 1.7594249202855665e-05
  },
  {
    "step": 2700,
    "epoch": 1.516147149677057,
    "eval_loss": 0.7286996245384216,
    "eval_f1": 0.6552932497233493,
    "eval_precision": 0.7343943778420835,
    "eval_recall": 0.5915750915750916,
    "eval_runtime": 42.0273,
    "eval_samples_per_second": 37.666,
    "eval_steps_per_second": 4.711
  },
  {
    "step": 2710,
    "epoch": 1.521763549564729,
    "loss": 0.7501,
    "grad_norm": 1.1753149032592773,
    "learning_rate": 1.756868674454288e-05
  },
  {
    "step": 2720,
    "epoch": 1.527379949452401,
    "loss": 0.7812,
    "grad_norm": 1.3417147397994995,
    "learning_rate": 1.7543007975162e-05
  },
  {
    "step": 2730,
    "epoch": 1.5329963493400731,
    "loss": 0.7954,
    "grad_norm": 0.8348989486694336,
    "learning_rate": 1.7517213289329055e-05
  },
  {
    "step": 2740,
    "epoch": 1.538612749227745,
    "loss": 0.7679,
    "grad_norm": 1.1027199029922485,
    "learning_rate": 1.7491303083441403e-05
  },
  {
    "step": 2750,
    "epoch": 1.544229149115417,
    "loss": 0.7715,
    "grad_norm": 1.2406724691390991,
    "learning_rate": 1.746527775567165e-05
  },
  {
    "step": 2760,
    "epoch": 1.5498455490030891,
    "loss": 0.7707,
    "grad_norm": 1.407495379447937,
    "learning_rate": 1.743913770596153e-05
  },
  {
    "step": 2770,
    "epoch": 1.555461948890761,
    "loss": 0.7379,
    "grad_norm": 0.899234414100647,
    "learning_rate": 1.7412883336015752e-05
  },
  {
    "step": 2780,
    "epoch": 1.561078348778433,
    "loss": 0.7743,
    "grad_norm": 2.1039223670959473,
    "learning_rate": 1.7386515049295825e-05
  },
  {
    "step": 2790,
    "epoch": 1.5666947486661051,
    "loss": 0.7683,
    "grad_norm": 1.4873610734939575,
    "learning_rate": 1.7360033251013867e-05
  },
  {
    "step": 2800,
    "epoch": 1.572311148553777,
    "loss": 0.7682,
    "grad_norm": 1.1239441633224487,
    "learning_rate": 1.733343834812638e-05
  },
  {
    "step": 2800,
    "epoch": 1.572311148553777,
    "eval_loss": 0.7268276214599609,
    "eval_f1": 0.6797949824656057,
    "eval_precision": 0.7390029325513197,
    "eval_recall": 0.6293706293706294,
    "eval_runtime": 43.2388,
    "eval_samples_per_second": 36.611,
    "eval_steps_per_second": 4.579
  },
  {
    "step": 2810,
    "epoch": 1.577927548441449,
    "loss": 0.7936,
    "grad_norm": 0.757246196269989,
    "learning_rate": 1.730673074932798e-05
  },
  {
    "step": 2820,
    "epoch": 1.5835439483291212,
    "loss": 0.7885,
    "grad_norm": 0.7750731706619263,
    "learning_rate": 1.727991086504514e-05
  },
  {
    "step": 2830,
    "epoch": 1.589160348216793,
    "loss": 0.7878,
    "grad_norm": 1.0084551572799683,
    "learning_rate": 1.7252979107429854e-05
  },
  {
    "step": 2840,
    "epoch": 1.594776748104465,
    "loss": 0.7573,
    "grad_norm": 0.8886697888374329,
    "learning_rate": 1.7225935890353325e-05
  },
  {
    "step": 2850,
    "epoch": 1.6003931479921372,
    "loss": 0.7238,
    "grad_norm": 1.25342857837677,
    "learning_rate": 1.7198781629399602e-05
  },
  {
    "step": 2860,
    "epoch": 1.606009547879809,
    "loss": 0.7252,
    "grad_norm": 1.0967429876327515,
    "learning_rate": 1.7171516741859187e-05
  },
  {
    "step": 2870,
    "epoch": 1.611625947767481,
    "loss": 0.7796,
    "grad_norm": 0.6386825442314148,
    "learning_rate": 1.7144141646722628e-05
  },
  {
    "step": 2880,
    "epoch": 1.6172423476551532,
    "loss": 0.8017,
    "grad_norm": 0.9309083819389343,
    "learning_rate": 1.711665676467407e-05
  },
  {
    "step": 2890,
    "epoch": 1.6228587475428249,
    "loss": 0.7656,
    "grad_norm": 1.0288581848144531,
    "learning_rate": 1.708906251808481e-05
  },
  {
    "step": 2900,
    "epoch": 1.628475147430497,
    "loss": 0.7137,
    "grad_norm": 1.150730848312378,
    "learning_rate": 1.706135933100678e-05
  },
  {
    "step": 2900,
    "epoch": 1.628475147430497,
    "eval_loss": 0.7229070067405701,
    "eval_f1": 0.6810801112406925,
    "eval_precision": 0.7383777475199378,
    "eval_recall": 0.6320346320346321,
    "eval_runtime": 42.2616,
    "eval_samples_per_second": 37.457,
    "eval_steps_per_second": 4.685
  },
  {
    "step": 2910,
    "epoch": 1.6340915473181692,
    "loss": 0.8294,
    "grad_norm": 1.0039927959442139,
    "learning_rate": 1.7033547629166062e-05
  },
  {
    "step": 2920,
    "epoch": 1.639707947205841,
    "loss": 0.798,
    "grad_norm": 1.300318956375122,
    "learning_rate": 1.7005627839956308e-05
  },
  {
    "step": 2930,
    "epoch": 1.645324347093513,
    "loss": 0.7737,
    "grad_norm": 0.9209911823272705,
    "learning_rate": 1.6977600392432213e-05
  },
  {
    "step": 2940,
    "epoch": 1.6509407469811852,
    "loss": 0.7431,
    "grad_norm": 0.8201106786727905,
    "learning_rate": 1.694946571730288e-05
  },
  {
    "step": 2950,
    "epoch": 1.656557146868857,
    "loss": 0.7451,
    "grad_norm": 0.5172355771064758,
    "learning_rate": 1.6921224246925245e-05
  },
  {
    "step": 2960,
    "epoch": 1.662173546756529,
    "loss": 0.7344,
    "grad_norm": 1.1757304668426514,
    "learning_rate": 1.689287641529738e-05
  },
  {
    "step": 2970,
    "epoch": 1.6677899466442012,
    "loss": 0.7675,
    "grad_norm": 1.1881401538848877,
    "learning_rate": 1.6864422658051885e-05
  },
  {
    "step": 2980,
    "epoch": 1.673406346531873,
    "loss": 0.7527,
    "grad_norm": 0.8222705721855164,
    "learning_rate": 1.683586341244914e-05
  },
  {
    "step": 2990,
    "epoch": 1.679022746419545,
    "loss": 0.7229,
    "grad_norm": 0.7769227623939514,
    "learning_rate": 1.680719911737062e-05
  },
  {
    "step": 3000,
    "epoch": 1.6846391463072172,
    "loss": 0.752,
    "grad_norm": 0.9342797994613647,
    "learning_rate": 1.6778430213312126e-05
  },
  {
    "step": 3000,
    "epoch": 1.6846391463072172,
    "eval_loss": 0.7207109928131104,
    "eval_f1": 0.6878969496377136,
    "eval_precision": 0.7432824279914942,
    "eval_recall": 0.6401931401931402,
    "eval_runtime": 45.9608,
    "eval_samples_per_second": 34.442,
    "eval_steps_per_second": 4.308
  },
  {
    "step": 3010,
    "epoch": 1.690255546194889,
    "loss": 0.749,
    "grad_norm": 0.46305620670318604,
    "learning_rate": 1.6749557142377035e-05
  },
  {
    "step": 3020,
    "epoch": 1.695871946082561,
    "loss": 0.7586,
    "grad_norm": 1.155322551727295,
    "learning_rate": 1.67205803482695e-05
  },
  {
    "step": 3030,
    "epoch": 1.7014883459702332,
    "loss": 0.8082,
    "grad_norm": 1.4801620244979858,
    "learning_rate": 1.6691500276287627e-05
  },
  {
    "step": 3040,
    "epoch": 1.707104745857905,
    "loss": 0.7805,
    "grad_norm": 0.5961589813232422,
    "learning_rate": 1.666231737331663e-05
  },
  {
    "step": 3050,
    "epoch": 1.712721145745577,
    "loss": 0.7575,
    "grad_norm": 1.327199101448059,
    "learning_rate": 1.6633032087821978e-05
  },
  {
    "step": 3060,
    "epoch": 1.7183375456332493,
    "loss": 0.766,
    "grad_norm": 1.3623639345169067,
    "learning_rate": 1.660364486984249e-05
  },
  {
    "step": 3070,
    "epoch": 1.723953945520921,
    "loss": 0.7496,
    "grad_norm": 1.3526808023452759,
    "learning_rate": 1.6574156170983417e-05
  },
  {
    "step": 3080,
    "epoch": 1.7295703454085931,
    "loss": 0.7877,
    "grad_norm": 0.9273965358734131,
    "learning_rate": 1.6544566444409515e-05
  },
  {
    "step": 3090,
    "epoch": 1.735186745296265,
    "loss": 0.7666,
    "grad_norm": 0.45156097412109375,
    "learning_rate": 1.651487614483807e-05
  },
  {
    "step": 3100,
    "epoch": 1.740803145183937,
    "loss": 0.7593,
    "grad_norm": 0.7246245741844177,
    "learning_rate": 1.6485085728531914e-05
  },
  {
    "step": 3100,
    "epoch": 1.740803145183937,
    "eval_loss": 0.7192447781562805,
    "eval_f1": 0.6964190272581507,
    "eval_precision": 0.7488505747126437,
    "eval_recall": 0.6508491508491508,
    "eval_runtime": 44.9418,
    "eval_samples_per_second": 35.223,
    "eval_steps_per_second": 4.406
  },
  {
    "step": 3110,
    "epoch": 1.7464195450716091,
    "loss": 0.7566,
    "grad_norm": 0.8671258091926575,
    "learning_rate": 1.6455195653292417e-05
  },
  {
    "step": 3120,
    "epoch": 1.752035944959281,
    "loss": 0.7279,
    "grad_norm": 0.7311021685600281,
    "learning_rate": 1.642520637845244e-05
  },
  {
    "step": 3130,
    "epoch": 1.757652344846953,
    "loss": 0.7455,
    "grad_norm": 0.9063090085983276,
    "learning_rate": 1.6395118364869296e-05
  },
  {
    "step": 3140,
    "epoch": 1.7632687447346251,
    "loss": 0.7668,
    "grad_norm": 1.574256181716919,
    "learning_rate": 1.6364932074917646e-05
  },
  {
    "step": 3150,
    "epoch": 1.768885144622297,
    "loss": 0.7458,
    "grad_norm": 1.0522724390029907,
    "learning_rate": 1.633464797248241e-05
  },
  {
    "step": 3160,
    "epoch": 1.774501544509969,
    "loss": 0.7631,
    "grad_norm": 1.5013384819030762,
    "learning_rate": 1.630426652295163e-05
  },
  {
    "step": 3170,
    "epoch": 1.7801179443976411,
    "loss": 0.7936,
    "grad_norm": 1.623502254486084,
    "learning_rate": 1.6273788193209313e-05
  },
  {
    "step": 3180,
    "epoch": 1.785734344285313,
    "loss": 0.7451,
    "grad_norm": 1.495071291923523,
    "learning_rate": 1.6243213451628277e-05
  },
  {
    "step": 3190,
    "epoch": 1.791350744172985,
    "loss": 0.7865,
    "grad_norm": 0.6706565618515015,
    "learning_rate": 1.621254276806293e-05
  },
  {
    "step": 3200,
    "epoch": 1.7969671440606572,
    "loss": 0.7344,
    "grad_norm": 1.5345791578292847,
    "learning_rate": 1.6181776613842066e-05
  },
  {
    "step": 3200,
    "epoch": 1.7969671440606572,
    "eval_loss": 0.7167152762413025,
    "eval_f1": 0.7083333333333334,
    "eval_precision": 0.7574895714827455,
    "eval_recall": 0.6651681651681651,
    "eval_runtime": 31.956,
    "eval_samples_per_second": 49.537,
    "eval_steps_per_second": 6.196
  },
  {
    "step": 3210,
    "epoch": 1.802583543948329,
    "loss": 0.7527,
    "grad_norm": 1.0833375453948975,
    "learning_rate": 1.61509154617616e-05
  },
  {
    "step": 3220,
    "epoch": 1.808199943836001,
    "loss": 0.7415,
    "grad_norm": 1.6602624654769897,
    "learning_rate": 1.6119959786077342e-05
  },
  {
    "step": 3230,
    "epoch": 1.8138163437236732,
    "loss": 0.7332,
    "grad_norm": 1.8513140678405762,
    "learning_rate": 1.6088910062497664e-05
  },
  {
    "step": 3240,
    "epoch": 1.819432743611345,
    "loss": 0.7631,
    "grad_norm": 0.7817428708076477,
    "learning_rate": 1.6057766768176217e-05
  },
  {
    "step": 3250,
    "epoch": 1.825049143499017,
    "loss": 0.7374,
    "grad_norm": 0.9680675864219666,
    "learning_rate": 1.602653038170459e-05
  },
  {
    "step": 3260,
    "epoch": 1.8306655433866892,
    "loss": 0.7271,
    "grad_norm": 0.9143930077552795,
    "learning_rate": 1.5995201383104967e-05
  },
  {
    "step": 3270,
    "epoch": 1.8362819432743611,
    "loss": 0.7839,
    "grad_norm": 0.793610692024231,
    "learning_rate": 1.5963780253822716e-05
  },
  {
    "step": 3280,
    "epoch": 1.841898343162033,
    "loss": 0.7352,
    "grad_norm": 0.7395488023757935,
    "learning_rate": 1.5932267476719046e-05
  },
  {
    "step": 3290,
    "epoch": 1.8475147430497052,
    "loss": 0.7709,
    "grad_norm": 1.606722116470337,
    "learning_rate": 1.5900663536063524e-05
  },
  {
    "step": 3300,
    "epoch": 1.8531311429373771,
    "loss": 0.7526,
    "grad_norm": 1.8492635488510132,
    "learning_rate": 1.586896891752669e-05
  },
  {
    "step": 3300,
    "epoch": 1.8531311429373771,
    "eval_loss": 0.7142797708511353,
    "eval_f1": 0.7230407113590793,
    "eval_precision": 0.7588289112534309,
    "eval_recall": 0.6904761904761905,
    "eval_runtime": 32.0308,
    "eval_samples_per_second": 49.421,
    "eval_steps_per_second": 6.182
  },
  {
    "step": 3310,
    "epoch": 1.858747542825049,
    "loss": 0.788,
    "grad_norm": 2.9224746227264404,
    "learning_rate": 1.5837184108172553e-05
  },
  {
    "step": 3320,
    "epoch": 1.8643639427127212,
    "loss": 0.7578,
    "grad_norm": 1.218717098236084,
    "learning_rate": 1.580530959645112e-05
  },
  {
    "step": 3330,
    "epoch": 1.8699803426003931,
    "loss": 0.7375,
    "grad_norm": 1.0694243907928467,
    "learning_rate": 1.57733458721909e-05
  },
  {
    "step": 3340,
    "epoch": 1.875596742488065,
    "loss": 0.796,
    "grad_norm": 1.1573996543884277,
    "learning_rate": 1.574129342659136e-05
  },
  {
    "step": 3350,
    "epoch": 1.8812131423757372,
    "loss": 0.7549,
    "grad_norm": 2.2011423110961914,
    "learning_rate": 1.5709152752215385e-05
  },
  {
    "step": 3360,
    "epoch": 1.8868295422634092,
    "loss": 0.7438,
    "grad_norm": 0.9546521902084351,
    "learning_rate": 1.567692434298171e-05
  },
  {
    "step": 3370,
    "epoch": 1.892445942151081,
    "loss": 0.7654,
    "grad_norm": 0.6450048089027405,
    "learning_rate": 1.5644608694157318e-05
  },
  {
    "step": 3380,
    "epoch": 1.8980623420387532,
    "loss": 0.7476,
    "grad_norm": 1.2985870838165283,
    "learning_rate": 1.5612206302349856e-05
  },
  {
    "step": 3390,
    "epoch": 1.9036787419264252,
    "loss": 0.7516,
    "grad_norm": 1.6482404470443726,
    "learning_rate": 1.5579717665499966e-05
  },
  {
    "step": 3400,
    "epoch": 1.909295141814097,
    "loss": 0.7679,
    "grad_norm": 1.4659217596054077,
    "learning_rate": 1.5547143282873663e-05
  },
  {
    "step": 3400,
    "epoch": 1.909295141814097,
    "eval_loss": 0.712383508682251,
    "eval_f1": 0.7270370690400069,
    "eval_precision": 0.7557032513023172,
    "eval_recall": 0.7004662004662005,
    "eval_runtime": 32.2456,
    "eval_samples_per_second": 49.092,
    "eval_steps_per_second": 6.14
  },
  {
    "step": 3410,
    "epoch": 1.9149115417017692,
    "loss": 0.7183,
    "grad_norm": 0.5929685235023499,
    "learning_rate": 1.551448365505465e-05
  },
  {
    "step": 3420,
    "epoch": 1.9205279415894412,
    "loss": 0.7694,
    "grad_norm": 0.7932459712028503,
    "learning_rate": 1.5481739283936623e-05
  },
  {
    "step": 3430,
    "epoch": 1.926144341477113,
    "loss": 0.7588,
    "grad_norm": 0.6164252758026123,
    "learning_rate": 1.5448910672715577e-05
  },
  {
    "step": 3440,
    "epoch": 1.9317607413647853,
    "loss": 0.735,
    "grad_norm": 0.5725464224815369,
    "learning_rate": 1.541599832588204e-05
  },
  {
    "step": 3450,
    "epoch": 1.9373771412524572,
    "loss": 0.7752,
    "grad_norm": 0.6031429171562195,
    "learning_rate": 1.5383002749213348e-05
  },
  {
    "step": 3460,
    "epoch": 1.9429935411401291,
    "loss": 0.7388,
    "grad_norm": 2.049475908279419,
    "learning_rate": 1.534992444976586e-05
  },
  {
    "step": 3470,
    "epoch": 1.9486099410278013,
    "loss": 0.7329,
    "grad_norm": 0.5233907103538513,
    "learning_rate": 1.531676393586719e-05
  },
  {
    "step": 3480,
    "epoch": 1.9542263409154732,
    "loss": 0.7679,
    "grad_norm": 0.6269529461860657,
    "learning_rate": 1.5283521717108333e-05
  },
  {
    "step": 3490,
    "epoch": 1.9598427408031451,
    "loss": 0.7489,
    "grad_norm": 1.510332703590393,
    "learning_rate": 1.5250198304335909e-05
  },
  {
    "step": 3500,
    "epoch": 1.9654591406908173,
    "loss": 0.7882,
    "grad_norm": 1.1839770078659058,
    "learning_rate": 1.5216794209644275e-05
  },
  {
    "step": 3500,
    "epoch": 1.9654591406908173,
    "eval_loss": 0.7107675671577454,
    "eval_f1": 0.729694663091428,
    "eval_precision": 0.7593159315931594,
    "eval_recall": 0.7022977022977023,
    "eval_runtime": 34.2149,
    "eval_samples_per_second": 46.266,
    "eval_steps_per_second": 5.787
  },
  {
    "step": 3510,
    "epoch": 1.9710755405784892,
    "loss": 0.7858,
    "grad_norm": 1.061887264251709,
    "learning_rate": 1.5183309946367647e-05
  },
  {
    "step": 3520,
    "epoch": 1.9766919404661611,
    "loss": 0.7309,
    "grad_norm": 1.4623280763626099,
    "learning_rate": 1.5149746029072237e-05
  },
  {
    "step": 3530,
    "epoch": 1.9823083403538333,
    "loss": 0.7599,
    "grad_norm": 0.40708792209625244,
    "learning_rate": 1.511610297354832e-05
  },
  {
    "step": 3540,
    "epoch": 1.9879247402415052,
    "loss": 0.7444,
    "grad_norm": 0.7945966720581055,
    "learning_rate": 1.5082381296802338e-05
  },
  {
    "step": 3550,
    "epoch": 1.9935411401291772,
    "loss": 0.7507,
    "grad_norm": 1.3120230436325073,
    "learning_rate": 1.5048581517048914e-05
  },
  {
    "step": 3560,
    "epoch": 1.9991575400168493,
    "loss": 0.7571,
    "grad_norm": 1.8970943689346313,
    "learning_rate": 1.5014704153702932e-05
  },
  {
    "step": 3570,
    "epoch": 2.0044931199101375,
    "loss": 0.7018,
    "grad_norm": 1.168039083480835,
    "learning_rate": 1.4980749727371526e-05
  },
  {
    "step": 3580,
    "epoch": 2.0101095197978096,
    "loss": 0.7322,
    "grad_norm": 0.9278470873832703,
    "learning_rate": 1.4946718759846084e-05
  },
  {
    "step": 3590,
    "epoch": 2.0157259196854818,
    "loss": 0.7279,
    "grad_norm": 0.7743629217147827,
    "learning_rate": 1.4912611774094237e-05
  },
  {
    "step": 3600,
    "epoch": 2.0213423195731535,
    "loss": 0.7865,
    "grad_norm": 1.0558239221572876,
    "learning_rate": 1.4878429294251822e-05
  },
  {
    "step": 3600,
    "epoch": 2.0213423195731535,
    "eval_loss": 0.7092676162719727,
    "eval_f1": 0.735284052019165,
    "eval_precision": 0.7562478000703977,
    "eval_recall": 0.7154512154512155,
    "eval_runtime": 34.4589,
    "eval_samples_per_second": 45.939,
    "eval_steps_per_second": 5.746
  },
  {
    "step": 3610,
    "epoch": 2.0269587194608256,
    "loss": 0.7387,
    "grad_norm": 1.6104183197021484,
    "learning_rate": 1.4844171845614823e-05
  },
  {
    "step": 3620,
    "epoch": 2.0325751193484978,
    "loss": 0.7502,
    "grad_norm": 1.390677809715271,
    "learning_rate": 1.48098399546313e-05
  },
  {
    "step": 3630,
    "epoch": 2.0381915192361695,
    "loss": 0.7255,
    "grad_norm": 0.777858316898346,
    "learning_rate": 1.4775434148893288e-05
  },
  {
    "step": 3640,
    "epoch": 2.0438079191238416,
    "loss": 0.753,
    "grad_norm": 1.295785903930664,
    "learning_rate": 1.4740954957128717e-05
  },
  {
    "step": 3650,
    "epoch": 2.049424319011514,
    "loss": 0.708,
    "grad_norm": 0.5080360174179077,
    "learning_rate": 1.470640290919326e-05
  },
  {
    "step": 3660,
    "epoch": 2.0550407188991855,
    "loss": 0.7321,
    "grad_norm": 1.5368832349777222,
    "learning_rate": 1.4671778536062198e-05
  },
  {
    "step": 3670,
    "epoch": 2.0606571187868576,
    "loss": 0.7295,
    "grad_norm": 1.1032791137695312,
    "learning_rate": 1.463708236982227e-05
  },
  {
    "step": 3680,
    "epoch": 2.06627351867453,
    "loss": 0.7365,
    "grad_norm": 0.9968491792678833,
    "learning_rate": 1.4602314943663486e-05
  },
  {
    "step": 3690,
    "epoch": 2.0718899185622015,
    "loss": 0.7386,
    "grad_norm": 0.8020327687263489,
    "learning_rate": 1.4567476791870936e-05
  },
  {
    "step": 3700,
    "epoch": 2.0775063184498737,
    "loss": 0.7557,
    "grad_norm": 0.82770836353302,
    "learning_rate": 1.4532568449816573e-05
  },
  {
    "step": 3700,
    "epoch": 2.0775063184498737,
    "eval_loss": 0.7079797983169556,
    "eval_f1": 0.7364334397377277,
    "eval_precision": 0.764189794091316,
    "eval_recall": 0.7106227106227107,
    "eval_runtime": 38.5129,
    "eval_samples_per_second": 41.103,
    "eval_steps_per_second": 5.141
  },
  {
    "step": 3710,
    "epoch": 2.083122718337546,
    "loss": 0.7475,
    "grad_norm": 1.1284763813018799,
    "learning_rate": 1.4497590453951002e-05
  },
  {
    "step": 3720,
    "epoch": 2.0887391182252175,
    "loss": 0.7071,
    "grad_norm": 0.5612466931343079,
    "learning_rate": 1.446254334179522e-05
  },
  {
    "step": 3730,
    "epoch": 2.0943555181128897,
    "loss": 0.7619,
    "grad_norm": 0.9323508739471436,
    "learning_rate": 1.4427427651932364e-05
  },
  {
    "step": 3740,
    "epoch": 2.099971918000562,
    "loss": 0.8003,
    "grad_norm": 1.7995390892028809,
    "learning_rate": 1.4392243923999436e-05
  },
  {
    "step": 3750,
    "epoch": 2.1055883178882335,
    "loss": 0.7596,
    "grad_norm": 1.406554937362671,
    "learning_rate": 1.4356992698678995e-05
  },
  {
    "step": 3760,
    "epoch": 2.1112047177759057,
    "loss": 0.7396,
    "grad_norm": 1.4965497255325317,
    "learning_rate": 1.4321674517690872e-05
  },
  {
    "step": 3770,
    "epoch": 2.116821117663578,
    "loss": 0.7241,
    "grad_norm": 0.8569284081459045,
    "learning_rate": 1.4286289923783826e-05
  },
  {
    "step": 3780,
    "epoch": 2.1224375175512495,
    "loss": 0.7609,
    "grad_norm": 1.5458946228027344,
    "learning_rate": 1.425083946072722e-05
  },
  {
    "step": 3790,
    "epoch": 2.1280539174389217,
    "loss": 0.7289,
    "grad_norm": 1.0278797149658203,
    "learning_rate": 1.4215323673302635e-05
  },
  {
    "step": 3800,
    "epoch": 2.133670317326594,
    "loss": 0.7631,
    "grad_norm": 1.662330150604248,
    "learning_rate": 1.4179743107295535e-05
  },
  {
    "step": 3800,
    "epoch": 2.133670317326594,
    "eval_loss": 0.7066140174865723,
    "eval_f1": 0.7428915041663087,
    "eval_precision": 0.7673469387755102,
    "eval_recall": 0.71994671994672,
    "eval_runtime": 39.0448,
    "eval_samples_per_second": 40.543,
    "eval_steps_per_second": 5.071
  },
  {
    "step": 3810,
    "epoch": 2.1392867172142656,
    "loss": 0.7651,
    "grad_norm": 1.5344526767730713,
    "learning_rate": 1.4144098309486864e-05
  },
  {
    "step": 3820,
    "epoch": 2.1449031171019377,
    "loss": 0.7233,
    "grad_norm": 0.6063191294670105,
    "learning_rate": 1.410838982764463e-05
  },
  {
    "step": 3830,
    "epoch": 2.15051951698961,
    "loss": 0.7265,
    "grad_norm": 1.2460858821868896,
    "learning_rate": 1.4072618210515505e-05
  },
  {
    "step": 3840,
    "epoch": 2.1561359168772816,
    "loss": 0.711,
    "grad_norm": 0.9723895192146301,
    "learning_rate": 1.4036784007816385e-05
  },
  {
    "step": 3850,
    "epoch": 2.1617523167649537,
    "loss": 0.7801,
    "grad_norm": 0.9210297465324402,
    "learning_rate": 1.400088777022595e-05
  },
  {
    "step": 3860,
    "epoch": 2.167368716652626,
    "loss": 0.7199,
    "grad_norm": 0.9660108685493469,
    "learning_rate": 1.396493004937619e-05
  },
  {
    "step": 3870,
    "epoch": 2.1729851165402976,
    "loss": 0.7555,
    "grad_norm": 1.34940767288208,
    "learning_rate": 1.3928911397843925e-05
  },
  {
    "step": 3880,
    "epoch": 2.1786015164279697,
    "loss": 0.7101,
    "grad_norm": 1.2634694576263428,
    "learning_rate": 1.3892832369142343e-05
  },
  {
    "step": 3890,
    "epoch": 2.1842179163156414,
    "loss": 0.7323,
    "grad_norm": 1.6972277164459229,
    "learning_rate": 1.385669351771245e-05
  },
  {
    "step": 3900,
    "epoch": 2.1898343162033136,
    "loss": 0.7507,
    "grad_norm": 1.1445167064666748,
    "learning_rate": 1.3820495398914587e-05
  },
  {
    "step": 3900,
    "epoch": 2.1898343162033136,
    "eval_loss": 0.7047898173332214,
    "eval_f1": 0.7409188492915413,
    "eval_precision": 0.7650292605071821,
    "eval_recall": 0.7182817182817183,
    "eval_runtime": 41.6765,
    "eval_samples_per_second": 37.983,
    "eval_steps_per_second": 4.751
  },
  {
    "step": 3910,
    "epoch": 2.1954507160909857,
    "loss": 0.7356,
    "grad_norm": 0.8941276669502258,
    "learning_rate": 1.378423856901987e-05
  },
  {
    "step": 3920,
    "epoch": 2.201067115978658,
    "loss": 0.7386,
    "grad_norm": 0.8531147241592407,
    "learning_rate": 1.3747923585201662e-05
  },
  {
    "step": 3930,
    "epoch": 2.2066835158663296,
    "loss": 0.7502,
    "grad_norm": 0.8618427515029907,
    "learning_rate": 1.3711551005526995e-05
  },
  {
    "step": 3940,
    "epoch": 2.2122999157540018,
    "loss": 0.7817,
    "grad_norm": 0.9572486281394958,
    "learning_rate": 1.3675121388947997e-05
  },
  {
    "step": 3950,
    "epoch": 2.2179163156416735,
    "loss": 0.7632,
    "grad_norm": 1.3924978971481323,
    "learning_rate": 1.3638635295293315e-05
  },
  {
    "step": 3960,
    "epoch": 2.2235327155293456,
    "loss": 0.7434,
    "grad_norm": 1.0670922994613647,
    "learning_rate": 1.360209328525949e-05
  },
  {
    "step": 3970,
    "epoch": 2.2291491154170178,
    "loss": 0.7776,
    "grad_norm": 1.4641671180725098,
    "learning_rate": 1.3565495920402362e-05
  },
  {
    "step": 3980,
    "epoch": 2.23476551530469,
    "loss": 0.7864,
    "grad_norm": 1.7236732244491577,
    "learning_rate": 1.3528843763128428e-05
  },
  {
    "step": 3990,
    "epoch": 2.2403819151923616,
    "loss": 0.7391,
    "grad_norm": 1.0156916379928589,
    "learning_rate": 1.3492137376686203e-05
  },
  {
    "step": 4000,
    "epoch": 2.245998315080034,
    "loss": 0.7334,
    "grad_norm": 0.7940567135810852,
    "learning_rate": 1.3455377325157556e-05
  },
  {
    "step": 4000,
    "epoch": 2.245998315080034,
    "eval_loss": 0.7032055258750916,
    "eval_f1": 0.7449434350359959,
    "eval_precision": 0.7675732956552455,
    "eval_recall": 0.7236097236097236,
    "eval_runtime": 45.2921,
    "eval_samples_per_second": 34.951,
    "eval_steps_per_second": 4.372
  },
  {
    "step": 4010,
    "epoch": 2.2516147149677055,
    "loss": 0.7514,
    "grad_norm": 1.0697665214538574,
    "learning_rate": 1.3418564173449063e-05
  },
  {
    "step": 4020,
    "epoch": 2.2572311148553776,
    "loss": 0.736,
    "grad_norm": 0.7129207849502563,
    "learning_rate": 1.3381698487283303e-05
  },
  {
    "step": 4030,
    "epoch": 2.26284751474305,
    "loss": 0.7149,
    "grad_norm": 1.05391263961792,
    "learning_rate": 1.3344780833190172e-05
  },
  {
    "step": 4040,
    "epoch": 2.268463914630722,
    "loss": 0.7228,
    "grad_norm": 1.5923446416854858,
    "learning_rate": 1.3307811778498182e-05
  },
  {
    "step": 4050,
    "epoch": 2.2740803145183937,
    "loss": 0.7278,
    "grad_norm": 1.1641106605529785,
    "learning_rate": 1.3270791891325734e-05
  },
  {
    "step": 4060,
    "epoch": 2.279696714406066,
    "loss": 0.7427,
    "grad_norm": 0.9251754879951477,
    "learning_rate": 1.3233721740572403e-05
  },
  {
    "step": 4070,
    "epoch": 2.2853131142937375,
    "loss": 0.7687,
    "grad_norm": 1.8756868839263916,
    "learning_rate": 1.319660189591017e-05
  },
  {
    "step": 4080,
    "epoch": 2.2909295141814097,
    "loss": 0.7499,
    "grad_norm": 0.5569472908973694,
    "learning_rate": 1.3159432927774693e-05
  },
  {
    "step": 4090,
    "epoch": 2.296545914069082,
    "loss": 0.7079,
    "grad_norm": 1.1909018754959106,
    "learning_rate": 1.312221540735653e-05
  },
  {
    "step": 4100,
    "epoch": 2.302162313956754,
    "loss": 0.7095,
    "grad_norm": 1.0939046144485474,
    "learning_rate": 1.3084949906592357e-05
  },
  {
    "step": 4100,
    "epoch": 2.302162313956754,
    "eval_loss": 0.702056348323822,
    "eval_f1": 0.7474522565727499,
    "eval_precision": 0.7695291835655087,
    "eval_recall": 0.7266067266067266,
    "eval_runtime": 32.8453,
    "eval_samples_per_second": 48.196,
    "eval_steps_per_second": 6.028
  },
  {
    "step": 4110,
    "epoch": 2.3077787138444257,
    "loss": 0.7299,
    "grad_norm": 0.7469573020935059,
    "learning_rate": 1.3047636998156182e-05
  },
  {
    "step": 4120,
    "epoch": 2.313395113732098,
    "loss": 0.7264,
    "grad_norm": 0.7303701639175415,
    "learning_rate": 1.3010277255450555e-05
  },
  {
    "step": 4130,
    "epoch": 2.3190115136197695,
    "loss": 0.7193,
    "grad_norm": 0.5757107138633728,
    "learning_rate": 1.2972871252597734e-05
  },
  {
    "step": 4140,
    "epoch": 2.3246279135074417,
    "loss": 0.7272,
    "grad_norm": 0.622451901435852,
    "learning_rate": 1.2935419564430889e-05
  },
  {
    "step": 4150,
    "epoch": 2.330244313395114,
    "loss": 0.7236,
    "grad_norm": 0.5735377669334412,
    "learning_rate": 1.2897922766485244e-05
  },
  {
    "step": 4160,
    "epoch": 2.3358607132827856,
    "loss": 0.756,
    "grad_norm": 1.0391714572906494,
    "learning_rate": 1.2860381434989248e-05
  },
  {
    "step": 4170,
    "epoch": 2.3414771131704577,
    "loss": 0.7532,
    "grad_norm": 0.6262572407722473,
    "learning_rate": 1.2822796146855719e-05
  },
  {
    "step": 4180,
    "epoch": 2.34709351305813,
    "loss": 0.7091,
    "grad_norm": 1.6445914506912231,
    "learning_rate": 1.278516747967296e-05
  },
  {
    "step": 4190,
    "epoch": 2.3527099129458016,
    "loss": 0.7567,
    "grad_norm": 0.9542454481124878,
    "learning_rate": 1.2747496011695918e-05
  },
  {
    "step": 4200,
    "epoch": 2.3583263128334737,
    "loss": 0.7305,
    "grad_norm": 1.0047707557678223,
    "learning_rate": 1.270978232183726e-05
  },
  {
    "step": 4200,
    "epoch": 2.3583263128334737,
    "eval_loss": 0.7009631395339966,
    "eval_f1": 0.749637217242851,
    "eval_precision": 0.7691364512173761,
    "eval_recall": 0.731102231102231,
    "eval_runtime": 32.3859,
    "eval_samples_per_second": 48.879,
    "eval_steps_per_second": 6.114
  },
  {
    "step": 4210,
    "epoch": 2.363942712721146,
    "loss": 0.7278,
    "grad_norm": 1.2605235576629639,
    "learning_rate": 1.2675804380250015e-05
  },
  {
    "step": 4220,
    "epoch": 2.3695591126088176,
    "loss": 0.7242,
    "grad_norm": 0.9644022583961487,
    "learning_rate": 1.2638012066037351e-05
  },
  {
    "step": 4230,
    "epoch": 2.3751755124964897,
    "loss": 0.7131,
    "grad_norm": 0.6082117557525635,
    "learning_rate": 1.2600179212427114e-05
  },
  {
    "step": 4240,
    "epoch": 2.380791912384162,
    "loss": 0.7456,
    "grad_norm": 1.953730821609497,
    "learning_rate": 1.2562306400812057e-05
  },
  {
    "step": 4250,
    "epoch": 2.3864083122718336,
    "loss": 0.7296,
    "grad_norm": 1.2753053903579712,
    "learning_rate": 1.2524394213198976e-05
  },
  {
    "step": 4260,
    "epoch": 2.3920247121595057,
    "loss": 0.7451,
    "grad_norm": 1.798505187034607,
    "learning_rate": 1.248644323219979e-05
  },
  {
    "step": 4270,
    "epoch": 2.397641112047178,
    "loss": 0.7424,
    "grad_norm": 0.6372842788696289,
    "learning_rate": 1.2448454041022553e-05
  },
  {
    "step": 4280,
    "epoch": 2.4032575119348496,
    "loss": 0.7313,
    "grad_norm": 0.6834731698036194,
    "learning_rate": 1.2410427223462524e-05
  },
  {
    "step": 4290,
    "epoch": 2.4088739118225218,
    "loss": 0.7198,
    "grad_norm": 0.6134259700775146,
    "learning_rate": 1.2372363363893176e-05
  },
  {
    "step": 4300,
    "epoch": 2.414490311710194,
    "loss": 0.7157,
    "grad_norm": 0.8120875358581543,
    "learning_rate": 1.2334263047257224e-05
  },
  {
    "step": 4300,
    "epoch": 2.414490311710194,
    "eval_loss": 0.6998401284217834,
    "eval_f1": 0.7533265097236438,
    "eval_precision": 0.7722980062959076,
    "eval_recall": 0.7352647352647352,
    "eval_runtime": 32.2872,
    "eval_samples_per_second": 49.029,
    "eval_steps_per_second": 6.132
  },
  {
    "step": 4310,
    "epoch": 2.4201067115978656,
    "loss": 0.734,
    "grad_norm": 1.6858948469161987,
    "learning_rate": 1.2296126859057629e-05
  },
  {
    "step": 4320,
    "epoch": 2.4257231114855378,
    "loss": 0.745,
    "grad_norm": 1.1014553308486938,
    "learning_rate": 1.225795538534861e-05
  },
  {
    "step": 4330,
    "epoch": 2.43133951137321,
    "loss": 0.7313,
    "grad_norm": 0.6502967476844788,
    "learning_rate": 1.2219749212726631e-05
  },
  {
    "step": 4340,
    "epoch": 2.4369559112608816,
    "loss": 0.7643,
    "grad_norm": 0.6149151921272278,
    "learning_rate": 1.2181508928321387e-05
  },
  {
    "step": 4350,
    "epoch": 2.4425723111485538,
    "loss": 0.7535,
    "grad_norm": 1.1157784461975098,
    "learning_rate": 1.2143235119786781e-05
  },
  {
    "step": 4360,
    "epoch": 2.448188711036226,
    "loss": 0.7522,
    "grad_norm": 2.195880174636841,
    "learning_rate": 1.21049283752919e-05
  },
  {
    "step": 4370,
    "epoch": 2.4538051109238976,
    "loss": 0.7376,
    "grad_norm": 1.220749020576477,
    "learning_rate": 1.2066589283511967e-05
  },
  {
    "step": 4380,
    "epoch": 2.45942151081157,
    "loss": 0.7169,
    "grad_norm": 1.006624460220337,
    "learning_rate": 1.20282184336193e-05
  },
  {
    "step": 4390,
    "epoch": 2.465037910699242,
    "loss": 0.7225,
    "grad_norm": 0.7927025556564331,
    "learning_rate": 1.1989816415274257e-05
  },
  {
    "step": 4400,
    "epoch": 2.4706543105869136,
    "loss": 0.7288,
    "grad_norm": 0.6400802135467529,
    "learning_rate": 1.195138381861618e-05
  },
  {
    "step": 4400,
    "epoch": 2.4706543105869136,
    "eval_loss": 0.6989283561706543,
    "eval_f1": 0.7538962151053263,
    "eval_precision": 0.7760930888575458,
    "eval_recall": 0.732933732933733,
    "eval_runtime": 32.2394,
    "eval_samples_per_second": 49.101,
    "eval_steps_per_second": 6.142
  },
  {
    "step": 4410,
    "epoch": 2.476270710474586,
    "loss": 0.7444,
    "grad_norm": 1.2007324695587158,
    "learning_rate": 1.1912921234254305e-05
  },
  {
    "step": 4420,
    "epoch": 2.481887110362258,
    "loss": 0.7326,
    "grad_norm": 1.5388977527618408,
    "learning_rate": 1.1874429253258713e-05
  },
  {
    "step": 4430,
    "epoch": 2.4875035102499297,
    "loss": 0.7322,
    "grad_norm": 0.9716836214065552,
    "learning_rate": 1.1835908467151239e-05
  },
  {
    "step": 4440,
    "epoch": 2.493119910137602,
    "loss": 0.735,
    "grad_norm": 1.6188857555389404,
    "learning_rate": 1.1797359467896361e-05
  },
  {
    "step": 4450,
    "epoch": 2.498736310025274,
    "loss": 0.731,
    "grad_norm": 1.0167156457901,
    "learning_rate": 1.1758782847892141e-05
  },
  {
    "step": 4460,
    "epoch": 2.5043527099129457,
    "loss": 0.7259,
    "grad_norm": 0.7171435356140137,
    "learning_rate": 1.172017919996108e-05
  },
  {
    "step": 4470,
    "epoch": 2.509969109800618,
    "loss": 0.7228,
    "grad_norm": 1.0961412191390991,
    "learning_rate": 1.1681549117341042e-05
  },
  {
    "step": 4480,
    "epoch": 2.5155855096882895,
    "loss": 0.7639,
    "grad_norm": 0.5576472282409668,
    "learning_rate": 1.1642893193676119e-05
  },
  {
    "step": 4490,
    "epoch": 2.5212019095759617,
    "loss": 0.727,
    "grad_norm": 1.2419730424880981,
    "learning_rate": 1.1604212023007513e-05
  },
  {
    "step": 4500,
    "epoch": 2.526818309463634,
    "loss": 0.7483,
    "grad_norm": 0.9567295908927917,
    "learning_rate": 1.1565506199764407e-05
  },
  {
    "step": 4500,
    "epoch": 2.526818309463634,
    "eval_loss": 0.6980100870132446,
    "eval_f1": 0.7552931252636018,
    "eval_precision": 0.7654299880321422,
    "eval_recall": 0.7454212454212454,
    "eval_runtime": 32.3269,
    "eval_samples_per_second": 48.969,
    "eval_steps_per_second": 6.125
  },
  {
    "step": 4510,
    "epoch": 2.532434709351306,
    "loss": 0.7496,
    "grad_norm": 0.8293583393096924,
    "learning_rate": 1.1526776318754824e-05
  },
  {
    "step": 4520,
    "epoch": 2.5380511092389777,
    "loss": 0.749,
    "grad_norm": 0.9475401043891907,
    "learning_rate": 1.1488022975156507e-05
  },
  {
    "step": 4530,
    "epoch": 2.54366750912665,
    "loss": 0.726,
    "grad_norm": 0.6568100452423096,
    "learning_rate": 1.1449246764507741e-05
  },
  {
    "step": 4540,
    "epoch": 2.5492839090143216,
    "loss": 0.7642,
    "grad_norm": 0.806584894657135,
    "learning_rate": 1.1410448282698237e-05
  },
  {
    "step": 4550,
    "epoch": 2.5549003089019937,
    "loss": 0.7461,
    "grad_norm": 0.9151315093040466,
    "learning_rate": 1.1371628125959936e-05
  },
  {
    "step": 4560,
    "epoch": 2.560516708789666,
    "loss": 0.7606,
    "grad_norm": 1.0549992322921753,
    "learning_rate": 1.1332786890857879e-05
  },
  {
    "step": 4570,
    "epoch": 2.566133108677338,
    "loss": 0.7568,
    "grad_norm": 1.1117442846298218,
    "learning_rate": 1.1293925174281024e-05
  },
  {
    "step": 4580,
    "epoch": 2.5717495085650097,
    "loss": 0.7518,
    "grad_norm": 0.5968146324157715,
    "learning_rate": 1.1255043573433073e-05
  },
  {
    "step": 4590,
    "epoch": 2.577365908452682,
    "loss": 0.7063,
    "grad_norm": 0.9245684742927551,
    "learning_rate": 1.1216142685823303e-05
  },
  {
    "step": 4600,
    "epoch": 2.5829823083403536,
    "loss": 0.7356,
    "grad_norm": 1.045145869255066,
    "learning_rate": 1.1177223109257374e-05
  },
  {
    "step": 4600,
    "epoch": 2.5829823083403536,
    "eval_loss": 0.6967557668685913,
    "eval_f1": 0.7567064398747568,
    "eval_precision": 0.7694028566511788,
    "eval_recall": 0.7444222444222445,
    "eval_runtime": 32.1955,
    "eval_samples_per_second": 49.168,
    "eval_steps_per_second": 6.15
  },
  {
    "step": 4610,
    "epoch": 2.5885987082280257,
    "loss": 0.7218,
    "grad_norm": 0.7817035913467407,
    "learning_rate": 1.1138285441828152e-05
  },
  {
    "step": 4620,
    "epoch": 2.594215108115698,
    "loss": 0.7384,
    "grad_norm": 0.8661457896232605,
    "learning_rate": 1.1099330281906505e-05
  },
  {
    "step": 4630,
    "epoch": 2.59983150800337,
    "loss": 0.7311,
    "grad_norm": 2.7079529762268066,
    "learning_rate": 1.1060358228132119e-05
  },
  {
    "step": 4640,
    "epoch": 2.6054479078910417,
    "loss": 0.731,
    "grad_norm": 0.5698139071464539,
    "learning_rate": 1.10213698794043e-05
  },
  {
    "step": 4650,
    "epoch": 2.611064307778714,
    "loss": 0.7094,
    "grad_norm": 0.6819891929626465,
    "learning_rate": 1.0982365834872757e-05
  },
  {
    "step": 4660,
    "epoch": 2.6166807076663856,
    "loss": 0.7283,
    "grad_norm": 0.7293210029602051,
    "learning_rate": 1.0943346693928403e-05
  },
  {
    "step": 4670,
    "epoch": 2.6222971075540578,
    "loss": 0.7613,
    "grad_norm": 1.7349427938461304,
    "learning_rate": 1.0904313056194148e-05
  },
  {
    "step": 4680,
    "epoch": 2.62791350744173,
    "loss": 0.7132,
    "grad_norm": 0.5200216174125671,
    "learning_rate": 1.0865265521515684e-05
  },
  {
    "step": 4690,
    "epoch": 2.633529907329402,
    "loss": 0.7036,
    "grad_norm": 0.936902642250061,
    "learning_rate": 1.0826204689952252e-05
  },
  {
    "step": 4700,
    "epoch": 2.6391463072170738,
    "loss": 0.7253,
    "grad_norm": 0.8740265369415283,
    "learning_rate": 1.0787131161767435e-05
  },
  {
    "step": 4700,
    "epoch": 2.6391463072170738,
    "eval_loss": 0.6959475874900818,
    "eval_f1": 0.7574165112730973,
    "eval_precision": 0.7714088397790055,
    "eval_recall": 0.7439227439227439,
    "eval_runtime": 38.3204,
    "eval_samples_per_second": 41.31,
    "eval_steps_per_second": 5.167
  },
  {
    "step": 4710,
    "epoch": 2.644762707104746,
    "loss": 0.7808,
    "grad_norm": 1.0116617679595947,
    "learning_rate": 1.074804553741994e-05
  },
  {
    "step": 4720,
    "epoch": 2.6503791069924176,
    "loss": 0.7422,
    "grad_norm": 1.3719656467437744,
    "learning_rate": 1.0708948417554344e-05
  },
  {
    "step": 4730,
    "epoch": 2.65599550688009,
    "loss": 0.7105,
    "grad_norm": 0.5470518469810486,
    "learning_rate": 1.0669840402991893e-05
  },
  {
    "step": 4740,
    "epoch": 2.661611906767762,
    "loss": 0.7229,
    "grad_norm": 1.130924940109253,
    "learning_rate": 1.0630722094721258e-05
  },
  {
    "step": 4750,
    "epoch": 2.667228306655434,
    "loss": 0.7528,
    "grad_norm": 1.314003825187683,
    "learning_rate": 1.0591594093889283e-05
  },
  {
    "step": 4760,
    "epoch": 2.672844706543106,
    "loss": 0.7022,
    "grad_norm": 1.104732871055603,
    "learning_rate": 1.0552457001791776e-05
  },
  {
    "step": 4770,
    "epoch": 2.678461106430778,
    "loss": 0.7209,
    "grad_norm": 1.4209173917770386,
    "learning_rate": 1.0513311419864242e-05
  },
  {
    "step": 4780,
    "epoch": 2.6840775063184497,
    "loss": 0.725,
    "grad_norm": 1.2111247777938843,
    "learning_rate": 1.0474157949672669e-05
  },
  {
    "step": 4790,
    "epoch": 2.689693906206122,
    "loss": 0.725,
    "grad_norm": 1.04447603225708,
    "learning_rate": 1.043499719290425e-05
  },
  {
    "step": 4800,
    "epoch": 2.695310306093794,
    "loss": 0.7057,
    "grad_norm": 0.4427354335784912,
    "learning_rate": 1.0395829751358162e-05
  },
  {
    "step": 4800,
    "epoch": 2.695310306093794,
    "eval_loss": 0.6957577466964722,
    "eval_f1": 0.7574756459127489,
    "eval_precision": 0.7709949991377824,
    "eval_recall": 0.7444222444222445,
    "eval_runtime": 37.9469,
    "eval_samples_per_second": 41.716,
    "eval_steps_per_second": 5.218
  },
  {
    "step": 4810,
    "epoch": 2.700926705981466,
    "loss": 0.7559,
    "grad_norm": 1.3394131660461426,
    "learning_rate": 1.035665622693631e-05
  },
  {
    "step": 4820,
    "epoch": 2.706543105869138,
    "loss": 0.7318,
    "grad_norm": 0.5408957004547119,
    "learning_rate": 1.031747722163408e-05
  },
  {
    "step": 4830,
    "epoch": 2.71215950575681,
    "loss": 0.7274,
    "grad_norm": 1.2997989654541016,
    "learning_rate": 1.0278293337531071e-05
  },
  {
    "step": 4840,
    "epoch": 2.7177759056444817,
    "loss": 0.7442,
    "grad_norm": 0.8512164354324341,
    "learning_rate": 1.0239105176781873e-05
  },
  {
    "step": 4850,
    "epoch": 2.723392305532154,
    "loss": 0.7623,
    "grad_norm": 2.068730592727661,
    "learning_rate": 1.0199913341606793e-05
  },
  {
    "step": 4860,
    "epoch": 2.729008705419826,
    "loss": 0.7226,
    "grad_norm": 0.8630260229110718,
    "learning_rate": 1.0160718434282594e-05
  },
  {
    "step": 4870,
    "epoch": 2.734625105307498,
    "loss": 0.7264,
    "grad_norm": 0.9236663579940796,
    "learning_rate": 1.012152105713326e-05
  },
  {
    "step": 4880,
    "epoch": 2.74024150519517,
    "loss": 0.7518,
    "grad_norm": 0.9681663513183594,
    "learning_rate": 1.008232181252073e-05
  },
  {
    "step": 4890,
    "epoch": 2.745857905082842,
    "loss": 0.7076,
    "grad_norm": 0.6852583289146423,
    "learning_rate": 1.0043121302835639e-05
  },
  {
    "step": 4900,
    "epoch": 2.7514743049705137,
    "loss": 0.7623,
    "grad_norm": 0.5811483860015869,
    "learning_rate": 1.0003920130488054e-05
  },
  {
    "step": 4900,
    "epoch": 2.7514743049705137,
    "eval_loss": 0.6936892867088318,
    "eval_f1": 0.7622832980972516,
    "eval_precision": 0.7745317064787764,
    "eval_recall": 0.7504162504162504,
    "eval_runtime": 37.838,
    "eval_samples_per_second": 41.836,
    "eval_steps_per_second": 5.233
  },
  {
    "step": 4910,
    "epoch": 2.757090704858186,
    "loss": 0.7397,
    "grad_norm": 1.5632251501083374,
    "learning_rate": 9.964718897898242e-06
  },
  {
    "step": 4920,
    "epoch": 2.762707104745858,
    "loss": 0.7227,
    "grad_norm": 0.6943310499191284,
    "learning_rate": 9.925518207487388e-06
  },
  {
    "step": 4930,
    "epoch": 2.76832350463353,
    "loss": 0.7061,
    "grad_norm": 0.9798736572265625,
    "learning_rate": 9.886318661668335e-06
  },
  {
    "step": 4940,
    "epoch": 2.773939904521202,
    "loss": 0.747,
    "grad_norm": 1.166308045387268,
    "learning_rate": 9.847120862836357e-06
  },
  {
    "step": 4950,
    "epoch": 2.779556304408874,
    "loss": 0.7288,
    "grad_norm": 1.0700589418411255,
    "learning_rate": 9.807925413359867e-06
  },
  {
    "step": 4960,
    "epoch": 2.7851727042965457,
    "loss": 0.7369,
    "grad_norm": 0.7880681753158569,
    "learning_rate": 9.768732915571175e-06
  },
  {
    "step": 4970,
    "epoch": 2.790789104184218,
    "loss": 0.7202,
    "grad_norm": 1.7736648321151733,
    "learning_rate": 9.729543971757237e-06
  },
  {
    "step": 4980,
    "epoch": 2.79640550407189,
    "loss": 0.7566,
    "grad_norm": 1.1050622463226318,
    "learning_rate": 9.690359184150391e-06
  },
  {
    "step": 4990,
    "epoch": 2.802021903959562,
    "loss": 0.7022,
    "grad_norm": 0.48188894987106323,
    "learning_rate": 9.6511791549191e-06
  },
  {
    "step": 5000,
    "epoch": 2.807638303847234,
    "loss": 0.7316,
    "grad_norm": 2.0427935123443604,
    "learning_rate": 9.612004486158714e-06
  },
  {
    "step": 5000,
    "epoch": 2.807638303847234,
    "eval_loss": 0.693256139755249,
    "eval_f1": 0.7636332939388822,
    "eval_precision": 0.774486301369863,
    "eval_recall": 0.7530802530802531,
    "eval_runtime": 38.0081,
    "eval_samples_per_second": 41.649,
    "eval_steps_per_second": 5.209
  },
  {
    "step": 5010,
    "epoch": 2.813254703734906,
    "loss": 0.7225,
    "grad_norm": 0.6590465903282166,
    "learning_rate": 9.5728357798822e-06
  },
  {
    "step": 5020,
    "epoch": 2.8188711036225778,
    "loss": 0.7515,
    "grad_norm": 1.67522132396698,
    "learning_rate": 9.533673638010889e-06
  },
  {
    "step": 5030,
    "epoch": 2.82448750351025,
    "loss": 0.7303,
    "grad_norm": 2.317006826400757,
    "learning_rate": 9.494518662365255e-06
  },
  {
    "step": 5040,
    "epoch": 2.830103903397922,
    "loss": 0.7383,
    "grad_norm": 1.3295636177062988,
    "learning_rate": 9.455371454655626e-06
  },
  {
    "step": 5050,
    "epoch": 2.8357203032855938,
    "loss": 0.7623,
    "grad_norm": 0.9026241302490234,
    "learning_rate": 9.416232616472961e-06
  },
  {
    "step": 5060,
    "epoch": 2.841336703173266,
    "loss": 0.7394,
    "grad_norm": 0.692206859588623,
    "learning_rate": 9.377102749279612e-06
  },
  {
    "step": 5070,
    "epoch": 2.846953103060938,
    "loss": 0.7318,
    "grad_norm": 0.5340024828910828,
    "learning_rate": 9.337982454400059e-06
  },
  {
    "step": 5080,
    "epoch": 2.85256950294861,
    "loss": 0.734,
    "grad_norm": 0.4247359037399292,
    "learning_rate": 9.298872333011684e-06
  },
  {
    "step": 5090,
    "epoch": 2.858185902836282,
    "loss": 0.7307,
    "grad_norm": 1.1456114053726196,
    "learning_rate": 9.259772986135531e-06
  },
  {
    "step": 5100,
    "epoch": 2.863802302723954,
    "loss": 0.7578,
    "grad_norm": 0.6973670721054077,
    "learning_rate": 9.220685014627058e-06
  },
  {
    "step": 5100,
    "epoch": 2.863802302723954,
    "eval_loss": 0.6925175189971924,
    "eval_f1": 0.7655671491080445,
    "eval_precision": 0.773902687989112,
    "eval_recall": 0.7574092574092575,
    "eval_runtime": 37.7647,
    "eval_samples_per_second": 41.918,
    "eval_steps_per_second": 5.243
  },
  {
    "step": 5110,
    "epoch": 2.869418702611626,
    "loss": 0.7216,
    "grad_norm": 0.7586914300918579,
    "learning_rate": 9.18160901916693e-06
  },
  {
    "step": 5120,
    "epoch": 2.875035102499298,
    "loss": 0.6997,
    "grad_norm": 1.7455099821090698,
    "learning_rate": 9.14254560025176e-06
  },
  {
    "step": 5130,
    "epoch": 2.88065150238697,
    "loss": 0.7286,
    "grad_norm": 0.8433896899223328,
    "learning_rate": 9.103495358184887e-06
  },
  {
    "step": 5140,
    "epoch": 2.886267902274642,
    "loss": 0.7303,
    "grad_norm": 0.9173933267593384,
    "learning_rate": 9.064458893067171e-06
  },
  {
    "step": 5150,
    "epoch": 2.891884302162314,
    "loss": 0.7126,
    "grad_norm": 0.9835129380226135,
    "learning_rate": 9.025436804787743e-06
  },
  {
    "step": 5160,
    "epoch": 2.897500702049986,
    "loss": 0.6993,
    "grad_norm": 1.1933962106704712,
    "learning_rate": 8.986429693014807e-06
  },
  {
    "step": 5170,
    "epoch": 2.903117101937658,
    "loss": 0.6913,
    "grad_norm": 1.3876514434814453,
    "learning_rate": 8.947438157186415e-06
  },
  {
    "step": 5180,
    "epoch": 2.90873350182533,
    "loss": 0.7297,
    "grad_norm": 0.8406627774238586,
    "learning_rate": 8.908462796501256e-06
  },
  {
    "step": 5190,
    "epoch": 2.914349901713002,
    "loss": 0.7343,
    "grad_norm": 1.2082537412643433,
    "learning_rate": 8.869504209909443e-06
  },
  {
    "step": 5200,
    "epoch": 2.919966301600674,
    "loss": 0.7482,
    "grad_norm": 1.1838937997817993,
    "learning_rate": 8.830562996103332e-06
  },
  {
    "step": 5200,
    "epoch": 2.919966301600674,
    "eval_loss": 0.6925817131996155,
    "eval_f1": 0.7667877354506293,
    "eval_precision": 0.7781587519286817,
    "eval_recall": 0.7557442557442557,
    "eval_runtime": 37.9692,
    "eval_samples_per_second": 41.692,
    "eval_steps_per_second": 5.215
  },
  {
    "step": 5210,
    "epoch": 2.925582701488346,
    "loss": 0.7501,
    "grad_norm": 0.7580008506774902,
    "learning_rate": 8.791639753508288e-06
  },
  {
    "step": 5220,
    "epoch": 2.931199101376018,
    "loss": 0.7589,
    "grad_norm": 0.5440326929092407,
    "learning_rate": 8.75273508027351e-06
  },
  {
    "step": 5230,
    "epoch": 2.93681550126369,
    "loss": 0.7316,
    "grad_norm": 0.7520999908447266,
    "learning_rate": 8.713849574262838e-06
  },
  {
    "step": 5240,
    "epoch": 2.942431901151362,
    "loss": 0.7148,
    "grad_norm": 1.101839303970337,
    "learning_rate": 8.674983833045553e-06
  },
  {
    "step": 5250,
    "epoch": 2.9480483010390337,
    "loss": 0.7322,
    "grad_norm": 1.0510717630386353,
    "learning_rate": 8.636138453887217e-06
  },
  {
    "step": 5260,
    "epoch": 2.953664700926706,
    "loss": 0.7274,
    "grad_norm": 0.8294170498847961,
    "learning_rate": 8.597314033740465e-06
  },
  {
    "step": 5270,
    "epoch": 2.959281100814378,
    "loss": 0.7435,
    "grad_norm": 0.5459033250808716,
    "learning_rate": 8.558511169235851e-06
  },
  {
    "step": 5280,
    "epoch": 2.96489750070205,
    "loss": 0.7117,
    "grad_norm": 1.6218780279159546,
    "learning_rate": 8.519730456672682e-06
  },
  {
    "step": 5290,
    "epoch": 2.970513900589722,
    "loss": 0.6866,
    "grad_norm": 1.8664395809173584,
    "learning_rate": 8.480972492009835e-06
  },
  {
    "step": 5300,
    "epoch": 2.976130300477394,
    "loss": 0.738,
    "grad_norm": 1.0664958953857422,
    "learning_rate": 8.442237870856616e-06
  },
  {
    "step": 5300,
    "epoch": 2.976130300477394,
    "eval_loss": 0.6913137435913086,
    "eval_f1": 0.7670747150696496,
    "eval_precision": 0.7780441856482274,
    "eval_recall": 0.7564102564102564,
    "eval_runtime": 32.665,
    "eval_samples_per_second": 48.462,
    "eval_steps_per_second": 6.062
  },
  {
    "step": 5310,
    "epoch": 2.9817467003650657,
    "loss": 0.7336,
    "grad_norm": 0.8165051937103271,
    "learning_rate": 8.403527188463612e-06
  },
  {
    "step": 5320,
    "epoch": 2.987363100252738,
    "loss": 0.7189,
    "grad_norm": 0.8647149205207825,
    "learning_rate": 8.364841039713516e-06
  },
  {
    "step": 5330,
    "epoch": 2.99297950014041,
    "loss": 0.7497,
    "grad_norm": 0.8233374357223511,
    "learning_rate": 8.326180019112011e-06
  },
  {
    "step": 5340,
    "epoch": 2.998595900028082,
    "loss": 0.7308,
    "grad_norm": 1.8334383964538574,
    "learning_rate": 8.287544720778631e-06
  },
  {
    "step": 5350,
    "epoch": 3.0039314799213703,
    "loss": 0.709,
    "grad_norm": 0.7830228209495544,
    "learning_rate": 8.248935738437618e-06
  },
  {
    "step": 5360,
    "epoch": 3.0095478798090425,
    "loss": 0.7275,
    "grad_norm": 0.9334861636161804,
    "learning_rate": 8.210353665408804e-06
  },
  {
    "step": 5370,
    "epoch": 3.015164279696714,
    "loss": 0.7751,
    "grad_norm": 0.7689281105995178,
    "learning_rate": 8.1717990945985e-06
  },
  {
    "step": 5380,
    "epoch": 3.0207806795843863,
    "loss": 0.7132,
    "grad_norm": 0.728043794631958,
    "learning_rate": 8.133272618490379e-06
  },
  {
    "step": 5390,
    "epoch": 3.0263970794720585,
    "loss": 0.7299,
    "grad_norm": 0.8838669657707214,
    "learning_rate": 8.09477482913637e-06
  },
  {
    "step": 5400,
    "epoch": 3.03201347935973,
    "loss": 0.7156,
    "grad_norm": 1.545535683631897,
    "learning_rate": 8.056306318147561e-06
  },
  {
    "step": 5400,
    "epoch": 3.03201347935973,
    "eval_loss": 0.6903809309005737,
    "eval_f1": 0.7683625336927223,
    "eval_precision": 0.7775315376747358,
    "eval_recall": 0.7594072594072594,
    "eval_runtime": 35.5398,
    "eval_samples_per_second": 44.542,
    "eval_steps_per_second": 5.571
  },
  {
    "step": 5410,
    "epoch": 3.0376298792474024,
    "loss": 0.7579,
    "grad_norm": 1.6172500848770142,
    "learning_rate": 8.017867676685102e-06
  },
  {
    "step": 5420,
    "epoch": 3.0432462791350745,
    "loss": 0.7033,
    "grad_norm": 0.7183704376220703,
    "learning_rate": 7.979459495451138e-06
  },
  {
    "step": 5430,
    "epoch": 3.048862679022746,
    "loss": 0.7893,
    "grad_norm": 1.01624596118927,
    "learning_rate": 7.941082364679714e-06
  },
  {
    "step": 5440,
    "epoch": 3.0544790789104184,
    "loss": 0.7373,
    "grad_norm": 0.8156070113182068,
    "learning_rate": 7.902736874127698e-06
  },
  {
    "step": 5450,
    "epoch": 3.0600954787980905,
    "loss": 0.7178,
    "grad_norm": 1.430474877357483,
    "learning_rate": 7.864423613065752e-06
  },
  {
    "step": 5460,
    "epoch": 3.0657118786857622,
    "loss": 0.7091,
    "grad_norm": 0.7925914525985718,
    "learning_rate": 7.826143170269239e-06
  },
  {
    "step": 5470,
    "epoch": 3.0713282785734344,
    "loss": 0.7553,
    "grad_norm": 0.7659889459609985,
    "learning_rate": 7.787896134009192e-06
  },
  {
    "step": 5480,
    "epoch": 3.0769446784611065,
    "loss": 0.7557,
    "grad_norm": 1.1907093524932861,
    "learning_rate": 7.74968309204328e-06
  },
  {
    "step": 5490,
    "epoch": 3.0825610783487782,
    "loss": 0.7169,
    "grad_norm": 0.5933243632316589,
    "learning_rate": 7.711504631606761e-06
  },
  {
    "step": 5500,
    "epoch": 3.0881774782364504,
    "loss": 0.7192,
    "grad_norm": 3.4126176834106445,
    "learning_rate": 7.67336133940346e-06
  },
  {
    "step": 5500,
    "epoch": 3.0881774782364504,
    "eval_loss": 0.689893901348114,
    "eval_f1": 0.7673989602549052,
    "eval_precision": 0.772972972972973,
    "eval_recall": 0.7619047619047619,
    "eval_runtime": 39.7066,
    "eval_samples_per_second": 39.867,
    "eval_steps_per_second": 4.987
  },
  {
    "step": 5510,
    "epoch": 3.0937938781241225,
    "loss": 0.7173,
    "grad_norm": 0.9464202523231506,
    "learning_rate": 7.635253801596773e-06
  },
  {
    "step": 5520,
    "epoch": 3.0994102780117943,
    "loss": 0.7051,
    "grad_norm": 0.7363544702529907,
    "learning_rate": 7.597182603800627e-06
  },
  {
    "step": 5530,
    "epoch": 3.1050266778994664,
    "loss": 0.7019,
    "grad_norm": 1.2532927989959717,
    "learning_rate": 7.559148331070514e-06
  },
  {
    "step": 5540,
    "epoch": 3.1106430777871386,
    "loss": 0.6968,
    "grad_norm": 0.6403274536132812,
    "learning_rate": 7.521151567894468e-06
  },
  {
    "step": 5550,
    "epoch": 3.1162594776748103,
    "loss": 0.7505,
    "grad_norm": 0.7125644683837891,
    "learning_rate": 7.483192898184102e-06
  },
  {
    "step": 5560,
    "epoch": 3.1218758775624824,
    "loss": 0.6747,
    "grad_norm": 0.9234960079193115,
    "learning_rate": 7.445272905265645e-06
  },
  {
    "step": 5570,
    "epoch": 3.1274922774501546,
    "loss": 0.743,
    "grad_norm": 0.7754389047622681,
    "learning_rate": 7.4073921718709465e-06
  },
  {
    "step": 5580,
    "epoch": 3.1331086773378263,
    "loss": 0.7194,
    "grad_norm": 1.0549416542053223,
    "learning_rate": 7.3695512801285466e-06
  },
  {
    "step": 5590,
    "epoch": 3.1387250772254984,
    "loss": 0.7001,
    "grad_norm": 1.1902045011520386,
    "learning_rate": 7.331750811554723e-06
  },
  {
    "step": 5600,
    "epoch": 3.1443414771131706,
    "loss": 0.7553,
    "grad_norm": 0.8933541178703308,
    "learning_rate": 7.293991347044555e-06
  },
  {
    "step": 5600,
    "epoch": 3.1443414771131706,
    "eval_loss": 0.6896631121635437,
    "eval_f1": 0.767176213673778,
    "eval_precision": 0.7740677966101694,
    "eval_recall": 0.7604062604062604,
    "eval_runtime": 36.4199,
    "eval_samples_per_second": 43.465,
    "eval_steps_per_second": 5.437
  },
  {
    "step": 5610,
    "epoch": 3.1499578770008423,
    "loss": 0.7158,
    "grad_norm": 1.0539000034332275,
    "learning_rate": 7.256273466862986e-06
  },
  {
    "step": 5620,
    "epoch": 3.1555742768885144,
    "loss": 0.7392,
    "grad_norm": 1.6153348684310913,
    "learning_rate": 7.2185977506359366e-06
  },
  {
    "step": 5630,
    "epoch": 3.1611906767761866,
    "loss": 0.7283,
    "grad_norm": 0.7659069895744324,
    "learning_rate": 7.180964777341359e-06
  },
  {
    "step": 5640,
    "epoch": 3.1668070766638583,
    "loss": 0.7514,
    "grad_norm": 1.0997835397720337,
    "learning_rate": 7.143375125300359e-06
  },
  {
    "step": 5650,
    "epoch": 3.1724234765515305,
    "loss": 0.7281,
    "grad_norm": 0.5804504156112671,
    "learning_rate": 7.10582937216832e-06
  },
  {
    "step": 5660,
    "epoch": 3.1780398764392026,
    "loss": 0.7337,
    "grad_norm": 0.8137353658676147,
    "learning_rate": 7.0683280949259995e-06
  },
  {
    "step": 5670,
    "epoch": 3.1836562763268743,
    "loss": 0.7307,
    "grad_norm": 0.9020971059799194,
    "learning_rate": 7.030871869870679e-06
  },
  {
    "step": 5680,
    "epoch": 3.1892726762145465,
    "loss": 0.7295,
    "grad_norm": 0.5453659892082214,
    "learning_rate": 6.993461272607312e-06
  },
  {
    "step": 5690,
    "epoch": 3.1948890761022186,
    "loss": 0.6974,
    "grad_norm": 0.45815804600715637,
    "learning_rate": 6.956096878039662e-06
  },
  {
    "step": 5700,
    "epoch": 3.2005054759898903,
    "loss": 0.7249,
    "grad_norm": 0.5778201222419739,
    "learning_rate": 6.918779260361484e-06
  },
  {
    "step": 5700,
    "epoch": 3.2005054759898903,
    "eval_loss": 0.689330518245697,
    "eval_f1": 0.7683900798654898,
    "eval_precision": 0.7760230939038886,
    "eval_recall": 0.7609057609057609,
    "eval_runtime": 34.3228,
    "eval_samples_per_second": 46.121,
    "eval_steps_per_second": 5.769
  },
  {
    "step": 5710,
    "epoch": 3.2061218758775625,
    "loss": 0.7251,
    "grad_norm": 1.5874814987182617,
    "learning_rate": 6.881508993047692e-06
  },
  {
    "step": 5720,
    "epoch": 3.2117382757652346,
    "loss": 0.7148,
    "grad_norm": 1.0430539846420288,
    "learning_rate": 6.844286648845539e-06
  },
  {
    "step": 5730,
    "epoch": 3.2173546756529063,
    "loss": 0.6981,
    "grad_norm": 0.84294593334198,
    "learning_rate": 6.807112799765841e-06
  },
  {
    "step": 5740,
    "epoch": 3.2229710755405785,
    "loss": 0.7104,
    "grad_norm": 1.7310872077941895,
    "learning_rate": 6.769988017074158e-06
  },
  {
    "step": 5750,
    "epoch": 3.2285874754282506,
    "loss": 0.694,
    "grad_norm": 0.9265689253807068,
    "learning_rate": 6.732912871282022e-06
  },
  {
    "step": 5760,
    "epoch": 3.2342038753159223,
    "loss": 0.7187,
    "grad_norm": 0.49157944321632385,
    "learning_rate": 6.6958879321381955e-06
  },
  {
    "step": 5770,
    "epoch": 3.2398202752035945,
    "loss": 0.7427,
    "grad_norm": 1.2402944564819336,
    "learning_rate": 6.658913768619875e-06
  },
  {
    "step": 5780,
    "epoch": 3.2454366750912667,
    "loss": 0.7621,
    "grad_norm": 2.0817508697509766,
    "learning_rate": 6.621990948923971e-06
  },
  {
    "step": 5790,
    "epoch": 3.2510530749789384,
    "loss": 0.6985,
    "grad_norm": 0.6988674998283386,
    "learning_rate": 6.585120040458383e-06
  },
  {
    "step": 5800,
    "epoch": 3.2566694748666105,
    "loss": 0.7358,
    "grad_norm": 0.5916435122489929,
    "learning_rate": 6.548301609833258e-06
  },
  {
    "step": 5800,
    "epoch": 3.2566694748666105,
    "eval_loss": 0.6885572075843811,
    "eval_f1": 0.7717737875482462,
    "eval_precision": 0.7779093369418133,
    "eval_recall": 0.7657342657342657,
    "eval_runtime": 33.3315,
    "eval_samples_per_second": 47.493,
    "eval_steps_per_second": 5.94
  },
  {
    "step": 5810,
    "epoch": 3.2622858747542827,
    "loss": 0.6871,
    "grad_norm": 0.793846607208252,
    "learning_rate": 6.5115362228522995e-06
  },
  {
    "step": 5820,
    "epoch": 3.2679022746419544,
    "loss": 0.7501,
    "grad_norm": 0.9321931600570679,
    "learning_rate": 6.474824444504073e-06
  },
  {
    "step": 5830,
    "epoch": 3.2735186745296265,
    "loss": 0.698,
    "grad_norm": 0.7863073945045471,
    "learning_rate": 6.438166838953306e-06
  },
  {
    "step": 5840,
    "epoch": 3.2791350744172987,
    "loss": 0.7419,
    "grad_norm": 0.9514192342758179,
    "learning_rate": 6.401563969532245e-06
  },
  {
    "step": 5850,
    "epoch": 3.2847514743049704,
    "loss": 0.7163,
    "grad_norm": 1.0790395736694336,
    "learning_rate": 6.365016398731976e-06
  },
  {
    "step": 5860,
    "epoch": 3.2903678741926425,
    "loss": 0.7358,
    "grad_norm": 0.797681987285614,
    "learning_rate": 6.328524688193787e-06
  },
  {
    "step": 5870,
    "epoch": 3.2959842740803147,
    "loss": 0.722,
    "grad_norm": 0.9348251819610596,
    "learning_rate": 6.292089398700545e-06
  },
  {
    "step": 5880,
    "epoch": 3.3016006739679864,
    "loss": 0.7155,
    "grad_norm": 1.0233458280563354,
    "learning_rate": 6.2557110901680686e-06
  },
  {
    "step": 5890,
    "epoch": 3.3072170738556586,
    "loss": 0.7168,
    "grad_norm": 0.8769562840461731,
    "learning_rate": 6.219390321636526e-06
  },
  {
    "step": 5900,
    "epoch": 3.3128334737433307,
    "loss": 0.7172,
    "grad_norm": 1.087785243988037,
    "learning_rate": 6.183127651261849e-06
  },
  {
    "step": 5900,
    "epoch": 3.3128334737433307,
    "eval_loss": 0.6882874965667725,
    "eval_f1": 0.7704547357842728,
    "eval_precision": 0.7750631844987363,
    "eval_recall": 0.765900765900766,
    "eval_runtime": 33.4795,
    "eval_samples_per_second": 47.283,
    "eval_steps_per_second": 5.914
  },
  {
    "step": 5910,
    "epoch": 3.3184498736310024,
    "loss": 0.7222,
    "grad_norm": 1.15236234664917,
    "learning_rate": 6.146923636307146e-06
  },
  {
    "step": 5920,
    "epoch": 3.3240662735186746,
    "loss": 0.7165,
    "grad_norm": 2.209542751312256,
    "learning_rate": 6.1107788331341435e-06
  },
  {
    "step": 5930,
    "epoch": 3.3296826734063467,
    "loss": 0.7395,
    "grad_norm": 0.9326104521751404,
    "learning_rate": 6.074693797194648e-06
  },
  {
    "step": 5940,
    "epoch": 3.3352990732940184,
    "loss": 0.7292,
    "grad_norm": 1.075804352760315,
    "learning_rate": 6.038669083021988e-06
  },
  {
    "step": 5950,
    "epoch": 3.3409154731816906,
    "loss": 0.7113,
    "grad_norm": 1.0574193000793457,
    "learning_rate": 6.002705244222499e-06
  },
  {
    "step": 5960,
    "epoch": 3.3465318730693627,
    "loss": 0.7338,
    "grad_norm": 1.0806312561035156,
    "learning_rate": 5.966802833467036e-06
  },
  {
    "step": 5970,
    "epoch": 3.3521482729570344,
    "loss": 0.694,
    "grad_norm": 0.9411386847496033,
    "learning_rate": 5.930962402482447e-06
  },
  {
    "step": 5980,
    "epoch": 3.3577646728447066,
    "loss": 0.7564,
    "grad_norm": 0.5833331942558289,
    "learning_rate": 5.895184502043129e-06
  },
  {
    "step": 5990,
    "epoch": 3.3633810727323787,
    "loss": 0.7235,
    "grad_norm": 0.7604563236236572,
    "learning_rate": 5.859469681962531e-06
  },
  {
    "step": 6000,
    "epoch": 3.3689974726200504,
    "loss": 0.6881,
    "grad_norm": 0.9681222438812256,
    "learning_rate": 5.823818491084724e-06
  },
  {
    "step": 6000,
    "epoch": 3.3689974726200504,
    "eval_loss": 0.6875454783439636,
    "eval_f1": 0.7719738824711201,
    "eval_precision": 0.7762626262626262,
    "eval_recall": 0.7677322677322678,
    "eval_runtime": 33.7542,
    "eval_samples_per_second": 46.898,
    "eval_steps_per_second": 5.866
  },
  {
    "step": 6010,
    "epoch": 3.3746138725077226,
    "loss": 0.699,
    "grad_norm": 1.1813035011291504,
    "learning_rate": 5.7882314772759765e-06
  },
  {
    "step": 6020,
    "epoch": 3.3802302723953943,
    "loss": 0.7216,
    "grad_norm": 1.7572612762451172,
    "learning_rate": 5.752709187416305e-06
  },
  {
    "step": 6030,
    "epoch": 3.3858466722830665,
    "loss": 0.7506,
    "grad_norm": 1.567819595336914,
    "learning_rate": 5.717252167391094e-06
  },
  {
    "step": 6040,
    "epoch": 3.3914630721707386,
    "loss": 0.736,
    "grad_norm": 0.9159625172615051,
    "learning_rate": 5.681860962082707e-06
  },
  {
    "step": 6050,
    "epoch": 3.3970794720584108,
    "loss": 0.7188,
    "grad_norm": 0.6663655042648315,
    "learning_rate": 5.646536115362095e-06
  },
  {
    "step": 6060,
    "epoch": 3.4026958719460825,
    "loss": 0.7143,
    "grad_norm": 0.6322194933891296,
    "learning_rate": 5.611278170080449e-06
  },
  {
    "step": 6070,
    "epoch": 3.4083122718337546,
    "loss": 0.7484,
    "grad_norm": 0.7175539135932922,
    "learning_rate": 5.5760876680608725e-06
  },
  {
    "step": 6080,
    "epoch": 3.4139286717214263,
    "loss": 0.7429,
    "grad_norm": 0.5191925764083862,
    "learning_rate": 5.5409651500900286e-06
  },
  {
    "step": 6090,
    "epoch": 3.4195450716090985,
    "loss": 0.7099,
    "grad_norm": 0.8453988432884216,
    "learning_rate": 5.505911155909842e-06
  },
  {
    "step": 6100,
    "epoch": 3.4251614714967706,
    "loss": 0.7316,
    "grad_norm": 1.2751762866973877,
    "learning_rate": 5.470926224209215e-06
  },
  {
    "step": 6100,
    "epoch": 3.4251614714967706,
    "eval_loss": 0.6873417496681213,
    "eval_f1": 0.772212433929021,
    "eval_precision": 0.778285134449518,
    "eval_recall": 0.7662337662337663,
    "eval_runtime": 38.6182,
    "eval_samples_per_second": 40.991,
    "eval_steps_per_second": 5.127
  },
  {
    "step": 6110,
    "epoch": 3.430777871384443,
    "loss": 0.7017,
    "grad_norm": 0.47120147943496704,
    "learning_rate": 5.4360108926157305e-06
  },
  {
    "step": 6120,
    "epoch": 3.4363942712721145,
    "loss": 0.7257,
    "grad_norm": 0.6702333092689514,
    "learning_rate": 5.401165697687394e-06
  },
  {
    "step": 6130,
    "epoch": 3.4420106711597867,
    "loss": 0.7092,
    "grad_norm": 0.8088284730911255,
    "learning_rate": 5.366391174904409e-06
  },
  {
    "step": 6140,
    "epoch": 3.4476270710474584,
    "loss": 0.7115,
    "grad_norm": 0.495339035987854,
    "learning_rate": 5.3316878586609135e-06
  },
  {
    "step": 6150,
    "epoch": 3.4532434709351305,
    "loss": 0.7018,
    "grad_norm": 1.1230696439743042,
    "learning_rate": 5.297056282256796e-06
  },
  {
    "step": 6160,
    "epoch": 3.4588598708228027,
    "loss": 0.6822,
    "grad_norm": 0.7495416402816772,
    "learning_rate": 5.262496977889488e-06
  },
  {
    "step": 6170,
    "epoch": 3.464476270710475,
    "loss": 0.7252,
    "grad_norm": 0.6745995283126831,
    "learning_rate": 5.228010476645784e-06
  },
  {
    "step": 6180,
    "epoch": 3.4700926705981465,
    "loss": 0.7344,
    "grad_norm": 0.9778150916099548,
    "learning_rate": 5.1935973084936894e-06
  },
  {
    "step": 6190,
    "epoch": 3.4757090704858187,
    "loss": 0.7049,
    "grad_norm": 1.4566781520843506,
    "learning_rate": 5.159258002274269e-06
  },
  {
    "step": 6200,
    "epoch": 3.4813254703734904,
    "loss": 0.7275,
    "grad_norm": 1.6752232313156128,
    "learning_rate": 5.124993085693513e-06
  },
  {
    "step": 6200,
    "epoch": 3.4813254703734904,
    "eval_loss": 0.6868650317192078,
    "eval_f1": 0.7725752508361206,
    "eval_precision": 0.7759489418878065,
    "eval_recall": 0.7692307692307693,
    "eval_runtime": 45.6251,
    "eval_samples_per_second": 34.696,
    "eval_steps_per_second": 4.34
  },
  {
    "step": 6210,
    "epoch": 3.4869418702611625,
    "loss": 0.7244,
    "grad_norm": 1.3000372648239136,
    "learning_rate": 5.090803085314249e-06
  },
  {
    "step": 6220,
    "epoch": 3.4925582701488347,
    "loss": 0.7025,
    "grad_norm": 1.1749852895736694,
    "learning_rate": 5.056688526548031e-06
  },
  {
    "step": 6230,
    "epoch": 3.498174670036507,
    "loss": 0.7223,
    "grad_norm": 0.8675979971885681,
    "learning_rate": 5.0226499336470635e-06
  },
  {
    "step": 6240,
    "epoch": 3.5037910699241785,
    "loss": 0.6907,
    "grad_norm": 0.6467824578285217,
    "learning_rate": 4.988687829696168e-06
  },
  {
    "step": 6250,
    "epoch": 3.5094074698118507,
    "loss": 0.7358,
    "grad_norm": 0.6973240971565247,
    "learning_rate": 4.9548027366047215e-06
  },
  {
    "step": 6260,
    "epoch": 3.5150238696995224,
    "loss": 0.7127,
    "grad_norm": 0.6678489446640015,
    "learning_rate": 4.920995175098637e-06
  },
  {
    "step": 6270,
    "epoch": 3.5206402695871946,
    "loss": 0.6847,
    "grad_norm": 1.2837504148483276,
    "learning_rate": 4.887265664712384e-06
  },
  {
    "step": 6280,
    "epoch": 3.5262566694748667,
    "loss": 0.6808,
    "grad_norm": 1.5191733837127686,
    "learning_rate": 4.853614723780974e-06
  },
  {
    "step": 6290,
    "epoch": 3.531873069362539,
    "loss": 0.7625,
    "grad_norm": 0.9409096837043762,
    "learning_rate": 4.820042869432022e-06
  },
  {
    "step": 6300,
    "epoch": 3.5374894692502106,
    "loss": 0.6993,
    "grad_norm": 1.1722973585128784,
    "learning_rate": 4.78655061757778e-06
  },
  {
    "step": 6300,
    "epoch": 3.5374894692502106,
    "eval_loss": 0.6871243119239807,
    "eval_f1": 0.7735168247042041,
    "eval_precision": 0.779732701742514,
    "eval_recall": 0.7673992673992674,
    "eval_runtime": 35.8886,
    "eval_samples_per_second": 44.109,
    "eval_steps_per_second": 5.517
  },
  {
    "step": 6310,
    "epoch": 3.5431058691378827,
    "loss": 0.7038,
    "grad_norm": 1.7218676805496216,
    "learning_rate": 4.753138482907213e-06
  },
  {
    "step": 6320,
    "epoch": 3.5487222690255544,
    "loss": 0.7095,
    "grad_norm": 0.9508951902389526,
    "learning_rate": 4.719806978878105e-06
  },
  {
    "step": 6330,
    "epoch": 3.5543386689132266,
    "loss": 0.6922,
    "grad_norm": 0.8932923674583435,
    "learning_rate": 4.6865566177091485e-06
  },
  {
    "step": 6340,
    "epoch": 3.5599550688008987,
    "loss": 0.734,
    "grad_norm": 0.9042068123817444,
    "learning_rate": 4.6533879103720785e-06
  },
  {
    "step": 6350,
    "epoch": 3.565571468688571,
    "loss": 0.721,
    "grad_norm": 1.01936936378479,
    "learning_rate": 4.620301366583827e-06
  },
  {
    "step": 6360,
    "epoch": 3.5711878685762426,
    "loss": 0.7079,
    "grad_norm": 0.5750554203987122,
    "learning_rate": 4.587297494798685e-06
  },
  {
    "step": 6370,
    "epoch": 3.5768042684639147,
    "loss": 0.7107,
    "grad_norm": 0.57343590259552,
    "learning_rate": 4.5543768022004845e-06
  },
  {
    "step": 6380,
    "epoch": 3.5824206683515865,
    "loss": 0.7097,
    "grad_norm": 0.8101696968078613,
    "learning_rate": 4.521539794694821e-06
  },
  {
    "step": 6390,
    "epoch": 3.5880370682392586,
    "loss": 0.7107,
    "grad_norm": 0.9573511481285095,
    "learning_rate": 4.488786976901256e-06
  },
  {
    "step": 6400,
    "epoch": 3.5936534681269308,
    "loss": 0.7539,
    "grad_norm": 0.7563955783843994,
    "learning_rate": 4.456118852145574e-06
  },
  {
    "step": 6400,
    "epoch": 3.5936534681269308,
    "eval_loss": 0.6866959929466248,
    "eval_f1": 0.7742639040348964,
    "eval_precision": 0.7802197802197802,
    "eval_recall": 0.7683982683982684,
    "eval_runtime": 35.0164,
    "eval_samples_per_second": 45.207,
    "eval_steps_per_second": 5.654
  },
  {
    "step": 6410,
    "epoch": 3.599269868014603,
    "loss": 0.7649,
    "grad_norm": 0.8754228949546814,
    "learning_rate": 4.42353592245206e-06
  },
  {
    "step": 6420,
    "epoch": 3.6048862679022746,
    "loss": 0.7233,
    "grad_norm": 0.6439138054847717,
    "learning_rate": 4.391038688535752e-06
  },
  {
    "step": 6430,
    "epoch": 3.6105026677899468,
    "loss": 0.7074,
    "grad_norm": 0.8447931408882141,
    "learning_rate": 4.358627649794789e-06
  },
  {
    "step": 6440,
    "epoch": 3.6161190676776185,
    "loss": 0.7475,
    "grad_norm": 0.650987446308136,
    "learning_rate": 4.326303304302696e-06
  },
  {
    "step": 6450,
    "epoch": 3.6217354675652906,
    "loss": 0.7141,
    "grad_norm": 1.167423963546753,
    "learning_rate": 4.294066148800751e-06
  },
  {
    "step": 6460,
    "epoch": 3.627351867452963,
    "loss": 0.7066,
    "grad_norm": 0.8833123445510864,
    "learning_rate": 4.261916678690358e-06
  },
  {
    "step": 6470,
    "epoch": 3.6329682673406345,
    "loss": 0.7719,
    "grad_norm": 1.0925313234329224,
    "learning_rate": 4.229855388025415e-06
  },
  {
    "step": 6480,
    "epoch": 3.6385846672283066,
    "loss": 0.7004,
    "grad_norm": 1.2490673065185547,
    "learning_rate": 4.197882769504727e-06
  },
  {
    "step": 6490,
    "epoch": 3.644201067115979,
    "loss": 0.7452,
    "grad_norm": 1.1691322326660156,
    "learning_rate": 4.165999314464456e-06
  },
  {
    "step": 6500,
    "epoch": 3.6498174670036505,
    "loss": 0.7426,
    "grad_norm": 1.0515869855880737,
    "learning_rate": 4.1342055128705345e-06
  },
  {
    "step": 6500,
    "epoch": 3.6498174670036505,
    "eval_loss": 0.6863102912902832,
    "eval_f1": 0.7744524327035612,
    "eval_precision": 0.7777031564808596,
    "eval_recall": 0.7712287712287712,
    "eval_runtime": 35.5798,
    "eval_samples_per_second": 44.492,
    "eval_steps_per_second": 5.565
  },
  {
    "step": 6510,
    "epoch": 3.6554338668913227,
    "loss": 0.7389,
    "grad_norm": 1.701751947402954,
    "learning_rate": 4.102501853311158e-06
  },
  {
    "step": 6520,
    "epoch": 3.661050266778995,
    "loss": 0.6946,
    "grad_norm": 0.7452702522277832,
    "learning_rate": 4.070888822989285e-06
  },
  {
    "step": 6530,
    "epoch": 3.6666666666666665,
    "loss": 0.6745,
    "grad_norm": 0.5310055613517761,
    "learning_rate": 4.039366907715123e-06
  },
  {
    "step": 6540,
    "epoch": 3.6722830665543387,
    "loss": 0.7449,
    "grad_norm": 1.0493314266204834,
    "learning_rate": 4.007936591898685e-06
  },
  {
    "step": 6550,
    "epoch": 3.677899466442011,
    "loss": 0.7185,
    "grad_norm": 0.948477566242218,
    "learning_rate": 3.976598358542332e-06
  },
  {
    "step": 6560,
    "epoch": 3.6835158663296825,
    "loss": 0.7505,
    "grad_norm": 1.3367133140563965,
    "learning_rate": 3.94535268923337e-06
  },
  {
    "step": 6570,
    "epoch": 3.6891322662173547,
    "loss": 0.7078,
    "grad_norm": 0.9327479600906372,
    "learning_rate": 3.914200064136622e-06
  },
  {
    "step": 6580,
    "epoch": 3.694748666105027,
    "loss": 0.7087,
    "grad_norm": 0.7972210049629211,
    "learning_rate": 3.883140961987069e-06
  },
  {
    "step": 6590,
    "epoch": 3.7003650659926985,
    "loss": 0.7056,
    "grad_norm": 0.9781026840209961,
    "learning_rate": 3.8521758600824835e-06
  },
  {
    "step": 6600,
    "epoch": 3.7059814658803707,
    "loss": 0.744,
    "grad_norm": 1.2542277574539185,
    "learning_rate": 3.821305234276107e-06
  },
  {
    "step": 6600,
    "epoch": 3.7059814658803707,
    "eval_loss": 0.6862184405326843,
    "eval_f1": 0.7754794405828658,
    "eval_precision": 0.7801179443976411,
    "eval_recall": 0.7708957708957709,
    "eval_runtime": 35.3293,
    "eval_samples_per_second": 44.807,
    "eval_steps_per_second": 5.604
  },
  {
    "step": 6610,
    "epoch": 3.711597865768043,
    "loss": 0.7296,
    "grad_norm": 1.0608131885528564,
    "learning_rate": 3.7905295589693193e-06
  },
  {
    "step": 6620,
    "epoch": 3.7172142656557146,
    "loss": 0.749,
    "grad_norm": 0.9619045257568359,
    "learning_rate": 3.7598493071043585e-06
  },
  {
    "step": 6630,
    "epoch": 3.7228306655433867,
    "loss": 0.7234,
    "grad_norm": 1.7947289943695068,
    "learning_rate": 3.72926495015706e-06
  },
  {
    "step": 6640,
    "epoch": 3.728447065431059,
    "loss": 0.7007,
    "grad_norm": 0.6310483813285828,
    "learning_rate": 3.6987769581295953e-06
  },
  {
    "step": 6650,
    "epoch": 3.7340634653187306,
    "loss": 0.7083,
    "grad_norm": 1.7297149896621704,
    "learning_rate": 3.668385799543255e-06
  },
  {
    "step": 6660,
    "epoch": 3.7396798652064027,
    "loss": 0.7029,
    "grad_norm": 0.9267590045928955,
    "learning_rate": 3.6380919414312633e-06
  },
  {
    "step": 6670,
    "epoch": 3.7452962650940744,
    "loss": 0.724,
    "grad_norm": 1.028037667274475,
    "learning_rate": 3.6078958493315773e-06
  },
  {
    "step": 6680,
    "epoch": 3.7509126649817466,
    "loss": 0.6949,
    "grad_norm": 0.765408992767334,
    "learning_rate": 3.5777979872797465e-06
  },
  {
    "step": 6690,
    "epoch": 3.7565290648694187,
    "loss": 0.7284,
    "grad_norm": 0.6842620968818665,
    "learning_rate": 3.5477988178017853e-06
  },
  {
    "step": 6700,
    "epoch": 3.762145464757091,
    "loss": 0.7165,
    "grad_norm": 0.7782268524169922,
    "learning_rate": 3.5178988019070524e-06
  },
  {
    "step": 6700,
    "epoch": 3.762145464757091,
    "eval_loss": 0.6859309673309326,
    "eval_f1": 0.7739720291432878,
    "eval_precision": 0.7786015164279697,
    "eval_recall": 0.7693972693972694,
    "eval_runtime": 35.1591,
    "eval_samples_per_second": 45.024,
    "eval_steps_per_second": 5.632
  },
  {
    "step": 6710,
    "epoch": 3.7677618646447626,
    "loss": 0.7272,
    "grad_norm": 0.6352558135986328,
    "learning_rate": 3.4880983990811745e-06
  },
  {
    "step": 6720,
    "epoch": 3.7733782645324347,
    "loss": 0.7447,
    "grad_norm": 0.6677514314651489,
    "learning_rate": 3.4583980672789907e-06
  },
  {
    "step": 6730,
    "epoch": 3.7789946644201065,
    "loss": 0.7366,
    "grad_norm": 1.700100064277649,
    "learning_rate": 3.4287982629174967e-06
  },
  {
    "step": 6740,
    "epoch": 3.7846110643077786,
    "loss": 0.7152,
    "grad_norm": 1.0417656898498535,
    "learning_rate": 3.399299440868856e-06
  },
  {
    "step": 6750,
    "epoch": 3.7902274641954508,
    "loss": 0.7614,
    "grad_norm": 0.6249107122421265,
    "learning_rate": 3.369902054453387e-06
  },
  {
    "step": 6760,
    "epoch": 3.795843864083123,
    "loss": 0.752,
    "grad_norm": 1.265313744544983,
    "learning_rate": 3.340606555432605e-06
  },
  {
    "step": 6770,
    "epoch": 3.8014602639707946,
    "loss": 0.7494,
    "grad_norm": 1.9408560991287231,
    "learning_rate": 3.311413394002285e-06
  },
  {
    "step": 6780,
    "epoch": 3.8070766638584668,
    "loss": 0.7232,
    "grad_norm": 0.9704639911651611,
    "learning_rate": 3.282323018785536e-06
  },
  {
    "step": 6790,
    "epoch": 3.8126930637461385,
    "loss": 0.7293,
    "grad_norm": 0.7737419605255127,
    "learning_rate": 3.253335876825909e-06
  },
  {
    "step": 6800,
    "epoch": 3.8183094636338106,
    "loss": 0.7132,
    "grad_norm": 1.9070745706558228,
    "learning_rate": 3.2244524135805355e-06
  },
  {
    "step": 6800,
    "epoch": 3.8183094636338106,
    "eval_loss": 0.685374915599823,
    "eval_f1": 0.7747702589807853,
    "eval_precision": 0.7774983232729712,
    "eval_recall": 0.7720612720612721,
    "eval_runtime": 35.1311,
    "eval_samples_per_second": 45.06,
    "eval_steps_per_second": 5.636
  },
  {
    "step": 6810,
    "epoch": 3.823925863521483,
    "loss": 0.7074,
    "grad_norm": 0.5266154408454895,
    "learning_rate": 3.1956730729132657e-06
  },
  {
    "step": 6820,
    "epoch": 3.829542263409155,
    "loss": 0.7528,
    "grad_norm": 1.1750972270965576,
    "learning_rate": 3.1669982970878542e-06
  },
  {
    "step": 6830,
    "epoch": 3.8351586632968266,
    "loss": 0.6994,
    "grad_norm": 0.7698037028312683,
    "learning_rate": 3.138428526761178e-06
  },
  {
    "step": 6840,
    "epoch": 3.840775063184499,
    "loss": 0.7071,
    "grad_norm": 1.506327748298645,
    "learning_rate": 3.1099642009764397e-06
  },
  {
    "step": 6850,
    "epoch": 3.8463914630721705,
    "loss": 0.7099,
    "grad_norm": 0.5660991072654724,
    "learning_rate": 3.0816057571564363e-06
  },
  {
    "step": 6860,
    "epoch": 3.8520078629598427,
    "loss": 0.7277,
    "grad_norm": 1.281459927558899,
    "learning_rate": 3.053353631096839e-06
  },
  {
    "step": 6870,
    "epoch": 3.857624262847515,
    "loss": 0.7105,
    "grad_norm": 0.8849294185638428,
    "learning_rate": 3.0252082569594822e-06
  },
  {
    "step": 6880,
    "epoch": 3.863240662735187,
    "loss": 0.7321,
    "grad_norm": 1.4740183353424072,
    "learning_rate": 2.997170067265711e-06
  },
  {
    "step": 6890,
    "epoch": 3.8688570626228587,
    "loss": 0.7498,
    "grad_norm": 1.1389274597167969,
    "learning_rate": 2.969239492889715e-06
  },
  {
    "step": 6900,
    "epoch": 3.874473462510531,
    "loss": 0.7291,
    "grad_norm": 1.6083219051361084,
    "learning_rate": 2.9414169630519173e-06
  },
  {
    "step": 6900,
    "epoch": 3.874473462510531,
    "eval_loss": 0.6852479577064514,
    "eval_f1": 0.7756603142761619,
    "eval_precision": 0.7787848271231957,
    "eval_recall": 0.7725607725607726,
    "eval_runtime": 35.0663,
    "eval_samples_per_second": 45.143,
    "eval_steps_per_second": 5.646
  },
  {
    "step": 6910,
    "epoch": 3.8800898623982025,
    "loss": 0.7169,
    "grad_norm": 1.079131007194519,
    "learning_rate": 2.9137029053123824e-06
  },
  {
    "step": 6920,
    "epoch": 3.8857062622858747,
    "loss": 0.709,
    "grad_norm": 1.3276841640472412,
    "learning_rate": 2.8860977455642323e-06
  },
  {
    "step": 6930,
    "epoch": 3.891322662173547,
    "loss": 0.6971,
    "grad_norm": 0.550773024559021,
    "learning_rate": 2.8586019080271146e-06
  },
  {
    "step": 6940,
    "epoch": 3.896939062061219,
    "loss": 0.7439,
    "grad_norm": 1.0835678577423096,
    "learning_rate": 2.831215815240679e-06
  },
  {
    "step": 6950,
    "epoch": 3.9025554619488907,
    "loss": 0.7357,
    "grad_norm": 1.0399943590164185,
    "learning_rate": 2.8039398880580804e-06
  },
  {
    "step": 6960,
    "epoch": 3.908171861836563,
    "loss": 0.7152,
    "grad_norm": 1.0630253553390503,
    "learning_rate": 2.7767745456395155e-06
  },
  {
    "step": 6970,
    "epoch": 3.9137882617242346,
    "loss": 0.7246,
    "grad_norm": 1.0283621549606323,
    "learning_rate": 2.7497202054457803e-06
  },
  {
    "step": 6980,
    "epoch": 3.9194046616119067,
    "loss": 0.6968,
    "grad_norm": 0.4011187255382538,
    "learning_rate": 2.722777283231853e-06
  },
  {
    "step": 6990,
    "epoch": 3.925021061499579,
    "loss": 0.7343,
    "grad_norm": 0.6087722778320312,
    "learning_rate": 2.6959461930405086e-06
  },
  {
    "step": 7000,
    "epoch": 3.930637461387251,
    "loss": 0.7007,
    "grad_norm": 1.2147557735443115,
    "learning_rate": 2.669227347195955e-06
  },
  {
    "step": 7000,
    "epoch": 3.930637461387251,
    "eval_loss": 0.6851551532745361,
    "eval_f1": 0.7758447641351623,
    "eval_precision": 0.7794957983193277,
    "eval_recall": 0.7722277722277723,
    "eval_runtime": 35.392,
    "eval_samples_per_second": 44.728,
    "eval_steps_per_second": 5.594
  },
  {
    "step": 7010,
    "epoch": 3.9362538612749227,
    "loss": 0.7358,
    "grad_norm": 0.719066858291626,
    "learning_rate": 2.6426211562974924e-06
  },
  {
    "step": 7020,
    "epoch": 3.941870261162595,
    "loss": 0.7421,
    "grad_norm": 0.5451843738555908,
    "learning_rate": 2.616128029213214e-06
  },
  {
    "step": 7030,
    "epoch": 3.9474866610502666,
    "loss": 0.7408,
    "grad_norm": 1.3945809602737427,
    "learning_rate": 2.5897483730737092e-06
  },
  {
    "step": 7040,
    "epoch": 3.9531030609379387,
    "loss": 0.7179,
    "grad_norm": 1.835244059562683,
    "learning_rate": 2.5634825932658103e-06
  },
  {
    "step": 7050,
    "epoch": 3.958719460825611,
    "loss": 0.7345,
    "grad_norm": 0.6435419321060181,
    "learning_rate": 2.5373310934263785e-06
  },
  {
    "step": 7060,
    "epoch": 3.964335860713283,
    "loss": 0.7047,
    "grad_norm": 1.1950641870498657,
    "learning_rate": 2.511294275436076e-06
  },
  {
    "step": 7070,
    "epoch": 3.9699522606009547,
    "loss": 0.716,
    "grad_norm": 1.3216428756713867,
    "learning_rate": 2.4853725394132068e-06
  },
  {
    "step": 7080,
    "epoch": 3.975568660488627,
    "loss": 0.7392,
    "grad_norm": 0.7075538635253906,
    "learning_rate": 2.4595662837075697e-06
  },
  {
    "step": 7090,
    "epoch": 3.9811850603762986,
    "loss": 0.7039,
    "grad_norm": 0.8373501896858215,
    "learning_rate": 2.433875904894324e-06
  },
  {
    "step": 7100,
    "epoch": 3.9868014602639708,
    "loss": 0.7293,
    "grad_norm": 0.6494402885437012,
    "learning_rate": 2.408301797767898e-06
  },
  {
    "step": 7100,
    "epoch": 3.9868014602639708,
    "eval_loss": 0.6849188804626465,
    "eval_f1": 0.7761916687536523,
    "eval_precision": 0.7783358446341871,
    "eval_recall": 0.7740592740592741,
    "eval_runtime": 35.2608,
    "eval_samples_per_second": 44.894,
    "eval_steps_per_second": 5.615
  },
  {
    "step": 7110,
    "epoch": 3.992417860151643,
    "loss": 0.7496,
    "grad_norm": 0.9210262298583984,
    "learning_rate": 2.3828443553359404e-06
  },
  {
    "step": 7120,
    "epoch": 3.998034260039315,
    "loss": 0.7139,
    "grad_norm": 0.8897389769554138,
    "learning_rate": 2.3575039688132527e-06
  },
  {
    "step": 7130,
    "epoch": 4.003369839932603,
    "loss": 0.7467,
    "grad_norm": 0.9738666415214539,
    "learning_rate": 2.332281027615794e-06
  },
  {
    "step": 7140,
    "epoch": 4.008986239820275,
    "loss": 0.7147,
    "grad_norm": 0.5594960451126099,
    "learning_rate": 2.3071759193547015e-06
  },
  {
    "step": 7150,
    "epoch": 4.014602639707947,
    "loss": 0.7198,
    "grad_norm": 1.1344783306121826,
    "learning_rate": 2.2821890298303174e-06
  },
  {
    "step": 7160,
    "epoch": 4.020219039595619,
    "loss": 0.7107,
    "grad_norm": 0.7367931008338928,
    "learning_rate": 2.257320743026271e-06
  },
  {
    "step": 7170,
    "epoch": 4.025835439483291,
    "loss": 0.7254,
    "grad_norm": 0.7908828258514404,
    "learning_rate": 2.232571441103576e-06
  },
  {
    "step": 7180,
    "epoch": 4.0314518393709635,
    "loss": 0.7184,
    "grad_norm": 0.8639170527458191,
    "learning_rate": 2.207941504394754e-06
  },
  {
    "step": 7190,
    "epoch": 4.037068239258635,
    "loss": 0.6969,
    "grad_norm": 1.1564980745315552,
    "learning_rate": 2.183431311398004e-06
  },
  {
    "step": 7200,
    "epoch": 4.042684639146307,
    "loss": 0.7344,
    "grad_norm": 1.6101754903793335,
    "learning_rate": 2.1590412387713644e-06
  },
  {
    "step": 7200,
    "epoch": 4.042684639146307,
    "eval_loss": 0.684744119644165,
    "eval_f1": 0.7761865112406329,
    "eval_precision": 0.7763157894736842,
    "eval_recall": 0.776057276057276,
    "eval_runtime": 35.9755,
    "eval_samples_per_second": 44.002,
    "eval_steps_per_second": 5.504
  },
  {
    "step": 7210,
    "epoch": 4.048301039033979,
    "loss": 0.7002,
    "grad_norm": 1.1195167303085327,
    "learning_rate": 2.1347716613269343e-06
  },
  {
    "step": 7220,
    "epoch": 4.053917438921651,
    "loss": 0.7246,
    "grad_norm": 0.8675418496131897,
    "learning_rate": 2.1106229520251264e-06
  },
  {
    "step": 7230,
    "epoch": 4.059533838809323,
    "loss": 0.7095,
    "grad_norm": 0.5615827441215515,
    "learning_rate": 2.0865954819689118e-06
  },
  {
    "step": 7240,
    "epoch": 4.0651502386969955,
    "loss": 0.6895,
    "grad_norm": 0.8969186544418335,
    "learning_rate": 2.0626896203981315e-06
  },
  {
    "step": 7250,
    "epoch": 4.070766638584667,
    "loss": 0.7194,
    "grad_norm": 0.9775773286819458,
    "learning_rate": 2.038905734683827e-06
  },
  {
    "step": 7260,
    "epoch": 4.076383038472339,
    "loss": 0.7251,
    "grad_norm": 0.8070520162582397,
    "learning_rate": 2.0152441903225804e-06
  },
  {
    "step": 7270,
    "epoch": 4.081999438360011,
    "loss": 0.7268,
    "grad_norm": 0.6630271077156067,
    "learning_rate": 1.9917053509309037e-06
  },
  {
    "step": 7280,
    "epoch": 4.087615838247683,
    "loss": 0.7197,
    "grad_norm": 0.6967088580131531,
    "learning_rate": 1.9682895782396595e-06
  },
  {
    "step": 7290,
    "epoch": 4.093232238135355,
    "loss": 0.696,
    "grad_norm": 0.6432616114616394,
    "learning_rate": 1.9449972320884892e-06
  },
  {
    "step": 7300,
    "epoch": 4.098848638023028,
    "loss": 0.7487,
    "grad_norm": 0.7150261998176575,
    "learning_rate": 1.921828670420286e-06
  },
  {
    "step": 7300,
    "epoch": 4.098848638023028,
    "eval_loss": 0.684787392616272,
    "eval_f1": 0.7765451664025356,
    "eval_precision": 0.7780377736921277,
    "eval_recall": 0.7750582750582751,
    "eval_runtime": 35.3833,
    "eval_samples_per_second": 44.739,
    "eval_steps_per_second": 5.596
  },
  {
    "step": 7310,
    "epoch": 4.104465037910699,
    "loss": 0.7255,
    "grad_norm": 0.5800085663795471,
    "learning_rate": 1.898784249275706e-06
  },
  {
    "step": 7320,
    "epoch": 4.110081437798371,
    "loss": 0.735,
    "grad_norm": 0.9396028518676758,
    "learning_rate": 1.8758643227876772e-06
  },
  {
    "step": 7330,
    "epoch": 4.115697837686043,
    "loss": 0.6903,
    "grad_norm": 0.6899664998054504,
    "learning_rate": 1.853069243175979e-06
  },
  {
    "step": 7340,
    "epoch": 4.121314237573715,
    "loss": 0.7203,
    "grad_norm": 0.6993586421012878,
    "learning_rate": 1.830399360741808e-06
  },
  {
    "step": 7350,
    "epoch": 4.126930637461387,
    "loss": 0.7534,
    "grad_norm": 0.993653416633606,
    "learning_rate": 1.8078550238624116e-06
  },
  {
    "step": 7360,
    "epoch": 4.13254703734906,
    "loss": 0.7477,
    "grad_norm": 1.4826947450637817,
    "learning_rate": 1.7854365789857232e-06
  },
  {
    "step": 7370,
    "epoch": 4.138163437236731,
    "loss": 0.6893,
    "grad_norm": 0.7510461211204529,
    "learning_rate": 1.7631443706250484e-06
  },
  {
    "step": 7380,
    "epoch": 4.143779837124403,
    "loss": 0.7466,
    "grad_norm": 0.7488189935684204,
    "learning_rate": 1.7409787413537627e-06
  },
  {
    "step": 7390,
    "epoch": 4.149396237012075,
    "loss": 0.7282,
    "grad_norm": 1.2287813425064087,
    "learning_rate": 1.7189400318000483e-06
  },
  {
    "step": 7400,
    "epoch": 4.155012636899747,
    "loss": 0.7183,
    "grad_norm": 2.039483070373535,
    "learning_rate": 1.697028580641662e-06
  },
  {
    "step": 7400,
    "epoch": 4.155012636899747,
    "eval_loss": 0.6845747828483582,
    "eval_f1": 0.7769532227132494,
    "eval_precision": 0.7781860698179389,
    "eval_recall": 0.7757242757242757,
    "eval_runtime": 35.4901,
    "eval_samples_per_second": 44.604,
    "eval_steps_per_second": 5.579
  },
  {
    "step": 7410,
    "epoch": 4.1606290367874195,
    "loss": 0.7243,
    "grad_norm": 0.6137552261352539,
    "learning_rate": 1.6752447246007265e-06
  },
  {
    "step": 7420,
    "epoch": 4.166245436675092,
    "loss": 0.6977,
    "grad_norm": 0.9654527306556702,
    "learning_rate": 1.6535887984385667e-06
  },
  {
    "step": 7430,
    "epoch": 4.171861836562763,
    "loss": 0.7468,
    "grad_norm": 2.070963144302368,
    "learning_rate": 1.63206113495055e-06
  },
  {
    "step": 7440,
    "epoch": 4.177478236450435,
    "loss": 0.7048,
    "grad_norm": 1.156269907951355,
    "learning_rate": 1.6106620649609783e-06
  },
  {
    "step": 7450,
    "epoch": 4.183094636338107,
    "loss": 0.7329,
    "grad_norm": 0.8251242637634277,
    "learning_rate": 1.589391917318015e-06
  },
  {
    "step": 7460,
    "epoch": 4.188711036225779,
    "loss": 0.7207,
    "grad_norm": 0.7537451982498169,
    "learning_rate": 1.568251018888609e-06
  },
  {
    "step": 7470,
    "epoch": 4.1943274361134515,
    "loss": 0.7197,
    "grad_norm": 1.1816624402999878,
    "learning_rate": 1.5472396945534962e-06
  },
  {
    "step": 7480,
    "epoch": 4.199943836001124,
    "loss": 0.7357,
    "grad_norm": 0.8747384548187256,
    "learning_rate": 1.526358267202186e-06
  },
  {
    "step": 7490,
    "epoch": 4.205560235888795,
    "loss": 0.7062,
    "grad_norm": 1.2282629013061523,
    "learning_rate": 1.5056070577280114e-06
  },
  {
    "step": 7500,
    "epoch": 4.211176635776467,
    "loss": 0.7624,
    "grad_norm": 1.2900111675262451,
    "learning_rate": 1.484986385023197e-06
  },
  {
    "step": 7500,
    "epoch": 4.211176635776467,
    "eval_loss": 0.6844327449798584,
    "eval_f1": 0.7776851234156104,
    "eval_precision": 0.778984296692282,
    "eval_recall": 0.7763902763902764,
    "eval_runtime": 35.1,
    "eval_samples_per_second": 45.1,
    "eval_steps_per_second": 5.641
  },
  {
    "step": 7510,
    "epoch": 4.216793035664139,
    "loss": 0.7061,
    "grad_norm": 0.7787601351737976,
    "learning_rate": 1.464496565973953e-06
  },
  {
    "step": 7520,
    "epoch": 4.222409435551811,
    "loss": 0.6897,
    "grad_norm": 1.0556983947753906,
    "learning_rate": 1.444137915455609e-06
  },
  {
    "step": 7530,
    "epoch": 4.2280258354394835,
    "loss": 0.7292,
    "grad_norm": 1.1834180355072021,
    "learning_rate": 1.4239107463277779e-06
  },
  {
    "step": 7540,
    "epoch": 4.233642235327156,
    "loss": 0.7196,
    "grad_norm": 1.1427339315414429,
    "learning_rate": 1.403815369429541e-06
  },
  {
    "step": 7550,
    "epoch": 4.239258635214827,
    "loss": 0.7321,
    "grad_norm": 1.0828601121902466,
    "learning_rate": 1.3838520935746745e-06
  },
  {
    "step": 7560,
    "epoch": 4.244875035102499,
    "loss": 0.7414,
    "grad_norm": 0.6856601238250732,
    "learning_rate": 1.364021225546911e-06
  },
  {
    "step": 7570,
    "epoch": 4.250491434990171,
    "loss": 0.7362,
    "grad_norm": 1.0664708614349365,
    "learning_rate": 1.3443230700952114e-06
  },
  {
    "step": 7580,
    "epoch": 4.256107834877843,
    "loss": 0.6905,
    "grad_norm": 0.7505211234092712,
    "learning_rate": 1.3247579299290924e-06
  },
  {
    "step": 7590,
    "epoch": 4.2617242347655155,
    "loss": 0.7314,
    "grad_norm": 0.45079687237739563,
    "learning_rate": 1.30532610571397e-06
  },
  {
    "step": 7600,
    "epoch": 4.267340634653188,
    "loss": 0.7232,
    "grad_norm": 0.6972859501838684,
    "learning_rate": 1.2860278960665395e-06
  },
  {
    "step": 7600,
    "epoch": 4.267340634653188,
    "eval_loss": 0.6844361424446106,
    "eval_f1": 0.7777129034948703,
    "eval_precision": 0.7792077553067023,
    "eval_recall": 0.7762237762237763,
    "eval_runtime": 35.4558,
    "eval_samples_per_second": 44.647,
    "eval_steps_per_second": 5.584
  },
  {
    "step": 7610,
    "epoch": 4.272957034540859,
    "loss": 0.7165,
    "grad_norm": 0.8887761831283569,
    "learning_rate": 1.2668635975501876e-06
  },
  {
    "step": 7620,
    "epoch": 4.278573434428531,
    "loss": 0.7121,
    "grad_norm": 0.9186533689498901,
    "learning_rate": 1.247833504670437e-06
  },
  {
    "step": 7630,
    "epoch": 4.284189834316203,
    "loss": 0.7161,
    "grad_norm": 0.7402582764625549,
    "learning_rate": 1.2289379098704136e-06
  },
  {
    "step": 7640,
    "epoch": 4.289806234203875,
    "loss": 0.7307,
    "grad_norm": 1.1337378025054932,
    "learning_rate": 1.210177103526362e-06
  },
  {
    "step": 7650,
    "epoch": 4.295422634091548,
    "loss": 0.7168,
    "grad_norm": 0.7670296430587769,
    "learning_rate": 1.1915513739431738e-06
  },
  {
    "step": 7660,
    "epoch": 4.30103903397922,
    "loss": 0.7178,
    "grad_norm": 1.1209861040115356,
    "learning_rate": 1.1730610073499626e-06
  },
  {
    "step": 7670,
    "epoch": 4.306655433866891,
    "loss": 0.7692,
    "grad_norm": 1.0860669612884521,
    "learning_rate": 1.1547062878956662e-06
  },
  {
    "step": 7680,
    "epoch": 4.312271833754563,
    "loss": 0.7086,
    "grad_norm": 1.0305103063583374,
    "learning_rate": 1.136487497644677e-06
  },
  {
    "step": 7690,
    "epoch": 4.317888233642235,
    "loss": 0.7083,
    "grad_norm": 0.6761919856071472,
    "learning_rate": 1.118404916572504e-06
  },
  {
    "step": 7700,
    "epoch": 4.323504633529907,
    "loss": 0.7198,
    "grad_norm": 0.9125660061836243,
    "learning_rate": 1.1004588225614844e-06
  },
  {
    "step": 7700,
    "epoch": 4.323504633529907,
    "eval_loss": 0.6842933297157288,
    "eval_f1": 0.7769269185949725,
    "eval_precision": 0.776797603195739,
    "eval_recall": 0.7770562770562771,
    "eval_runtime": 35.3239,
    "eval_samples_per_second": 44.814,
    "eval_steps_per_second": 5.605
  },
  {
    "step": 7710,
    "epoch": 4.32912103341758,
    "loss": 0.7349,
    "grad_norm": 0.7690536379814148,
    "learning_rate": 1.0826494913964935e-06
  },
  {
    "step": 7720,
    "epoch": 4.334737433305252,
    "loss": 0.7177,
    "grad_norm": 0.6806135177612305,
    "learning_rate": 1.0649771967607214e-06
  },
  {
    "step": 7730,
    "epoch": 4.340353833192923,
    "loss": 0.743,
    "grad_norm": 0.7597135901451111,
    "learning_rate": 1.0474422102314652e-06
  },
  {
    "step": 7740,
    "epoch": 4.345970233080595,
    "loss": 0.7049,
    "grad_norm": 1.0635863542556763,
    "learning_rate": 1.0300448012759467e-06
  },
  {
    "step": 7750,
    "epoch": 4.351586632968267,
    "loss": 0.7066,
    "grad_norm": 0.6668893098831177,
    "learning_rate": 1.0127852372471792e-06
  },
  {
    "step": 7760,
    "epoch": 4.3572030328559395,
    "loss": 0.6796,
    "grad_norm": 0.7795371413230896,
    "learning_rate": 9.956637833798622e-07
  },
  {
    "step": 7770,
    "epoch": 4.362819432743612,
    "loss": 0.7173,
    "grad_norm": 0.6327272057533264,
    "learning_rate": 9.786807027862966e-07
  },
  {
    "step": 7780,
    "epoch": 4.368435832631283,
    "loss": 0.6966,
    "grad_norm": 0.5391806364059448,
    "learning_rate": 9.618362564523432e-07
  },
  {
    "step": 7790,
    "epoch": 4.374052232518955,
    "loss": 0.733,
    "grad_norm": 0.6359940767288208,
    "learning_rate": 9.451307032334178e-07
  },
  {
    "step": 7800,
    "epoch": 4.379668632406627,
    "loss": 0.6806,
    "grad_norm": 0.9460374116897583,
    "learning_rate": 9.285642998505062e-07
  },
  {
    "step": 7800,
    "epoch": 4.379668632406627,
    "eval_loss": 0.6842901110649109,
    "eval_f1": 0.7767507702556415,
    "eval_precision": 0.7769448609028818,
    "eval_recall": 0.7765567765567766,
    "eval_runtime": 35.3774,
    "eval_samples_per_second": 44.746,
    "eval_steps_per_second": 5.597
  },
  {
    "step": 7810,
    "epoch": 4.385285032294299,
    "loss": 0.7132,
    "grad_norm": 1.0793265104293823,
    "learning_rate": 9.121373008862289e-07
  },
  {
    "step": 7820,
    "epoch": 4.3909014321819715,
    "loss": 0.7186,
    "grad_norm": 1.381493091583252,
    "learning_rate": 8.958499587809155e-07
  },
  {
    "step": 7830,
    "epoch": 4.396517832069644,
    "loss": 0.7108,
    "grad_norm": 0.8831136226654053,
    "learning_rate": 8.797025238287327e-07
  },
  {
    "step": 7840,
    "epoch": 4.402134231957316,
    "loss": 0.7456,
    "grad_norm": 1.109521746635437,
    "learning_rate": 8.636952441738422e-07
  },
  {
    "step": 7850,
    "epoch": 4.407750631844987,
    "loss": 0.7125,
    "grad_norm": 0.6574850678443909,
    "learning_rate": 8.4782836580658e-07
  },
  {
    "step": 7860,
    "epoch": 4.413367031732659,
    "loss": 0.7227,
    "grad_norm": 0.8882244229316711,
    "learning_rate": 8.321021325596757e-07
  },
  {
    "step": 7870,
    "epoch": 4.418983431620331,
    "loss": 0.7491,
    "grad_norm": 0.4216727018356323,
    "learning_rate": 8.165167861045143e-07
  },
  {
    "step": 7880,
    "epoch": 4.4245998315080035,
    "loss": 0.7368,
    "grad_norm": 0.9742628335952759,
    "learning_rate": 8.010725659474139e-07
  },
  {
    "step": 7890,
    "epoch": 4.430216231395676,
    "loss": 0.7385,
    "grad_norm": 1.0446341037750244,
    "learning_rate": 7.857697094259431e-07
  },
  {
    "step": 7900,
    "epoch": 4.435832631283347,
    "loss": 0.7126,
    "grad_norm": 0.893565833568573,
    "learning_rate": 7.706084517052881e-07
  },
  {
    "step": 7900,
    "epoch": 4.435832631283347,
    "eval_loss": 0.6841887831687927,
    "eval_f1": 0.7773245650545243,
    "eval_precision": 0.777259863492592,
    "eval_recall": 0.7773892773892774,
    "eval_runtime": 35.6181,
    "eval_samples_per_second": 44.444,
    "eval_steps_per_second": 5.559
  },
  {
    "step": 7900,
    "epoch": 4.435832631283347,
    "train_runtime": 5235.7575,
    "train_samples_per_second": 13.601,
    "train_steps_per_second": 1.701,
    "total_flos": 4.452329205680947e+16,
    "train_loss": 0.861943962302389
  }
]