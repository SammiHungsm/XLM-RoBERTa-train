import json
import re

# ==========================================
# 1. å®šç¾©è¦æ¨™è¨»çš„ã€Œå¯¦é«”åå–®ã€
# ==========================================
# é€™äº›æ˜¯æˆ‘å€‘å¸Œæœ›æ¨¡å‹å­¸æœƒæ‰ä½çš„é‡é»
target_names = ["æ¥Šç¾ç", "é‡‘æ¾¤åŸ¹"]
target_orgs = ["æ¸¯éµ"]

# æ³¨æ„ï¼šã€Œè¡Œæ”¿ç¸½è£ã€ã€ã€Œå¸¸å‹™ç¸½ç›£ã€ã€ã€Œå“¡å·¥ã€ç­‰è·ä½æœƒè‡ªå‹•è®Šæˆ Oï¼Œ
# é€™èƒ½æ•™å°æ¨¡å‹ä¸è¦æŠŠè·ä½èª¤ç•¶æˆäººåã€‚

# ==========================================
# 2. åŸå§‹æ–‡æœ¬
# ==========================================
raw_content = """æ¸¯éµæ–°ä»»è¡Œæ”¿ç¸½è£æ¥Šç¾çæ˜¨å±¥æ–°ï¼Œå¥¹ä»Šæ—©ï¼ˆ2æ—¥ï¼‰æ–¼æ¸¯éµç¸½éƒ¨æœƒè¦‹å‚³åª’ï¼Œç¨±ä¸Šä»»å¾Œå·¥ä½œé‡é»åŒ…æ‹¬æ¨é€²6å€‹æ–°éµè·¯é …ç›®ï¼Œå°ˆæ³¨å·¥ç¨‹å’Œè²¡å‹™ç®¡ç†åŠå»ºè¨­é«˜å³°æœŸçš„ç¾é‡‘æµï¼Œäº¦æœƒç©æ¥µç”¨å¥½ç§‘æŠ€åŠäººå·¥æ™ºèƒ½å»é¢å°æŒ‘æˆ°ï¼ŒåŒæ™‚ç™¼å±•é–‹æ‹“ä¸åŒæ¥­å‹™ã€‚æ¥Šç¾çåˆè¡¨ç¤ºï¼Œè‘—é‡èˆ‡å“¡å·¥æºé€šï¼Œç›¼ç· é€ è‰¯å¥½å·¥ä½œç’°å¢ƒè®“å“¡å·¥ç™¼æ®æ‰€é•·ã€‚

æ¥Šç¾çåŸæ˜¯æ¸¯éµå¸¸å‹™ç¸½ç›£ï¼ˆé¦™æ¸¯å®¢é‹æœå‹™ï¼‰ï¼Œæ˜¨æ—¥èµ·æ¥æ›¿é‡‘æ¾¤åŸ¹å‡ä»»è¡Œæ”¿ç¸½è£ã€‚å¥¹ç¨±åŠ å…¥æ¸¯éµå·²26å¹´ï¼Œæ˜ç™½æ–°å´—ä½è²¬ä»»é‡å¤§ï¼Œæœƒé—œå¿ƒæ˜ç™½ä¹˜å®¢éœ€è¦ä¸¦ä¸æ–·æå‡éµè·¯æœå‹™ï¼Œèˆ‡æ™‚ä¸¦é€²ï¼ŒåŒæ™‚éå›ºéµè·¯è³‡ç”¢ã€è³ªç´ åŠéŸŒæ€§ã€‚
å¥¹åˆèªªï¼Œæ¸¯éµç›®å‰å¦ä¸€é‡ä»»æ˜¯æ¨é€²6å€‹æ¶‰åŠå¤§å¶¼å±±ã€å±¯é–€åŠåŒ—éƒ½çš„éµè·¯æ–°é …ç›®ï¼Œæœªè¨ˆåŠåŒ—ç’°ç·šéƒ¨åˆ†çš„æŠ•è³‡å·²æ¶‰1400å„„å…ƒï¼Œå°‡åœ¨2027å¹´è‡³2034å¹´å¸¶ä¾†é€¾20å€‹æ–°è»Šç«™ï¼Œå·¥ç¨‹åŠè²¡å‹™ç®¡ç†å°‡å±¬å·¥ä½œé‡é»ã€‚æ¥Šæåˆ°ï¼Œæ¸¯éµå»å¹´æœ‰ä¸åŒçµ„åˆæ‡‰ä»˜ç¾é‡‘æµéœ€è¦ï¼Œå°‡æŒçºŒåˆ©ç”¨ç›¸é—œåšæ³•ï¼Œèªç‚ºç¾æ™‚ç®¡ç†ç¾é‡‘æµæ–¹é¢åšå¾—ä¸éŒ¯ã€‚
æ¥Šç¾ççºŒç¨±ï¼Œæ¸¯éµéµè·¯æœå‹™æ˜¯é¦™æ¸¯æ°‘ç”ŸåŠç¶“æ¿Ÿçš„é‡è¦åŸºå»ºè¨­æ–½ï¼Œå¿…é ˆè®“å…¶èƒ½æŒçºŒç™¼å±•ï¼Œé¢å°ä¹˜å®¢éœ€æ±‚è½‰è®Šã€å¸‚å ´åŠç’°å¢ƒè®ŠåŒ–ç­‰æŒ‘æˆ°ï¼ŒæœƒåŠªåŠ›ç©æ¥µåˆ©ç”¨äººå·¥æ™ºèƒ½ï¼Œä»¥å‰µæ–°ã€æå‡æœå‹™å’Œç‡Ÿé‹æ•ˆç‡ï¼ŒåŒæ™‚ä¿æŒç«¶çˆ­åŠ›ï¼Œé€éœ²ç¾æ­£æœ‰ä¸åŒAIæ–¹é¢çš„æ¸¬è©¦åŠå¯¦é©—ï¼Œç›®æ¨™æ˜¯å°‡æ›´å¤šç›¸é—œè¨ˆåŠƒè½å¯¦åŠæ“´å¤§ã€‚
æ¥Šç¾çäº¦è¡¨ç¤ºï¼Œæ¸¯éµæœ‰å„ªç§€çš„åœ˜éšŠï¼Œæƒ³ç‚ºå“¡å·¥ç· é€ è‰¯å¥½å·¥ä½œå¹³å°ï¼ŒæœŸæœ›åŠ å¼·å·¥ä½œæ–‡åŒ–åŠæºé€šã€‚

åŸæ–‡ç¶²å€ï¼šhttps://news.mingpao.com/ins/%E6%B8%AF%E8%81%9E/article/20260102/s00001/1767321394120"""

# ==========================================
# 3. è™•ç†é‚è¼¯
# ==========================================
def process_data(text):
    # A. ç§»é™¤ URL
    if "åŸæ–‡ç¶²å€ï¼š" in text:
        text = text.split("åŸæ–‡ç¶²å€ï¼š")[0]

    # B. åˆ†å¥
    sentences = re.split(r'([ã€‚ï¼ï¼Ÿ\n])', text)
    segments = []
    current_sent = ""
    for s in sentences:
        current_sent += s
        if re.match(r'[ã€‚ï¼ï¼Ÿ\n]', s):
            if current_sent.strip():
                segments.append(current_sent.strip())
            current_sent = ""
    if current_sent.strip(): segments.append(current_sent.strip())

    # C. è‡ªå‹•æ¨™è¨»
    # ç¢ºä¿ ID èˆ‡ä½ çš„ train_lora.py ä¸€è‡´
    label2id = {
        "O": 0, "B-NAME": 1, "I-NAME": 2, 
        "B-ADDRESS": 3, "I-ADDRESS": 4, 
        "B-PHONE": 5, "I-PHONE": 6, 
        "B-ID": 7, "I-ID": 8, 
        "B-ACCOUNT": 9, "I-ACCOUNT": 10,
        "B-LICENSE_PLATE": 11, "I-LICENSE_PLATE": 12,
        "B-ORG": 13, "I-ORG": 14
    }

    final_data = []

    for sent in segments:
        tokens = list(sent)
        tags = [label2id["O"]] * len(tokens)
        
        # 1. æ¨™è¨»äººå (NAME)
        for name in target_names:
            for match in re.finditer(name, sent):
                start, end = match.span()
                tags[start] = label2id["B-NAME"]
                for i in range(start + 1, end):
                    tags[i] = label2id["I-NAME"]
        
        # 2. æ¨™è¨»æ©Ÿæ§‹ (ORG)
        for org in target_orgs:
            for match in re.finditer(org, sent):
                start, end = match.span()
                # åªæœ‰ç•¶è©²ä½ç½®åŸæœ¬æ˜¯ 'O' æ‰æ¨™è¨»ï¼Œé¿å…è¦†è“‹äººå (é›–ç”±é€™ç¯‡æ–‡ä¸æœƒé‡ç–Š)
                if tags[start] == label2id["O"]: 
                    tags[start] = label2id["B-ORG"]
                    for i in range(start + 1, end):
                        tags[i] = label2id["I-ORG"]
        
        if len(tokens) > 0:
            final_data.append({
                "tokens": tokens,
                "ner_tags": tags
            })
            
    return final_data

# ==========================================
# 4. åŸ·è¡Œèˆ‡å„²å­˜
# ==========================================
mtr_json_data = process_data(raw_content)

output_file = "mtr_news_data.json"
with open(output_file, "w", encoding="utf-8") as f:
    json.dump(mtr_json_data, f, ensure_ascii=False, indent=2)

print(f"âœ… è™•ç†å®Œæˆï¼å…±ç”Ÿæˆ {len(mtr_json_data)} æ¢æ··åˆæ•¸æ“šã€‚")
print(f"   - å·²æ¨™è¨» NAME: {target_names}")
print(f"   - å·²æ¨™è¨» ORG:  {target_orgs}")
print(f"ğŸ“ æª”æ¡ˆå·²å„²å­˜ç‚º: {output_file}")